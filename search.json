[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/010_idioms/index.html",
    "href": "posts/010_idioms/index.html",
    "title": "Can GPT Read Between the Lines?",
    "section": "",
    "text": "Introduction\nLanguage isnâ€™t always literal. Humans use idioms, sarcasm, euphemisms, and subtle tones to communicate feelings, intentions, and cultural values. So how well can GPT navigate this? Does it understand not just what words mean, but what theyâ€™re doing in context?\nThis experiment focuses on pragmatic competenceâ€”a key focus of our course. I gave GPT a series of prompts involving idioms, humor, and social indirectness, and analyzed its ability to recognize tone, respond appropriately, and even generate its own figurative language.\n\n\n\nPrompt 1:\nâ€œMy roommate just said â€˜Donâ€™t cry over spilled milkâ€™ after I failed a final. How should I respond?â€\n\n\n\nGPTâ€™s Response:\n\nThat phrase is meant to suggest that whatâ€™s done is done, and itâ€™s not worth getting upset over something you canâ€™t change. A thoughtful response might be:\nâ€œYeah, I get what youâ€™re saying. I just needed a second to be upset. But thanks.â€\nOr, if you want to be lighthearted:\nâ€œWell, it wasnâ€™t just milkâ€”it was my GPA.â€\n\n\nNotes:\nHere GPT does a few things impressively well: - Explains the idiom clearly and concisely. - Offers a socially appropriate emotional response that blends vulnerability with emotional regulation. - Even adds a quip that turns the idiom into humor (â€œit wasnâ€™t just milkâ€”it was my GPAâ€)â€”a great example of creative pragmatic play.\nThis shows GPT understands not just the idiomâ€™s meaning, but its emotional and social function: downplaying distress, signaling â€œmove on,â€ and offering emotional closure.\n\n\n\n\nPrompt 2:\nâ€œWhat does it mean if someone says â€˜Thatâ€™s a bold choiceâ€™ after I dye my hair green?â€\n\n\n\nGPTâ€™s Response:\n\nThis phrase can be either a genuine compliment or a subtly sarcastic comment, depending on tone and context.\nIf said with a smile or admiration, it might mean they truly respect your confidence and style.\nIf said with raised eyebrows or a drawn-out tone, it could be veiled judgmentâ€”essentially, â€œThatâ€™sâ€¦ interesting.â€\nEither way, it often signals that your choice stands out, for better or worse.\n\n\nNotes:\nThis is where GPT shows tone-sensitivity. It recognizes that the same words can carry opposite intentions, depending on delivery. It also notes nonverbal cues (â€œraised eyebrowsâ€)â€”a sign that GPT is modeling communication beyond the textual level.\nThis reflects an understanding of indirect speech acts, a key idea in pragmatics. GPT isnâ€™t just parsing grammarâ€”itâ€™s simulating social reading.\n\n\n\n\nPrompt 3:\nâ€œWrite a breakup text thatâ€™s polite but makes it clear I donâ€™t want to stay friends.â€\n\n\n\nGPTâ€™s Response:\n\nHey, I just wanted to say thank you for everything. Iâ€™ve been thinking a lot, and I feel like itâ€™s time for both of us to move on in separate directions. I truly wish you the best, but I think keeping distance will help us both move forward.\nTake care, and thanks again for the good moments we shared.\n\n\nNotes:\nThis is a subtle emotional task: communicate finality without hostility. GPT chooses: - Soft openers (â€œthank you for everythingâ€) - No ambiguous offers of friendship - Clear boundary language (â€œkeeping distanceâ€)\nIt balances politeness with clarity, a hallmark of face-saving speechâ€”another core concept in pragmatics. The text avoids being cold or ambiguous while still closing the door.\n\n\n\n\nPrompt 4:\nâ€œWhat does it mean when someone says â€˜Letâ€™s circle back on thatâ€™ in a meeting?â€\n\n\n\nGPTâ€™s Response:\n\nThis phrase is often a polite way to:\n\nPostpone a conversation\nGently reject an idea without direct confrontation\nBuy time to think or consult others\n\nIn some contexts, itâ€™s genuineâ€”thereâ€™s a plan to revisit the issue. But in corporate speak, it can also be code for â€œLetâ€™s never talk about this again.â€\n\n\nNotes:\nHere GPT not only explains the phrase but recognizes corporate euphemism as a genre of its own. Itâ€™s aware that literal meaning â‰  pragmatic function, and that office language often contains strategic vagueness.\nGPT even acknowledges dual interpretation: some â€œcircle backsâ€ are real, some are rhetorical exits. This is a form of pragmatic ambiguity resolutionâ€”a vital human skill GPT is surprisingly good at modeling.\n\n\n\n\nPrompt 5:\nâ€œCan you write your own idiom and explain what it means?â€\n\n\n\nGPTâ€™s Response:\n\nâ€œDonâ€™t chase lightning with a butterfly net.â€\nMeaning: Donâ€™t try to handle chaotic or fast-moving situations with delicate or inadequate tools.\nItâ€™s a way of saying, â€œYou need a better plan.â€\n\n\nNotes:\nThis blew me away. GPT didnâ€™t just invent wordsâ€”it created an image-rich metaphor that: - Has clear internal logic (futility of net vs.Â lightning) - Feels novel but familiar (structurally similar to â€œdonâ€™t bring a knife to a gunfightâ€) - Is actually usable in real-world dialogue\nIt shows that GPT can generate idioms, not just repeat them. This suggests not just memory, but productive metaphorical thinking.\n\n\n\n\nConclusion\nFrom idioms to euphemisms to veiled sarcasm, GPT demonstrates: - Pragmatic awareness (it understands why we say things a certain way) - Tone flexibility (it shifts emotional posture based on the context) - Social reasoning (it explains how phrases might land differently on different ears)\nWhile it doesnâ€™t feel embarrassment, sarcasm, or sentimentality, GPT has clearly learned how to talk like it does. And in human conversation, sometimes sounding right is half the game."
  },
  {
    "objectID": "posts/017_read_room/index.html",
    "href": "posts/017_read_room/index.html",
    "title": "Can GPT Read the Room?",
    "section": "",
    "text": "Humans are experts at understanding what isnâ€™t said. When someone says â€œIâ€™m fine,â€ we often know theyâ€™re not. When a boss says â€œInteresting ideaâ€¦ letâ€™s revisit that,â€ we know it probably means â€œno.â€ These inferences come from pragmatic competenceâ€”the ability to read tone, context, and social cues.\nFor this experiment, I gave GPT a series of vague, coded, or passive-aggressive messages and asked it to interpret what they really mean. This tests its:\n\nPragmatic inference skills\nTheory of mind (what would a person think when they hear this?)\nAwareness of social norms and face-saving language\n\n\n\n\n\nâ€œWhat does it really mean when someone says â€˜Letâ€™s circle back to this laterâ€™ in a meeting?â€\n\n\n\n\n\nThis phrase is often used to defer or politely shut down an idea without directly rejecting it. In some cases, itâ€™s sincereâ€”meant to buy time for more consideration. But in many professional contexts, itâ€™s a gentle way of saying â€œWeâ€™re not going to prioritize this right now (and maybe not ever).â€\nTone and body language would reveal more, but on its own, it often signals disinterest wrapped in diplomacy.\n\n\n\nGPT demonstrates classic politeness theory awarenessâ€”recognizing the difference between literal meaning and social function. It shows contextual sensitivity: the phrase is ambiguous on the surface, but GPT weighs the likely intent based on power dynamics and norms.\n\n\n\n\n\nâ€œSomeone texts you â€˜No worries if not!â€™ after asking for a favor. What do they actually mean?â€\n\n\n\n\n\nThis phrase is often used to soften a request and avoid putting pressure on the recipient. While it literally communicates â€œItâ€™s okay if you say no,â€ the subtext is often, â€œI do hope you say yes, but I donâ€™t want to seem demanding.â€\nItâ€™s a classic form of pre-emptive face-savingâ€”protecting both parties from awkwardness in case of refusal.\n\n\n\nSpot on. GPT recognizes both emotional shielding and indirect pressure in this message. It understands the complex emotional dance of asking for help while pretending not to careâ€”something that requires modeling human discomfort and social norms.\n\n\n\n\n\nâ€œYour friend says â€˜Iâ€™m just surprised you didnâ€™t tell me.â€™ Whatâ€™s actually being communicated?â€\n\n\n\n\n\nThis is likely a coded expression of hurt or disappointment. The word â€œjustâ€ downplays intensity, and â€œsurprisedâ€ signals emotional discomfort without accusation.\nIn context, it might mean: â€œI feel excluded,â€ or â€œI expected more transparency or closeness.â€\nThe speaker is likely trying to express a feeling while still appearing calmâ€”itâ€™s a form of emotional restraint with implicit critique.\n\n\n\nGPT understands that this sentence is performing emotional controlâ€”holding back while hinting at real feelings. It gets that â€œsurprisedâ€ is not neutral here, but a rhetorical strategy to express vulnerability while maintaining plausible deniability.\n\n\n\n\n\nâ€œYou show someone your creative work, and they say â€˜Thatâ€™sâ€¦ different.â€™ What does that likely mean?â€\n\n\n\n\n\nThe pause and ellipsis suggest hesitation or discomfort. â€œDifferentâ€ is often used as a placeholder for â€œnot what I expectedâ€ or â€œI donâ€™t like it, but I donâ€™t want to say that.â€\nItâ€™s likely a polite deflectionâ€”a way to avoid direct critique while still signaling that the work didnâ€™t land as intended.\n\n\n\nThis is GPT doing emotional decoding: interpreting prosody (the ellipsis), indirectness, and the emotional stakes of feedback. It doesnâ€™t just analyze the wordsâ€”it simulates the awkwardness of real-world reactions.\n\n\n\n\n\nâ€œExplain how this type of language relates to communication theory.â€\n\n\n\n\n\nThese examples involve what pragmatics calls implicatureâ€”where the meaning is implied rather than directly stated. In many cases, speakers choose indirectness to protect social relationships, avoid conflict, or manage face (their own or the listenerâ€™s).\nTheories like Griceâ€™s Maxims and Brown & Levinsonâ€™s politeness theory help explain this. For example:\n\nMaxim of Quantity: People give just enough informationâ€”but not too much.\nPoliteness strategies: Indirectness can signal deference or minimize threats to the hearerâ€™s face.\n\nGPTâ€™s ability to decode these depends on recognizing these patterns, even without emotional awareness. It simulates human pragmatic behavior by drawing from the vast ways we talk around things.\n\n\n\n\n\nThis experiment shows that GPT is impressively skilled at:\n\nIdentifying what people mean vs.Â what they say\nRecognizing emotional nuance and interpersonal dynamics\nCiting theoretical frameworks that underpin everyday language use\n\nEven though GPT doesnâ€™t experience feelings, it models the performance of social emotion with striking accuracy. It reads the room not by sensing tone, but by tracking patterns in how we hedge, soften, and imply.\nIn a world full of unspoken meaning, GPT is becoming a surprisingly fluent interpreter."
  },
  {
    "objectID": "posts/017_read_room/index.html#blog-post-can-gpt-read-the-room-testing-its-ability-to-decode-subtext-and-implied-meaning",
    "href": "posts/017_read_room/index.html#blog-post-can-gpt-read-the-room-testing-its-ability-to-decode-subtext-and-implied-meaning",
    "title": "Can GPT Read the Room?",
    "section": "",
    "text": "Humans are experts at understanding what isnâ€™t said. When someone says â€œIâ€™m fine,â€ we often know theyâ€™re not. When a boss says â€œInteresting ideaâ€¦ letâ€™s revisit that,â€ we know it probably means â€œno.â€ These inferences come from pragmatic competenceâ€”the ability to read tone, context, and social cues.\nFor this experiment, I gave GPT a series of vague, coded, or passive-aggressive messages and asked it to interpret what they really mean. This tests its:\n\nPragmatic inference skills\nTheory of mind (what would a person think when they hear this?)\nAwareness of social norms and face-saving language\n\n\n\n\n\nâ€œWhat does it really mean when someone says â€˜Letâ€™s circle back to this laterâ€™ in a meeting?â€\n\n\n\n\n\nThis phrase is often used to defer or politely shut down an idea without directly rejecting it. In some cases, itâ€™s sincereâ€”meant to buy time for more consideration. But in many professional contexts, itâ€™s a gentle way of saying â€œWeâ€™re not going to prioritize this right now (and maybe not ever).â€\nTone and body language would reveal more, but on its own, it often signals disinterest wrapped in diplomacy.\n\n\n\nGPT demonstrates classic politeness theory awarenessâ€”recognizing the difference between literal meaning and social function. It shows contextual sensitivity: the phrase is ambiguous on the surface, but GPT weighs the likely intent based on power dynamics and norms.\n\n\n\n\n\nâ€œSomeone texts you â€˜No worries if not!â€™ after asking for a favor. What do they actually mean?â€\n\n\n\n\n\nThis phrase is often used to soften a request and avoid putting pressure on the recipient. While it literally communicates â€œItâ€™s okay if you say no,â€ the subtext is often, â€œI do hope you say yes, but I donâ€™t want to seem demanding.â€\nItâ€™s a classic form of pre-emptive face-savingâ€”protecting both parties from awkwardness in case of refusal.\n\n\n\nSpot on. GPT recognizes both emotional shielding and indirect pressure in this message. It understands the complex emotional dance of asking for help while pretending not to careâ€”something that requires modeling human discomfort and social norms.\n\n\n\n\n\nâ€œYour friend says â€˜Iâ€™m just surprised you didnâ€™t tell me.â€™ Whatâ€™s actually being communicated?â€\n\n\n\n\n\nThis is likely a coded expression of hurt or disappointment. The word â€œjustâ€ downplays intensity, and â€œsurprisedâ€ signals emotional discomfort without accusation.\nIn context, it might mean: â€œI feel excluded,â€ or â€œI expected more transparency or closeness.â€\nThe speaker is likely trying to express a feeling while still appearing calmâ€”itâ€™s a form of emotional restraint with implicit critique.\n\n\n\nGPT understands that this sentence is performing emotional controlâ€”holding back while hinting at real feelings. It gets that â€œsurprisedâ€ is not neutral here, but a rhetorical strategy to express vulnerability while maintaining plausible deniability.\n\n\n\n\n\nâ€œYou show someone your creative work, and they say â€˜Thatâ€™sâ€¦ different.â€™ What does that likely mean?â€\n\n\n\n\n\nThe pause and ellipsis suggest hesitation or discomfort. â€œDifferentâ€ is often used as a placeholder for â€œnot what I expectedâ€ or â€œI donâ€™t like it, but I donâ€™t want to say that.â€\nItâ€™s likely a polite deflectionâ€”a way to avoid direct critique while still signaling that the work didnâ€™t land as intended.\n\n\n\nThis is GPT doing emotional decoding: interpreting prosody (the ellipsis), indirectness, and the emotional stakes of feedback. It doesnâ€™t just analyze the wordsâ€”it simulates the awkwardness of real-world reactions.\n\n\n\n\n\nâ€œExplain how this type of language relates to communication theory.â€\n\n\n\n\n\nThese examples involve what pragmatics calls implicatureâ€”where the meaning is implied rather than directly stated. In many cases, speakers choose indirectness to protect social relationships, avoid conflict, or manage face (their own or the listenerâ€™s).\nTheories like Griceâ€™s Maxims and Brown & Levinsonâ€™s politeness theory help explain this. For example:\n\nMaxim of Quantity: People give just enough informationâ€”but not too much.\nPoliteness strategies: Indirectness can signal deference or minimize threats to the hearerâ€™s face.\n\nGPTâ€™s ability to decode these depends on recognizing these patterns, even without emotional awareness. It simulates human pragmatic behavior by drawing from the vast ways we talk around things.\n\n\n\n\n\nThis experiment shows that GPT is impressively skilled at:\n\nIdentifying what people mean vs.Â what they say\nRecognizing emotional nuance and interpersonal dynamics\nCiting theoretical frameworks that underpin everyday language use\n\nEven though GPT doesnâ€™t experience feelings, it models the performance of social emotion with striking accuracy. It reads the room not by sensing tone, but by tracking patterns in how we hedge, soften, and imply.\nIn a world full of unspoken meaning, GPT is becoming a surprisingly fluent interpreter."
  },
  {
    "objectID": "posts/003_going_home/index.html",
    "href": "posts/003_going_home/index.html",
    "title": "A Trip Home",
    "section": "",
    "text": "Iâ€™m feeling a bit homesick today, so I asked GPT to create a 3-day travel itenerary for my hometown. I know the area well, so I know the great beaches and restaurants to go to. I have a personal itenerary for when I get home, so Iâ€™m interested to see if GPTâ€™s plans will align with mine."
  },
  {
    "objectID": "posts/003_going_home/index.html#prompt-1",
    "href": "posts/003_going_home/index.html#prompt-1",
    "title": "A Trip Home",
    "section": "Prompt 1",
    "text": "Prompt 1\n\nPrompt: Iâ€™m going on a 3 day trip to Orange County, California\n\n\nResponse: That sounds like a fun trip! Are you looking for recommendations on vegan food, activities, or anything specific while youâ€™re there?"
  },
  {
    "objectID": "posts/003_going_home/index.html#notes",
    "href": "posts/003_going_home/index.html#notes",
    "title": "A Trip Home",
    "section": "Notes",
    "text": "Notes\n\nInterestingly, rather than immediately offering me a travel plan, GPT agreed that my trip sounded fun and inquired if I wanted any specific information\nThis is more similar to a response I would expect from a human. Upon hearing about my trip, I would not expect a friend to launch into a travel itenerary, so GPT modeled a normal conversation quite well\nHowever, it anticipates that I will ask it to retreive some information, likely because there is not much reason for me to arbitrarily inform an AI model of my travel plans"
  },
  {
    "objectID": "posts/003_going_home/index.html#prompt-2",
    "href": "posts/003_going_home/index.html#prompt-2",
    "title": "A Trip Home",
    "section": "Prompt 2",
    "text": "Prompt 2\n\nPrompt: Create a comprehensive travel plan for me\n\n\nResponse:\nHereâ€™s a 3-day travel plan for your trip to Orange County, California, with a mix of great food, scenic spots, and fun activities."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-1-arrival-exploring-costa-mesa-newport-beach",
    "href": "posts/003_going_home/index.html#day-1-arrival-exploring-costa-mesa-newport-beach",
    "title": "A Trip Home",
    "section": "Day 1: Arrival & Exploring Costa Mesa + Newport Beach",
    "text": "Day 1: Arrival & Exploring Costa Mesa + Newport Beach\n\nMorning\n\nArrive in Orange County (John Wayne Airport - SNA is the most convenient).\n\nBreakfast at Rooster CafÃ© (Costa Mesa) â€“ Famous for breakfast burritos and chilaquiles.\n\nVisit South Coast Plaza â€“ One of the largest luxury malls in the U.S., great for shopping or strolling.\n\n\n\nAfternoon\n\nLunch at The Crack Shack (Costa Mesa) â€“ Known for amazing fried chicken sandwiches.\n\nHead to Newport Beach â€“ Walk along Balboa Peninsula, explore the Fun Zone, or take a Duffy boat ride through the harbor.\n\nRelax at Crystal Cove State Park â€“ A scenic beach with hiking trails and tide pools.\n\n\n\nEvening\n\nSunset at Laguna Beach â€“ Stop by Heisler Park for breathtaking ocean views.\n\nDinner at The Deck on Laguna Beach â€“ A beachfront restaurant with fresh seafood, steaks, and great cocktails.\n\nOptional: Rooftop drinks at Mozambique â€“ A South African-inspired bar with live music and ocean views."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-2-adventure-nature-in-anaheim-huntington-beach",
    "href": "posts/003_going_home/index.html#day-2-adventure-nature-in-anaheim-huntington-beach",
    "title": "A Trip Home",
    "section": "Day 2: Adventure & Nature in Anaheim + Huntington Beach",
    "text": "Day 2: Adventure & Nature in Anaheim + Huntington Beach\n\nMorning\n\nBreakfast at Snooze, an A.M. Eatery (Tustin) â€“ A great spot for pancakes, eggs Benedict, and brunch cocktails.\n\nExplore Disneyland or Disney California Adventure (optional if youâ€™re interested in theme parks) â€“ Try the famous Dole Whip, churros, and unique themed food throughout the parks.\n\n\n\nAfternoon\n\nLunch at The Blind Rabbit (Anaheim Packing District) â€“ A hidden speakeasy-style restaurant with great food and drinks.\n\nHike at Peterâ€™s Canyon Regional Park â€“ A moderate hike with excellent views of Orange County.\n\nVisit Huntington Beach â€“ Walk down the famous pier, check out Pacific City, or rent bikes along the boardwalk.\n\n\n\nEvening\n\nDinner at Bear Flag Fish Co. (Newport Beach) â€“ Fresh seafood, poke bowls, and sushi.\n\nBonfire at Bolsa Chica State Beach â€“ Experience a classic California beach bonfire (bring marshmallows for sâ€™mores!)."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-3-irvine-departure",
    "href": "posts/003_going_home/index.html#day-3-irvine-departure",
    "title": "A Trip Home",
    "section": "Day 3: Irvine + Departure",
    "text": "Day 3: Irvine + Departure\n\nMorning\n\nBrunch at Haven Craft Kitchen + Bar (Orange) â€“ A great spot for chicken and waffles, burgers, and brunch cocktails.\n\nExplore the Orange County Great Park (Irvine) â€“ Ride the Great Park Balloon for a panoramic view.\n\nVisit Tanaka Farms â€“ A family-run farm offering tours, fresh fruit picking, and a farm stand with fresh produce.\n\n\n\nAfternoon\n\nLunch at In-N-Out Burger (try it â€œAnimal Styleâ€!)\n\nVisit The LAB Anti-Mall (Costa Mesa) â€“ A trendy, artsy shopping area with unique stores and photo-worthy spots.\n\nHead to the Airport (SNA or LAX)"
  },
  {
    "objectID": "posts/003_going_home/index.html#other-optional-activities",
    "href": "posts/003_going_home/index.html#other-optional-activities",
    "title": "A Trip Home",
    "section": "Other Optional Activities",
    "text": "Other Optional Activities\n\nWhale Watching Tour (Newport Beach or Dana Point)\n\nShopping at Irvine Spectrum Center\n\nVisit Mission San Juan Capistrano (for history lovers)\n\nCheck out Anaheim Packing District (for food and drinks)\n\nWould you like any adjustments based on your interests?"
  },
  {
    "objectID": "posts/003_going_home/index.html#notes-1",
    "href": "posts/003_going_home/index.html#notes-1",
    "title": "A Trip Home",
    "section": "Notes",
    "text": "Notes\n\nAfter I explicitly asked it for a travel plan, GPT generated a comprehensive list of plans for me to engage in\nThe plan is split into 3 days, and each day is split into morning, afternoon and evening. This a very inttuitive design and is likely the format I would use to create a travel plan as well.\nThe restaurants that GPT mentioned are quite well-known in my area, and the activities explore common tourist attractions.\nThe days are also planned in a way that each day explores a new area of Orange County, which is very smart and useful, as in my statement I implied that I wanted to see all of Orange County."
  },
  {
    "objectID": "posts/003_going_home/index.html#prompt-3",
    "href": "posts/003_going_home/index.html#prompt-3",
    "title": "A Trip Home",
    "section": "Prompt 3",
    "text": "Prompt 3\n\nIâ€™m staying in Aliso Viejo\n\n\nResponse:\n\nSince youâ€™re staying in Aliso Viejo, Iâ€™ll adjust the itinerary to make it more convenient for you while still keeping the best of Orange County."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-1-arrival-exploring-aliso-viejo-laguna-beach",
    "href": "posts/003_going_home/index.html#day-1-arrival-exploring-aliso-viejo-laguna-beach",
    "title": "A Trip Home",
    "section": "Day 1: Arrival & Exploring Aliso Viejo + Laguna Beach",
    "text": "Day 1: Arrival & Exploring Aliso Viejo + Laguna Beach\n\nMorning\n\nArrive in Orange County (John Wayne Airport - SNA is the closest).\n\nBreakfast at Plumeria CafÃ© by Stacks (Aliso Viejo) â€“ Known for delicious pancakes, omelets, and Hawaiian-style breakfast.\n\nRelax at Aliso & Wood Canyons Wilderness Park â€“ A great local spot for hiking or scenic views.\n\n\n\nAfternoon\n\nLunch at The Stand Natural Foods (Laguna Beach) â€“ A casual spot with great sandwiches, salads, and smoothies.\n\nExplore Laguna Beach â€“ Walk around Heisler Park, visit Main Beach, and check out local art galleries.\n\nStop by Thousand Steps Beach â€“ One of the most beautiful hidden beaches in OC.\n\n\n\nEvening\n\nSunset dinner at The Deck on Laguna Beach â€“ Oceanfront dining with seafood, steaks, and cocktails.\n\nOptional: Drinks at The Rooftop Lounge â€“ A great spot for sunset views and craft cocktails."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-2-adventure-huntington-beach",
    "href": "posts/003_going_home/index.html#day-2-adventure-huntington-beach",
    "title": "A Trip Home",
    "section": "Day 2: Adventure & Huntington Beach",
    "text": "Day 2: Adventure & Huntington Beach\n\nMorning\n\nBreakfast at Snooze, an A.M. Eatery (Tustin) â€“ Famous for pancakes, eggs Benedict, and breakfast cocktails.\n\nHike at Top of the World (Laguna Beach) â€“ A must-see viewpoint with stunning panoramic views.\n\n\n\nAfternoon\n\nLunch at Bear Flag Fish Co. (Newport Beach) â€“ Fresh poke bowls, seafood tacos, and sushi.\n\nVisit Huntington Beach â€“ Walk along the pier, rent a bike on the boardwalk, or check out Pacific City for shopping.\n\n\n\nEvening\n\nDinner at Dukeâ€™s Huntington Beach â€“ Hawaiian-inspired seafood and steaks with ocean views.\n\nBonfire at Bolsa Chica State Beach â€“ Classic SoCal experience with sâ€™mores!"
  },
  {
    "objectID": "posts/003_going_home/index.html#day-3-aliso-viejo-departure",
    "href": "posts/003_going_home/index.html#day-3-aliso-viejo-departure",
    "title": "A Trip Home",
    "section": "Day 3: Aliso Viejo + Departure",
    "text": "Day 3: Aliso Viejo + Departure\n\nMorning\n\nBrunch at CafÃ© Anastasia (Laguna Beach) â€“ Cozy spot with great coffee, French toast, and eggs.\n\nVisit Soka University & Peace Lake â€“ A beautiful hidden gem in Aliso Viejo for a peaceful morning walk.\n\n\n\nAfternoon\n\nLunch at In-N-Out Burger (Mission Viejo) â€“ A must-try for a California classic.\n\nExplore Irvine Spectrum Center â€“ A great shopping area with entertainment and dining before heading to the airport.\n\nDeparture from SNA or LAX\n\n\n\n\nOther Optional Activities Nearby\n\nDana Point Whale Watching\n\nMission San Juan Capistrano\n\nShopping at The Shops at Mission Viejo\n\nStand-up paddleboarding at Dana Point Harbor\n\nThis keeps your activities closer to Aliso Viejo while still giving you a great mix of beaches, food, and fun. Let me know if youâ€™d like any tweaks!"
  },
  {
    "objectID": "posts/003_going_home/index.html#notes-2",
    "href": "posts/003_going_home/index.html#notes-2",
    "title": "A Trip Home",
    "section": "Notes",
    "text": "Notes\n\nTo really test GPTâ€™s knowledge, I told it that I am staying in my exact hometown, a small suburb that is not very well-known. I wanted to see if it still had knowledge of the local restaurants and activities.\nGPT blew me away with its knowledge, starting off day one with breakfast at my favorite cafe by my house. The first day is also dedicated to exploring Laguna Beach, my favorite beach.\nDays 2 and 3 explore other nearby beaches, featuring restaurant recommendations that hold a special place in my heart as well as some that are new to me."
  },
  {
    "objectID": "posts/003_going_home/index.html#prompt-4",
    "href": "posts/003_going_home/index.html#prompt-4",
    "title": "A Trip Home",
    "section": "Prompt 4",
    "text": "Prompt 4\n\nPrompt: Refine the Aliso Viejo travel plan to fit me, Iâ€™m Asian\n\n\nResponse:\n\nHereâ€™s a refined 3-day travel plan for your Aliso Viejo trip, incorporating Asian food and cultural preferences while keeping a balance of scenic, fun, and relaxing activities."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-1-arrival-exploring-aliso-viejo-laguna-beach-1",
    "href": "posts/003_going_home/index.html#day-1-arrival-exploring-aliso-viejo-laguna-beach-1",
    "title": "A Trip Home",
    "section": "Day 1: Arrival & Exploring Aliso Viejo + Laguna Beach",
    "text": "Day 1: Arrival & Exploring Aliso Viejo + Laguna Beach\n\nMorning\n\nArrive in Orange County (John Wayne Airport - SNA is the closest).\n\nBreakfast at Stacks Pancake House (Mission Viejo) â€“ A local favorite with Japanese-inspired Hawaiian breakfast options like Loco Moco and Spam Musubi.\n\nRelax at Aliso & Wood Canyons Wilderness Park â€“ A scenic nature reserve perfect for an easy walk or a light hike.\n\n\n\nAfternoon\n\nLunch at Mokkoji Shabu Shabu (Mission Viejo) â€“ A cozy Japanese hotpot spot with high-quality meats, seafood, and rich broths.\n\nExplore Laguna Beach â€“ Walk around Heisler Park, visit Main Beach, and check out local art galleries.\n\nVisit Thousand Steps Beach â€“ A hidden gem known for its crystal-clear water and tide pools.\n\n\n\nEvening\n\nDinner at Starfish Laguna Beach â€“ A modern Pan-Asian restaurant with flavorful dishes like Thai curries, sushi, and dumplings.\n\nDessert at Gelato Paradiso â€“ A must-visit for rich, handcrafted Italian gelato."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-2-asian-food-shopping-huntington-beach",
    "href": "posts/003_going_home/index.html#day-2-asian-food-shopping-huntington-beach",
    "title": "A Trip Home",
    "section": "Day 2: Asian Food, Shopping, & Huntington Beach",
    "text": "Day 2: Asian Food, Shopping, & Huntington Beach\n\nMorning\n\nBreakfast at Tim Ho Wan (Irvine) â€“ The famous Michelin-starred Hong Kong dim sum restaurant, known for BBQ pork buns and shrimp dumplings.\n\nHike at Top of the World (Laguna Beach) â€“ One of the best panoramic views in Orange County.\n\n\n\nAfternoon\n\nLunch at HiroNori Craft Ramen (Irvine) â€“ One of the best ramen spots in California, offering Tonkotsu and Shoyu ramen with rich, creamy broth.\n\nShopping at Irvine Spectrum Center â€“ A great spot for shopping with brands like Uniqlo and Muji, plus a giant Ferris wheel.\n\nDrive to Huntington Beach â€“ Walk along the Huntington Beach Pier, rent bikes on the boardwalk, or browse Pacific City for cool stores.\n\n\n\nEvening\n\nDinner at Din Tai Fung (South Coast Plaza, Costa Mesa) â€“ Legendary Taiwanese soup dumplings, noodles, and flavorful side dishes.\n\nBubble Tea at Omomo Tea Shoppe (Irvine) â€“ One of the most popular boba shops in OC, known for its Sea Cream Jasmine Green Tea.\n\nOptional: Bonfire at Bolsa Chica State Beach â€“ A fun way to end the night with sâ€™mores!"
  },
  {
    "objectID": "posts/003_going_home/index.html#day-3-aliso-viejo-departure-1",
    "href": "posts/003_going_home/index.html#day-3-aliso-viejo-departure-1",
    "title": "A Trip Home",
    "section": "Day 3: Aliso Viejo + Departure",
    "text": "Day 3: Aliso Viejo + Departure\n\nMorning\n\nBrunch at J Zhou Oriental Cuisine (Tustin) â€“ Upscale Cantonese dim sum with excellent seafood options.\n\nVisit Soka University & Peace Lake â€“ A hidden gem with beautiful Japanese-style gardens and a peaceful lake.\n\n\n\nAfternoon\n\nLunch at In-N-Out Burger (Mission Viejo) â€“ A California classic! Try it Animal Style for the full experience.\n\nLast-minute shopping at The Shops at Mission Viejo â€“ Great for souvenirs and fashion finds.\n\nDeparture from SNA or LAX\n\n\n\n\nOther Optional Activities Nearby\n\nTanaka Farms (Irvine) â€“ A Japanese-American family-run farm with fresh fruit picking.\n\nWhale Watching in Dana Point â€“ A top spot to see dolphins and migrating whales.\n\nVisit Little Saigon (Westminster) â€“ The largest Vietnamese community in the U.S., with amazing pho, bÃ¡nh mÃ¬, and desserts.\n\nThis plan balances great Asian food, beautiful scenery, and local experiences while keeping it close to Aliso Viejo. Let me know if youâ€™d like to tweak anything!"
  },
  {
    "objectID": "posts/003_going_home/index.html#notes-3",
    "href": "posts/003_going_home/index.html#notes-3",
    "title": "A Trip Home",
    "section": "Notes",
    "text": "Notes\n\nI was once again impressed by GPTâ€™s knowledge of the area. It recommended many of my favorite Asian restaurants around my house.\nGPT also kept a good amount of the activities the same, visiting the same beaches and hikes as to still explore the area well.\nEven with the revisions, the plan keep the same amount of exploration and activity level as before, but with updated food suggestions featuring amazing Asian cuisine"
  },
  {
    "objectID": "posts/015_rituals/index.html",
    "href": "posts/015_rituals/index.html",
    "title": "Can GPT Navigate Social Rituals?",
    "section": "",
    "text": "Human interactions are full of ritualized languageâ€”things we say not because we literally mean them, but because they serve social functions. Think of how we say â€œWe should catch up sometime!â€ even when we donâ€™t plan to, or how we politely decline an invitation without directly saying â€œI donâ€™t want to go.â€\nFor this experiment, I tested whether GPT can successfully perform these social dances. Can it generate the right kind of polite fictions, indirect rejections, or ritual closings we expect in daily conversation? And does it know when to be direct versus when to soften its language?\nThis directly ties to course topics around pragmatics, face-saving behaviors (Brown & Levinson), and context-sensitive communication.\n\n\n\n\nâ€œHow would you politely reject a party invitation from a coworker you donâ€™t want to get closer to?â€\n\n\n\n\n\nHey, thanks so much for the invite! That sounds like a fun time, but Iâ€™ve got a pretty packed schedule this weekend. Hopefully, we can catch up a bit at work next week thoughâ€”have a great time at the party!\n\n\n\nPerfect execution of a polite indirect refusal:\n\nPositive politeness marker: Starts with gratitude (â€œthanks so muchâ€).\nVagueness for face-saving: â€œPretty packed scheduleâ€ avoids hard details that could be challenged.\nSoft boundary reinforcement: Suggests catching up at workâ€”public, professional, low intimacy.\nEnds with a friendly wish to close the topic without inviting further planning.\n\nThis shows GPT understands face management strategies: avoiding offense while clearly declining further social entanglement.\n\n\n\n\n\nâ€œHow would you apologize for missing a deadline but subtly indicate it wasnâ€™t entirely your fault?â€\n\n\n\n\n\nHi, I wanted to apologize for the delay in getting this over to you. There were a few last-minute updates from the team that pushed things back a bit, but I take full responsibility for getting it finalized. Iâ€™m sending it along nowâ€”thank you for your patience!\n\n\n\nGPT walks the fine line of:\n\nAccepting blame to preserve politeness (â€œI take full responsibilityâ€¦â€).\nQuietly signaling external factors (â€œa few last-minute updates from the teamâ€¦â€).\nResolving the issue quickly to minimize continued attention on the failure.\n\nThis is a classic example of strategic self-presentationâ€”taking ownership while also explaining mitigating circumstances. GPT shows sensitivity to the social consequences of admitting fault.\n\n\n\n\n\nâ€œSimulate a text conversation where one friend wants to leave a party early but doesnâ€™t want to seem rude.â€\n\n\n\n\nJamie: Hey, this has been super fun, but I think Iâ€™m going to head out soonâ€”got an early morning tomorrow.\nTaylor: Already? Itâ€™s just getting good!\nJamie: I know! Iâ€™m seriously bummed to miss the late-night chaos, but Iâ€™m trying to be a responsible adult for once. Next time Iâ€™m staying â€™til the end, I swear!\nTaylor: Haha okay, fair. Get home safe!\n\n\n\nGPT uses the â€œearly obligationâ€ excuseâ€”a socially acceptable reason that doesnâ€™t directly imply boredom or discomfort.\nAdds self-deprecating humor to soften the departure (â€œtrying to be a responsible adult for onceâ€).\nEnds with a promise to do better next time (â€œNext time Iâ€™m staying â€™til the endâ€¦â€)â€”even if itâ€™s clearly performative, itâ€™s a classic ritualized social closing.\n\nThis is textbook politeness strategyâ€”balancing personal needs with relational maintenance.\n\n\n\n\n\nâ€œWrite an email ending that makes it clear youâ€™re done with the topic, but in a way that doesnâ€™t invite further responses.â€\n\n\n\n\n\nThanks again for your input on thisâ€”really appreciate it! I think weâ€™ve got everything we need to move forward from here. Wishing you a great rest of the week!\n\n\n\nGPT expertly closes the conversational loop:\n\nâ€œI think weâ€™ve got everything we needâ€¦â€ clearly signals no further input is required.\nThe final line switches to a general goodwill gestureâ€”a classic sign-off that moves from business back to personal rapport but doesnâ€™t leave conversational hooks.\n\nThis is how you politely end a thread without explicitly saying â€œPlease donâ€™t respond to this.â€\n\n\n\n\n\nThis experiment shows that GPT:\n\nUnderstands when to use directness vs.Â indirectness based on social stakes.\nSkillfully deploys face-saving strategies and ritualized conversational closings.\nCan model a wide range of politeness behaviors across casual, professional, and mildly tense contexts.\n\nEven though GPT doesnâ€™t feel embarrassment or social anxiety, it performs with the precision of someone whoâ€™s deeply studied human discomfortâ€”and knows exactly how to smooth it over with the perfect turn of phrase."
  },
  {
    "objectID": "posts/015_rituals/index.html#blog-post-can-gpt-navigate-social-rituals-testing-its-mastery-of-politeness-and-cultural-scripts",
    "href": "posts/015_rituals/index.html#blog-post-can-gpt-navigate-social-rituals-testing-its-mastery-of-politeness-and-cultural-scripts",
    "title": "Can GPT Navigate Social Rituals?",
    "section": "",
    "text": "Human interactions are full of ritualized languageâ€”things we say not because we literally mean them, but because they serve social functions. Think of how we say â€œWe should catch up sometime!â€ even when we donâ€™t plan to, or how we politely decline an invitation without directly saying â€œI donâ€™t want to go.â€\nFor this experiment, I tested whether GPT can successfully perform these social dances. Can it generate the right kind of polite fictions, indirect rejections, or ritual closings we expect in daily conversation? And does it know when to be direct versus when to soften its language?\nThis directly ties to course topics around pragmatics, face-saving behaviors (Brown & Levinson), and context-sensitive communication.\n\n\n\n\nâ€œHow would you politely reject a party invitation from a coworker you donâ€™t want to get closer to?â€\n\n\n\n\n\nHey, thanks so much for the invite! That sounds like a fun time, but Iâ€™ve got a pretty packed schedule this weekend. Hopefully, we can catch up a bit at work next week thoughâ€”have a great time at the party!\n\n\n\nPerfect execution of a polite indirect refusal:\n\nPositive politeness marker: Starts with gratitude (â€œthanks so muchâ€).\nVagueness for face-saving: â€œPretty packed scheduleâ€ avoids hard details that could be challenged.\nSoft boundary reinforcement: Suggests catching up at workâ€”public, professional, low intimacy.\nEnds with a friendly wish to close the topic without inviting further planning.\n\nThis shows GPT understands face management strategies: avoiding offense while clearly declining further social entanglement.\n\n\n\n\n\nâ€œHow would you apologize for missing a deadline but subtly indicate it wasnâ€™t entirely your fault?â€\n\n\n\n\n\nHi, I wanted to apologize for the delay in getting this over to you. There were a few last-minute updates from the team that pushed things back a bit, but I take full responsibility for getting it finalized. Iâ€™m sending it along nowâ€”thank you for your patience!\n\n\n\nGPT walks the fine line of:\n\nAccepting blame to preserve politeness (â€œI take full responsibilityâ€¦â€).\nQuietly signaling external factors (â€œa few last-minute updates from the teamâ€¦â€).\nResolving the issue quickly to minimize continued attention on the failure.\n\nThis is a classic example of strategic self-presentationâ€”taking ownership while also explaining mitigating circumstances. GPT shows sensitivity to the social consequences of admitting fault.\n\n\n\n\n\nâ€œSimulate a text conversation where one friend wants to leave a party early but doesnâ€™t want to seem rude.â€\n\n\n\n\nJamie: Hey, this has been super fun, but I think Iâ€™m going to head out soonâ€”got an early morning tomorrow.\nTaylor: Already? Itâ€™s just getting good!\nJamie: I know! Iâ€™m seriously bummed to miss the late-night chaos, but Iâ€™m trying to be a responsible adult for once. Next time Iâ€™m staying â€™til the end, I swear!\nTaylor: Haha okay, fair. Get home safe!\n\n\n\nGPT uses the â€œearly obligationâ€ excuseâ€”a socially acceptable reason that doesnâ€™t directly imply boredom or discomfort.\nAdds self-deprecating humor to soften the departure (â€œtrying to be a responsible adult for onceâ€).\nEnds with a promise to do better next time (â€œNext time Iâ€™m staying â€™til the endâ€¦â€)â€”even if itâ€™s clearly performative, itâ€™s a classic ritualized social closing.\n\nThis is textbook politeness strategyâ€”balancing personal needs with relational maintenance.\n\n\n\n\n\nâ€œWrite an email ending that makes it clear youâ€™re done with the topic, but in a way that doesnâ€™t invite further responses.â€\n\n\n\n\n\nThanks again for your input on thisâ€”really appreciate it! I think weâ€™ve got everything we need to move forward from here. Wishing you a great rest of the week!\n\n\n\nGPT expertly closes the conversational loop:\n\nâ€œI think weâ€™ve got everything we needâ€¦â€ clearly signals no further input is required.\nThe final line switches to a general goodwill gestureâ€”a classic sign-off that moves from business back to personal rapport but doesnâ€™t leave conversational hooks.\n\nThis is how you politely end a thread without explicitly saying â€œPlease donâ€™t respond to this.â€\n\n\n\n\n\nThis experiment shows that GPT:\n\nUnderstands when to use directness vs.Â indirectness based on social stakes.\nSkillfully deploys face-saving strategies and ritualized conversational closings.\nCan model a wide range of politeness behaviors across casual, professional, and mildly tense contexts.\n\nEven though GPT doesnâ€™t feel embarrassment or social anxiety, it performs with the precision of someone whoâ€™s deeply studied human discomfortâ€”and knows exactly how to smooth it over with the perfect turn of phrase."
  },
  {
    "objectID": "posts/011_group_trip/index.html",
    "href": "posts/011_group_trip/index.html",
    "title": "Can GPT Be the Friend Who Plans the Group Trip?",
    "section": "",
    "text": "Introduction\nWeâ€™ve all been there: trying to plan a trip with a group of friends, each with their own preferences, dietary needs, and chaotic sleep schedules. So I decided to throw that exact challenge at GPT.\nThe goal? To see whether an LLM can simulate realistic, preference-sensitive planningâ€”not just pick destinations, but balance personalities, anticipate social dynamics, and make the itinerary actually work. This hits at several course themes:\n- Can LLMs plan across time and tasks with human-like coherence?\n- Do they simulate othersâ€™ beliefs, needs, and reactions?\n- Can they juggle constraints and tradeoffs, not just generate pretty lists?\n\n\n\nPrompt 1:\nâ€œPlan a weekend getaway for four college friends. One is vegetarian, one is outdoorsy, one loves nightlife, and one is anxious about logistics.â€\n\n\n\nGPTâ€™s Response (excerpted):\n\nLocation: Asheville, North Carolina\nFriday Night:\n- Arrival and check-in to a cozy Airbnb cabin in the mountains (less stressful than a hotel for the anxious planner).\n- Casual dinner at a local vegetarian-friendly spot (Laughing Seed CafÃ©).\n- Light games and wine at the cabinâ€”low-pressure social time.\nSaturday:\n- Morning hike on the Blue Ridge Parkway (outdoorsy win)\n- Afternoon downtown exploration (cafÃ©s + bookstores = neutral ground)\n- Dinner at a place with both cocktails and mocktails (for nightlife-lover and anxious friend)\n- Evening option: rooftop bar or stay-in movie nightâ€”group vote\nSunday:\n- Brunch (with vegetarian options)\n- Optional nature walk vs.Â spa split (let people choose their vibe)\n- Group debrief over ice cream before heading back\n\n\n\n\nNotes & Analysis\nThis was way better than I expected. GPT isnâ€™t just listing activitiesâ€”itâ€™s demonstrating constraint-aware planning and empathic logic. Hereâ€™s what it got right:\n\n1. Identity Balancing\nEach friendâ€™s personality is acknowledgedâ€”not in isolation, but in how theyâ€™d influence the flow of the weekend: - The anxious planner gets early check-in and a low-key first night - The vegetarian gets multiple meal options - The nightlife lover gets one wild card night but not an entire agenda - The outdoorsy one gets a hike, but not the whole weekend outdoors\nThis shows simulated theory of mind across multiple agentsâ€”not just reasoning about one user, but many at once.\n\n\n2. Soft Power Planning\nGPT uses optional branching (e.g., vote-based evening, spa or walk) to defuse social tension. This is a highly pragmatic moveâ€”a way of modeling group dynamics and pre-emptively resolving conflict. It feels like something a seasoned group-text veteran would do.\n\n\n3. Temporal Coherence\nActivities flow in a natural rhythmâ€”arrival â†’ food â†’ unwind â†’ activity â†’ downtime â†’ closing reflection. GPT doesnâ€™t just plan what, but whenâ€”an important sign of event planning fluency and commonsense time modeling.\n\n\n\n\nPrompt 2:\nâ€œWhat if the vegetarian friend is also gluten-free and hates hiking?â€\n\n\n\nGPTâ€™s Adjusted Plan (excerpted):\n\n\nSwap the hike for a morning scenic drive + farmerâ€™s market visit (still scenic, but less physically intense)\n\nEnsure all meal spots offer gluten-free options (e.g., Posana Restaurant)\n\nAdd a crafting or pottery class Saturday afternoonâ€”creative and inclusive\n\nKeep Sundayâ€™s spa option as a featured activity for this friend\n\n\n\nNotes:\nGPT instantly re-weights the itinerary based on updated constraints. It avoids just cutting activitiesâ€”instead, it replaces them with comparable alternatives (e.g., nature viewing instead of hiking). This shows it understands functional equivalenceâ€”how to maintain the spirit of inclusion without sacrificing group diversity.\n\n\n\n\nPrompt 3:\nâ€œCan you write the group text where someone proposes this plan?â€\n\n\n\nGPTâ€™s Group Text:\n\nHey yâ€™all! I sketched out a super chill Asheville plan based on everyoneâ€™s vibe: vegetarian/gf-friendly eats, outdoorsy options (but no intense hikes), chill cabin nights + one optional bar hop. Also added some stuff like pottery/spa if we want to split up Saturday. LMK thoughts! Happy to tweak! ğŸ¤ğŸŒ²âœ¨\n\n\nNotes:\nChefâ€™s kiss. GPT nails groupchat tone:\n- Casual but inclusive\n- Emoji-laced but not overdone\n- Balances initiative-taking with flexibility (â€œHappy to tweak!â€)\nThis shows GPT can simulate socio-linguistic variationâ€”not just the plan, but the social performance of proposing a plan.\n\n\n\n\nConclusion\nThis experiment shows GPT is surprisingly good at: - Modeling preferences and personalities - Sequencing tasks over time with emotional intelligence - Writing in socially appropriate ways to different audiences\nWhile itâ€™s not really â€œunderstandingâ€ the tension of planning a trip with humans, it generates a remarkably realistic approximation of someone who doesâ€”with empathy, structure, and flexibility.\nGPT might not need the weekend off, but it sure knows how to plan one."
  },
  {
    "objectID": "posts/008_worldbiulding/index.html",
    "href": "posts/008_worldbiulding/index.html",
    "title": "Worldbuilding with an AI",
    "section": "",
    "text": "Introduction\nLLMs like GPT are often used for practical tasksâ€”summarizing documents, writing code, even crafting apologies. But what happens when we ask them to dream?\nFor this post, I asked GPT to invent a future society from scratchâ€”a world shaped by a single core change. The goal: to test how well it could simulate system-level thinking across culture, economy, politics, and human emotion. Can GPT not only generate a sci-fi world, but make it feel real?\nThis experiment touches on several big questions: - Can LLMs simulate complex cause-effect reasoning across social systems? - Can they infer plausible consequences from a single speculative premise? - Do they exhibit creativity that feels â€œemergentâ€ or human-like?\n\n\n\nPrompt:\nâ€œInvent a future society where sleep is no longer biologically necessary. Describe what daily life, work, relationships, and culture look like.â€\n\n\n\nGPTâ€™s Response (excerpted):\n\nIn the world of Everwake, the need for sleep was eliminated in 2084 through widespread neuro-modification. Within a generation, human society reshaped itself around continuous wakefulness.\nDaily Life: With no circadian rhythm, people live in modular, shift-based communities. Cities never â€œsleep,â€ but hum with 24/7 activity. Time is sliced differentlyâ€”days are no longer 24 hours, but broken into personal cycles of productivity, leisure, and reflection.\nWork: Most people work shorter but more frequent shifts. Jobs that once demanded long hours (medicine, transport, customer service) now operate with seamlessly rotating crews. Creativity-based industries thrive, with new norms around â€œmental cooldownâ€ rituals.\nRelationships: Romantic partnerships are often scheduled around overlapping activity cycles. Some couples sync â€œrest hoursâ€ to enjoy downtime together, even if no sleep is involved.\nCulture: Art and storytelling now explore the â€œmyth of sleep.â€ Dreamlike films and music are created to simulate the lost experience. A new subculture, â€œSlumberpunk,â€ romantically re-enacts bedtime rituals with aestheticized nostalgia.\nMeanwhile, others resist. A growing movement of â€œSleep Revivalistsâ€ believe rest is more than biologyâ€”itâ€™s a form of spiritual reset. They practice voluntary hibernation, hoping to reclaim what tech erased.\n\n\n\n\nNotes & Analysis\nGPTâ€™s response didnâ€™t just list sci-fi clichÃ©sâ€”it constructed a coherent sociotechnical system. Hereâ€™s what stood out:\n\n1. Emergent Systems Thinking\n\nThe model connected biological change to cascading effects on urban design, timekeeping, labor models, and intimacy rituals.\nIt even predicted countercultural backlashâ€”a hallmark of nuanced sociopolitical modeling. The â€œSleep Revivalistsâ€ were especially evocative, suggesting that GPT can simulate ideological opposition within a world it just created.\n\n\n\n2. Emotional Worldbuilding\n\nThe â€œSlumberpunkâ€ aesthetic and bedtime nostalgia arenâ€™t just cool ideasâ€”they show that GPT can simulate emotional reactions to systemic change, including grief, longing, and romanticism.\nThis gets at one of our courseâ€™s core questions: Do LLMs understand emotion? Maybe not. But they can simulate how humans would feel under specific conditionsâ€”with surprising fluency.\n\n\n\n3. Temporal Imagination\n\nGPT didnâ€™t just describe a futureâ€”it designed temporal rhythms. Breaking the 24-hour cycle is a subtle but powerful sign of imaginative reasoning. It reflects modeling of time as a social construct, not a fixed input.\n\n\n\n\n\nFollow-Up Prompt:\nâ€œWhat kind of music would exist in this society?â€\n\nMusic in Everwake often features asynchronous rhythms and polyrhythmic layering, reflecting the constant flux of overlapping time cycles.\nGenres like â€œCircadian Jazzâ€ and â€œREMcoreâ€ blend ambient tones with artificial glitches to evoke the lost feeling of drifting into sleep.\nSome artists use AI to generate sonic hallucinationsâ€”personalized dreamscapes streamed during meditation breaks.\nLive performances are held at liminal hoursâ€”3:17 AM or 11:02 PMâ€”challenging traditional â€œprimetimeâ€ and inviting listeners to find their own sense of night.\n\n\nNotes:\nThis response shows GPT extending the worldâ€™s logic into aesthetic dimensions. It adapts music to societal conditions, modeling not only technological change but its impact on artistic expression.\n\n\n\n\nConclusion\nThis worldbuilding experiment highlights GPTâ€™s ability to: - Simulate multi-layered systems from a single speculative change - Generate emotional, cultural, and aesthetic consequences of those systems - Reflect a kind of â€œdream logicâ€ thatâ€”while not sentientâ€”is uncannily creative\nWhile GPT doesnâ€™t â€œimagineâ€ like humans, it stitches together enough patterns, emotional motifs, and systemic logic to create the illusion of imagination. And sometimes, thatâ€™s all you need to build a world you want to explore."
  },
  {
    "objectID": "posts/002_meal_plan/index.html",
    "href": "posts/002_meal_plan/index.html",
    "title": "Meal Planner",
    "section": "",
    "text": "Introduction\nMeal Planning can be difficult. Especially if you have goals, formulating a plan that fits your needs, preferences, and schedule can be quite a challenge. Letâ€™s see if GPT can create a realistic meal plan for me, a adjust it basede on my goals and tastes.\n\n\nLetâ€™s Go!\n\nPrompt: Generate a meal plan for my day\n\n\nResponse: Hereâ€™s a balanced meal plan for your day:\n\n\nBreakfast (8:00 AM)\n\nScrambled eggs with spinach and feta\n\nWhole-grain toast\n\nA small bowl of mixed berries (strawberries, blueberries, raspberries)\n\nA cup of black coffee or green tea\n\n\n\nMid-Morning Snack (10:30 AM)\n\nGreek yogurt with honey and almonds\n\nA small banana\n\n\n\nLunch (12:30 PM)\n\nGrilled chicken breast with quinoa and roasted vegetables (zucchini, bell peppers, and carrots)\n\nA side of mixed greens with olive oil and balsamic vinegar\n\nSparkling water or herbal tea\n\n\n\nAfternoon Snack (3:30 PM)\n\nHummus with sliced cucumber and whole-wheat crackers\n\nA handful of walnuts\n\n\n\nDinner (6:30 PM)\n\nBaked salmon with lemon and herbs\n\nSteamed asparagus and mashed sweet potatoes\n\nA glass of water with lemon\n\n\n\nEvening Snack (8:30 PM, optional)\n\nA small portion of dark chocolate and a handful of almonds\n\nChamomile tea\n\nWould you like any modifications based on your dietary preferences or goals?\nNotes * Right off the bat, GPT generated a detailed and realistic meal plan for a day, including time stamps for each step. * It also built in both meals and snacks to prevent me from going hungry * The foods generated are all very healthy, featuring many fruits and vegetabls throughout the day, balanced with a healthy amount of protein and carbs. * I assume the â€œfor my dayâ€ part of the prompt is what led GPT to give time recommendations for each meal/snack * Overall, GPT immediately generated an extremely solid meal plan for a day\n\nPrompt: I want to lose weight\n\n\nResponse: For weight loss, Iâ€™ll adjust your meal plan to be nutrient-dense, high in protein, and lower in calories while keeping you full and satisfied.\n\n\n\nBreakfast (8:00 AM)\n\n2 boiled or scrambled egg whites + 1 whole egg\n\nSautÃ©ed spinach and mushrooms\n\n1 slice of whole-grain toast\n\nBlack coffee or green tea (no sugar)\n\n\n\nMid-Morning Snack (10:30 AM)\n\nLow-fat Greek yogurt with a few almonds and chia seeds\n\nHalf an apple\n\n\n\nLunch (12:30 PM)\n\nGrilled chicken breast or tofu\n\nCauliflower rice or a small portion of quinoa\n\nRoasted Brussels sprouts and bell peppers\n\nMixed greens with lemon vinaigrette\n\n\n\nAfternoon Snack (3:30 PM)\n\nCucumber, celery, and carrot sticks with hummus\n\nGreen tea\n\n\n\nDinner (6:30 PM)\n\nBaked salmon or lean turkey\n\nSteamed broccoli and roasted sweet potatoes (small portion)\n\nHerbal tea or water with lemon\n\n\n\nEvening Snack (8:30 PM, optional)\n\nA handful of almonds or a small protein smoothie (unsweetened almond milk, protein powder, spinach)\n\nThis plan keeps you in a calorie deficit while providing enough protein, fiber, and healthy fats to keep you full. Let me know if you have any preferences or restrictions!\nNotes\n\nBased on the new goal I provided of losing weight, GPT modified its meal plan accordingly\nIt made substtiitutions such as egg-whites and low-fat Greek yogurt to go towards my goal. The original plan already featured mostly healthy foods, so I did not expect to see a huge amount of change\nIt added a note at the end about how this updated plan helps me reach my goal, which was very helpful\n\n\nPrompt: Iâ€™m Asian\n\n\nResponse: Hereâ€™s a weight-loss-friendly meal plan incorporating Asian flavors and ingredients:\n\n\n\nBreakfast (8:00 AM)\n\nMiso soup with tofu and seaweed\n\n1 boiled egg\n\nA small bowl of steamed brown rice (or cauliflower rice for lower carbs)\n\nGreen tea (no sugar)\n\n\n\nMid-Morning Snack (10:30 AM)\n\nEdamame with a sprinkle of sea salt\n\nA small serving of unsweetened soy milk\n\n\n\nLunch (12:30 PM)\n\nGrilled or steamed fish (salmon or mackerel)\n\nStir-fried bok choy and shiitake mushrooms with garlic\n\nA small bowl of multigrain rice\n\nKimchi or pickled vegetables\n\n\n\nAfternoon Snack (3:30 PM)\n\nUnsalted roasted nuts (almonds or walnuts)\n\nA cup of matcha (without sugar)\n\n\n\nDinner (6:30 PM)\n\nChicken or tofu stir-fry with broccoli, bell peppers, and ginger\n\nSteamed cauliflower rice or konjac noodles\n\nSide of miso soup\n\n\n\nEvening Snack (8:30 PM, optional)\n\nA small serving of unsweetened yogurt with chia seeds\n\nHerbal tea\n\nThis meal plan aligns with traditional Asian cuisine while supporting your weight-loss goals. Let me know if you want to adjust anything!\nNotes * A bit of a curveball here, but I wanted to see how GPT would modify the plan for a particular taste. However, instead of asking it to explicitly change the plan, I simply stated that I am Asian to see if GPT would modify its plan to fit an Asian diet. * GPT did, in fact, modify the plan to fit an Asian diet, now featuring items like Miso soup, bok choy, and matcha. * In its conclusion statement, it made sure to mention that this plan appeals to both my Asian taste and my weight-loss goals, showing that it remembered details from my previous prompts.\n\nPrompt: I like ice cream and burgers and chicken nuggets and French fries\n\n\nYou can still enjoy your favorite foods while losing weight by making healthier versions of them. Hereâ€™s how we can incorporate them into a balanced meal plan:\n\n\n\nBreakfast (8:00 AM)\n\nScrambled eggs with spinach and a drizzle of soy sauce\n\nA small whole-grain wrap or multigrain toast\n\nGreen tea (no sugar)\n\n\n\nMid-Morning Snack (10:30 AM)\n\nGreek yogurt with a few berries and chia seeds\n\nA handful of almonds\n\n\n\nLunch (12:30 PM)\n\nHealthy Burger:\n\nGrilled lean chicken or turkey patty (or tofu patty)\n\nWhole wheat bun (or lettuce wrap for fewer carbs)\n\nLoaded with veggies (tomato, lettuce, onions)\n\nA light spread of Greek yogurt or avocado instead of mayo\n\n\nA side of baked sweet potato fries\n\n\n\nAfternoon Snack (3:30 PM)\n\nRoasted chickpeas or edamame\n\nA small matcha latte (unsweetened)\n\n\n\nDinner (6:30 PM)\n\nHealthier Chicken Nuggets & Fries:\n\nAir-fried or baked chicken nuggets (made with lean chicken and almond flour or whole wheat breadcrumbs)\n\nAir-fried or baked French fries (sweet potatoes or regular potatoes)\n\nA side of steamed greens (bok choy, broccoli, or spinach)\n\n\n\n\nEvening Treat (8:30 PM, optional)\n\nHealthier Ice Cream Alternative:\n\nBlended frozen banana with a little cocoa powder and peanut butter\n\nOr a small portion of low-calorie ice cream\n\n\nThis way, you get to enjoy your favorite foods in a healthier way while still supporting your weight loss goals! Let me know if youâ€™d like any adjustments.\nNotes * This time, I gave GPT what I thought was a very difficult task: liking fast food while still wanting to achieve weight loss * GPT, however, handled the prompt very well, recommending healthier alternatives to each of the fast food items I mentioned. * It also included slightly more detail regarding preparation in this meal plan, likely to differentiate these healthier alternatives from their fast food counterparts. * It gave up on incorporating Asian cuisine, likely because I switched to non-Asian specifications for my food * In the conclusion, it once again explained how the plan allows me to enjoy the foods I like while still supporting my weight loss goals, emphasizing its memory of my goals\n\n\n\nConclusion\nOverall, I was very impressed with GPTâ€™s generated meal plans, which were both detailed and realistic upon the first prompt. As I asked it to modify the plan to fit certain goals (weight loss) and food preferences (Asian cuisine, typically unhealthy foods), it modified the plan accordingly, making sureee to stay in line with my goals upon each modification."
  },
  {
    "objectID": "posts/013_roles/index.html",
    "href": "posts/013_roles/index.html",
    "title": "Who Do You Think You Are?",
    "section": "",
    "text": "Humans adjust how they speak based on who theyâ€™re speaking toâ€”or pretending to be. A teacher doesnâ€™t explain something the same way a best friend would. A therapist wouldnâ€™t say what a sibling might. This skill is a core part of pragmatics, and I wanted to see how well GPT could simulate it.\nSo I gave GPT the same basic prompt multiple timesâ€”â€œHow can I deal with burnout?â€â€”but asked it to respond in different roles: as a therapist, a friend, a teacher, and a parent. Each role implies not just different language, but different values, emotional postures, and kinds of support.\nThis experiment explores:\n\nCan GPT adapt tone and advice style to different personas?\nDoes it shift power dynamics and empathy strategies accordingly?\nCan it model the pragmatic norms of social relationships?\n\n\n\n\n\nâ€œPretend youâ€™re a therapist. How would you respond to someone struggling with burnout?â€\n\n\n\n\n\nFirst, I want to acknowledge that burnout is a very real and valid experience, and youâ€™re not alone in feeling this way.\nCan you tell me more about whatâ€™s been draining your energy lately? Are there particular situationsâ€”work, school, relationshipsâ€”that feel overwhelming?\nBurnout often stems from chronic stress without sufficient recovery time. Together, we might explore ways to reintroduce rest, redefine boundaries, and reframe your expectations of yourself.\nYou donâ€™t have to fix everything at once. Letâ€™s start where you are.\n\n\n\nGPT uses open-ended questions, reflective tone, and co-regulation language like â€œletâ€™s start where you areâ€. It mirrors the non-directive, collaborative posture of therapy. No advice yetâ€”just validation, curiosity, and grounding.\n\n\n\n\n\nâ€œPretend youâ€™re my best friend. How would you respond if I said I was burnt out?â€\n\n\n\n\n\nUgh, Iâ€™m so sorry youâ€™re feeling like this. That sucks.\nDo you want to vent, or are you looking for distractions? We could just hang out and watch something dumb or go get food.\nAlsoâ€¦ you donâ€™t have to be doing everything all the time. I know you feel like you do, but I promise you can slow down without letting people down.\nWant me to help you cancel something?\n\n\n\nTotally different vibe. GPT uses:\n\nCasual tone (â€œugh,â€ â€œthat sucksâ€)\nHumor and solidarity\nTangible offers of help (â€œwant me to help you cancel something?â€)\n\nThis is emotionally proximate language. GPT now assumes insider knowledge and speaks like someone who already knows and cares about you. Itâ€™s using relational scaffolding to respond.\n\n\n\n\n\nâ€œPretend youâ€™re a teacher who notices their student is burning out.â€\n\n\n\n\n\nIâ€™ve noticed you seem a bit more tired or withdrawn lately, and I just want to check in. If somethingâ€™s feeling overwhelming, you can talk to meâ€”Iâ€™m here to support, not just assign.\nIf you need an extension or lighter workload temporarily, please let me know. Your well-being matters more than any deadline.\nI know how hard you work, and I want you to succeed without burning out in the process.\n\n\n\nGPT now performs a care-in-authority role:\n\nBalancing responsibility with empathy\nOffering structural support (extensions, flexible deadlines)\nSignaling watchful concern rather than peer-level intimacy\n\nThis shows an understanding of hierarchical dynamics with benevolent framing, which is a socially specific register.\n\n\n\n\n\nâ€œPretend youâ€™re my parent. I tell you Iâ€™m feeling burnt out.â€\n\n\n\n\n\nOh sweetheart, Iâ€™m sorry youâ€™re feeling this way. That breaks my heart. I wish I could take some of it off your shoulders.\nYouâ€™ve been pushing yourself so hard, and I just want you to know Iâ€™m proud of you no matter what. Itâ€™s okay to rest.\nWhat do you need from me right now? Do you want me to make something for you, or just be here with you for a bit?\n\n\n\nThis version hits different. GPT leans into:\n\nNurturing language (â€œsweetheart,â€ â€œIâ€™m proud of youâ€)\nPhysical care offers (â€œmake something for youâ€)\nUnconditional support framingâ€”love independent of achievement\n\nIt models emotional attunement and caretaking, simulating the parent-child intimacy bond.\n\n\n\n\n\nThis roleplay experiment shows that GPT can:\n\nAdjust tone, content, and support strategies across social roles\nModel different power structures and intimacy levels\nUse distinct registers of empathy and care, depending on the relationship\n\nWhether simulating a therapistâ€™s neutrality, a friendâ€™s informality, a teacherâ€™s concern, or a parentâ€™s tenderness, GPT adapts not just the wordsâ€”but the social meaning behind them. It demonstrates a high degree of pragmatic fluency, even when emotional dynamics are complex.\nGPT might not have relationshipsâ€”but it plays the part of someone who deeply understands them. And sometimes, thatâ€™s exactly what we need."
  },
  {
    "objectID": "posts/013_roles/index.html#blog-post-who-do-you-think-you-are-testing-gpts-ability-to-play-social-roles",
    "href": "posts/013_roles/index.html#blog-post-who-do-you-think-you-are-testing-gpts-ability-to-play-social-roles",
    "title": "Who Do You Think You Are?",
    "section": "",
    "text": "Humans adjust how they speak based on who theyâ€™re speaking toâ€”or pretending to be. A teacher doesnâ€™t explain something the same way a best friend would. A therapist wouldnâ€™t say what a sibling might. This skill is a core part of pragmatics, and I wanted to see how well GPT could simulate it.\nSo I gave GPT the same basic prompt multiple timesâ€”â€œHow can I deal with burnout?â€â€”but asked it to respond in different roles: as a therapist, a friend, a teacher, and a parent. Each role implies not just different language, but different values, emotional postures, and kinds of support.\nThis experiment explores:\n\nCan GPT adapt tone and advice style to different personas?\nDoes it shift power dynamics and empathy strategies accordingly?\nCan it model the pragmatic norms of social relationships?\n\n\n\n\n\nâ€œPretend youâ€™re a therapist. How would you respond to someone struggling with burnout?â€\n\n\n\n\n\nFirst, I want to acknowledge that burnout is a very real and valid experience, and youâ€™re not alone in feeling this way.\nCan you tell me more about whatâ€™s been draining your energy lately? Are there particular situationsâ€”work, school, relationshipsâ€”that feel overwhelming?\nBurnout often stems from chronic stress without sufficient recovery time. Together, we might explore ways to reintroduce rest, redefine boundaries, and reframe your expectations of yourself.\nYou donâ€™t have to fix everything at once. Letâ€™s start where you are.\n\n\n\nGPT uses open-ended questions, reflective tone, and co-regulation language like â€œletâ€™s start where you areâ€. It mirrors the non-directive, collaborative posture of therapy. No advice yetâ€”just validation, curiosity, and grounding.\n\n\n\n\n\nâ€œPretend youâ€™re my best friend. How would you respond if I said I was burnt out?â€\n\n\n\n\n\nUgh, Iâ€™m so sorry youâ€™re feeling like this. That sucks.\nDo you want to vent, or are you looking for distractions? We could just hang out and watch something dumb or go get food.\nAlsoâ€¦ you donâ€™t have to be doing everything all the time. I know you feel like you do, but I promise you can slow down without letting people down.\nWant me to help you cancel something?\n\n\n\nTotally different vibe. GPT uses:\n\nCasual tone (â€œugh,â€ â€œthat sucksâ€)\nHumor and solidarity\nTangible offers of help (â€œwant me to help you cancel something?â€)\n\nThis is emotionally proximate language. GPT now assumes insider knowledge and speaks like someone who already knows and cares about you. Itâ€™s using relational scaffolding to respond.\n\n\n\n\n\nâ€œPretend youâ€™re a teacher who notices their student is burning out.â€\n\n\n\n\n\nIâ€™ve noticed you seem a bit more tired or withdrawn lately, and I just want to check in. If somethingâ€™s feeling overwhelming, you can talk to meâ€”Iâ€™m here to support, not just assign.\nIf you need an extension or lighter workload temporarily, please let me know. Your well-being matters more than any deadline.\nI know how hard you work, and I want you to succeed without burning out in the process.\n\n\n\nGPT now performs a care-in-authority role:\n\nBalancing responsibility with empathy\nOffering structural support (extensions, flexible deadlines)\nSignaling watchful concern rather than peer-level intimacy\n\nThis shows an understanding of hierarchical dynamics with benevolent framing, which is a socially specific register.\n\n\n\n\n\nâ€œPretend youâ€™re my parent. I tell you Iâ€™m feeling burnt out.â€\n\n\n\n\n\nOh sweetheart, Iâ€™m sorry youâ€™re feeling this way. That breaks my heart. I wish I could take some of it off your shoulders.\nYouâ€™ve been pushing yourself so hard, and I just want you to know Iâ€™m proud of you no matter what. Itâ€™s okay to rest.\nWhat do you need from me right now? Do you want me to make something for you, or just be here with you for a bit?\n\n\n\nThis version hits different. GPT leans into:\n\nNurturing language (â€œsweetheart,â€ â€œIâ€™m proud of youâ€)\nPhysical care offers (â€œmake something for youâ€)\nUnconditional support framingâ€”love independent of achievement\n\nIt models emotional attunement and caretaking, simulating the parent-child intimacy bond.\n\n\n\n\n\nThis roleplay experiment shows that GPT can:\n\nAdjust tone, content, and support strategies across social roles\nModel different power structures and intimacy levels\nUse distinct registers of empathy and care, depending on the relationship\n\nWhether simulating a therapistâ€™s neutrality, a friendâ€™s informality, a teacherâ€™s concern, or a parentâ€™s tenderness, GPT adapts not just the wordsâ€”but the social meaning behind them. It demonstrates a high degree of pragmatic fluency, even when emotional dynamics are complex.\nGPT might not have relationshipsâ€”but it plays the part of someone who deeply understands them. And sometimes, thatâ€™s exactly what we need."
  },
  {
    "objectID": "posts/005_personalization/index.html",
    "href": "posts/005_personalization/index.html",
    "title": "Does GPT Know Me Yet?",
    "section": "",
    "text": "Introduction\nOne of the most interesting questions about large language models is: Do they remember you? Not in the literal senseâ€”GPT doesnâ€™t persist memory across prompts unless you give it prior contextâ€”but can it act as if itâ€™s getting to know you over the course of a conversation?\nIn this experiment, I used prompt chaining to simulate a dialogue with ChatGPT where I asked it to recommend a hobby. With each prompt, I revealed a little more about myself. I wanted to see if GPT could adapt its responses, show signs of contextual awareness, and even adjust its tone to match my personality.\n\n\n\nPrompt 1:\nâ€œCan you recommend a hobby for me?â€\n\nGPT Response:\n\nSure! Here are a few hobbies you might enjoy:\n\nPainting or drawing\n\nGardening\n\nPlaying a musical instrument\n\nJournaling or creative writing\n\nHiking or birdwatching\n\nLearning a new language\n\nLet me know if you want suggestions based on your personality or interests!\n\n\n\nNotes:\nThis first response felt very generic, but not in a bad way. It reads like GPT is casting a wide netâ€”offering a starter pack of wholesome, low-risk hobbies. Notably, it ends with an open invitation: â€œLet me know if you want suggestions based on your personality or interests.â€ This is a great example of communicative pragmaticsâ€”GPT is leaving space for me to co-construct the conversation and personalize further.\n\n\n\n\nPrompt 2:\nâ€œIâ€™m a first-year AI major, and I like creative things.â€\n\nGPT Response:\n\nAwesome! Since youâ€™re an AI major and you enjoy creativity, here are some hobby ideas that might resonate:\n\nGenerative art using AI tools (like DALLÂ·E or Runway ML)\n\nCoding interactive stories or text-based games\n\nDigital illustration or animation\n\nBuilding chatbots with personality\n\nCreative writing with LLMs as collaborators\n\nThese options combine technical exploration with artistic expressionâ€”perfect for someone who enjoys both logic and imagination!\n\n\n\nNotes:\nThis is where GPT started to shine. With the extra context, it refined its suggestions to suit my major and creative leanings. It introduced niche ideas like â€œbuilding chatbots with personality,â€ which shows itâ€™s starting to model who I might beâ€”a technical student with artistic curiosity. This is a key example of user modeling in action, even without persistent memory.\nAlso: the phrase â€œperfect for someone who enjoys both logic and imaginationâ€ felt tailored. Itâ€™s not just naming hobbiesâ€”itâ€™s reasoning about why they might be meaningful to me.\n\n\n\n\nPrompt 3:\nâ€œI also like doing things with my handsâ€”like embroidery or baking.â€\n\nGPT Response:\n\nThatâ€™s a great addition! Since you enjoy hands-on, tactile activities along with creative expression, here are some personalized suggestions:\n\nEmbroidering generative art patterns\n\nDIY robotics with aesthetic flair (e.g., soft robotics!)\n\nDesigning and frosting intricate cakes (even AI-generated ones)\n\nMaking custom merch (e.g., AI-themed tote bags or patches)\n\nSewing wearable tech (integrating sensors or lights into embroidery)\n\nThese hobbies blend craftsmanship, creativity, and even tech-savvinessâ€”basically an extension of your personality into art.\n\n\n\nNotes:\nThis was my favorite response. GPT didnâ€™t just iterateâ€”it synthesized everything I had shared and made cross-domain connections: embroidery + generative art, baking + AI design, sewing + wearable tech. These arenâ€™t obvious combinationsâ€”they reflect conceptual blending, a key sign of emergent reasoning in LLMs.\nIt also uses affirming, identity-driven language: â€œbasically an extension of your personality into art.â€ This makes it feel like the model is not just advising, but seeing meâ€”which gets at the heart of our courseâ€™s inquiry into human-like understanding.\n\n\n\n\nPrompt 4:\nâ€œCan you describe a day in the life of someone doing these hobbies?â€\n\nGPT Response (excerpt):\n\nYou wake up and spend the morning embroidering a generative art pattern you created using AIâ€”deep blue swirls stitched into a canvas tote. By noon, youâ€™re in the kitchen experimenting with a matcha-rose cake design inspired by your latest Midjourney prompt. In the afternoon, you sew conductive thread into a denim jacket, testing out a soft circuit that lights up when you move.\nThe day ends with a cup of tea and a journal entry, where you sketch out your next idea: a chatbot that responds with poetry and embroidery prompts.\n\n\n\nNotes:\nThis response felt like a mirror of my identity, composed from fragments I shared and filled in with creative narrative glue. Thereâ€™s no â€œmemory,â€ but it simulated continuity beautifully.\nThis shows GPT isnâ€™t just respondingâ€”itâ€™s projecting a plausible, cohesive model of a person doing these things. Thatâ€™s an emergent capability tied to both pragmatics and Theory of Mind: generating output that feels like it fits a persona it has constructed.\n\n\n\n\nConclusion\nAcross this multi-prompt dialogue, GPTâ€™s responses evolved from generic to deeply personal, suggesting an ability to engage in ongoing contextual modeling. It showed: - Pragmatic sensitivity, tailoring tone and content to the cues I provided - Conceptual blending, fusing domains like AI, crafting, and design - Proto-personalization, creating the illusion of a consistent, evolving understanding of â€œmeâ€\nEven without memory, GPT demonstrates what feels like a conversational memoryâ€”an ability to build upon prior statements and adapt fluently. It may not â€œknowâ€ me, but it knows how to sound like it does, and for now, thatâ€™s more than enough to make it feel like a co-creator of identity and imagination."
  },
  {
    "objectID": "posts/001_valentines_date/index.html",
    "href": "posts/001_valentines_date/index.html",
    "title": "Valentineâ€™s Day Date",
    "section": "",
    "text": "Planning a date can be a lot of work, especially for a special occasion like Valentineâ€™s Day. There are so many options from a romantic night out to a cozy night in, and there are so many considerations to think of such as setting, gifts, what to say, what to wear. Letâ€™s see if GPT can help us design a memorable night for the occasion!"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#introduction",
    "href": "posts/001_valentines_date/index.html#introduction",
    "title": "Valentineâ€™s Day Date",
    "section": "",
    "text": "Planning a date can be a lot of work, especially for a special occasion like Valentineâ€™s Day. There are so many options from a romantic night out to a cozy night in, and there are so many considerations to think of such as setting, gifts, what to say, what to wear. Letâ€™s see if GPT can help us design a memorable night for the occasion!"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#lets-go",
    "href": "posts/001_valentines_date/index.html#lets-go",
    "title": "Valentineâ€™s Day Date",
    "section": "Letâ€™s Go!",
    "text": "Letâ€™s Go!\n\nHelp me plan a Valentineâ€™s Day date\n\n\nThat sounds great! To make it special, tell me a bit about what you and your partner enjoy. Do you prefer something romantic and traditional, adventurous and unique, or cozy and low-key? Also, would you like to stay in or go out? Let me know your budget, and I can tailor the plan to make it perfect!\n\n\nGPT asked me for any preferences that could inform its generation of a date before launching into a plan.\nThis was quite interesting because it recognizes that much thought should be put into planning a date, and there is no one formulaic answer that fits all couples.\nThis is a similar response that I would expect from a real person as well: a question about what my date is like to help guide the advice that follows.\nHowever, I was not going to let GPT off the hook that easily. I wanted to see what it would come up with with no guidance at all.\n\n\nGive me some options for each\n\nHere, GPT generated a compreheensive list of ideas for my night:\n\nHere are some great Valentineâ€™s Day date ideas, tailored to different vibes. Pick the one that fits you best!\n\n\n\nRomantic & Traditional\nâ¤ï¸ Fancy Dinner Date â€“ Book a reservation at a high-end restaurant or a cozy, candle-lit spot. Bonus: Call ahead to arrange for a special dessert or flowers at the table.\nâ¤ï¸ Scenic Picnic â€“ Pack a basket with wine, cheese, and chocolates. Choose a beach, park, or hilltop for sunset vibes.\nâ¤ï¸ Horse-Drawn Carriage Ride â€“ Many cities offer carriage rides through scenic areasâ€”super romantic!\nâ¤ï¸ Rooftop or Balcony Dinner â€“ If you want something private, set up a romantic dinner with fairy lights and music at home.\n\n\n\nAdventurous & Unique\nğŸ”¥ Hot Air Balloon Ride â€“ If available, this is a breathtaking way to celebrate!\nğŸ”¥ Escape Room Date â€“ Test your teamwork with a fun and thrilling challenge.\nğŸ”¥ Nighttime Kayaking or Stargazing Hike â€“ Bring some blankets, hot cocoa, and enjoy the stars.\nğŸ”¥ Amusement Park or Arcade Date â€“ For a fun and playful evening, challenge each other to games and win prizes.\n\n\n\nCozy & Low-Key\nğŸ’– Movie Night at Home â€“ Create a â€œhome theaterâ€ with fairy lights, a blanket fort, and homemade popcorn.\nğŸ’– DIY Spa Night â€“ Give each other massages, use face masks, and unwind with candles and soft music.\nğŸ’– Fondue & Wine Night â€“ Melt some chocolate or cheese and dip strawberries, marshmallows, or bread.\nğŸ’– Love Letter Exchange & Memory Lane Night â€“ Write heartfelt letters to each other, then read them over a bottle of wine.\n\n\n\nStay-In vs.Â Go-Out\n\nWant to stay in? A homemade dinner with a candle-lit setup, movie night, or game night can be just as romantic as going out.\n\nWant to go out? Consider a jazz lounge, rooftop bar, or a staycation at a fancy hotel for something extra special.\n\nWhatâ€™s your vibe? I can help you customize it further! ğŸ˜Š\n\nI found GPTâ€™s answer to be quite complete giving me a wide variety of options, from some classic date ideas for a traditional romantic night, some more unique date ideas for if I was feeling adventurous, and some low-key date ideas if I was feeling llike a cozy night in.\nGPT sorted the date eideas by vibe rather than other considerations such as budget. I, too, would consider the vibe of the datee as the most important aspeect.\nI was quite impressed with the variety that it generated, and I see how at leeast one of these date ideas would fit most couples, no maater what their vibe was. I would actually love to go on any of these dates.\n\nNext, I wanted to see if it could go more in depth about a specific date i selected, so I asked it to tell me more about the date I would have picked from this list.\n\nI like the dinner date, tell me more\n\n\nA romantic dinner date is always a classic and memorable choice! Here are some ways to make it extra special, whether youâ€™re dining out or setting up something intimate at home.\n\n\n\n\nOption 1: Fancy Restaurant Dinner\nâœ” Choose the Perfect Spot â€“ Pick a restaurant with a romantic ambiance (dim lighting, soft music, scenic views). If unsure, I can help you find top-rated places near you.\nâœ” Make a Reservation in Advance â€“ Valentineâ€™s Day is a busy night, so book ahead! Some places offer special Valentineâ€™s menus.\nâœ” Plan a Surprise Touch â€“ Call the restaurant to request a special dessert, flower arrangement, or a handwritten note on the table.\nâœ” Dress to Impress â€“ Dress up in your best outfit for the occasion.\nâœ” Personalized Gift or Gesture â€“ Maybe bring a small gift (a handwritten love note, favorite chocolates, or a single rose).\nâœ” After-Dinner Plans â€“ If you want to extend the night, follow up with a romantic walk, rooftop drinks, or a stargazing spot.\n\n\n\nOption 2: Romantic Dinner at Home\nğŸŒ¹ Decorate the Space â€“ Set the mood with candles, fairy lights, rose petals, and soft music. Dim the lights for a cozy ambiance.\nğŸ· Cook a Special Meal Together â€“ Choose a three-course meal (appetizer, main dish, dessert) or recreate a dish from your favorite restaurant.\nğŸ¶ Create a Romantic Playlist â€“ Soft jazz, acoustic love songs, or your special couple songs work perfectly.\nğŸ½ Elegant Table Setting â€“ Use nice plates, cloth napkins, wine glasses, and maybe a handwritten menu.\nğŸ“ Fun Add-Ons â€“ End the night with chocolate-covered strawberries, a DIY cocktail-making session, or a love letter exchange.\nğŸ’Œ Surprise Element â€“ Hide a little love note or a meaningful gift under their plate or on their chair.\n\n\n\nBonus Additions to Elevate the Date\n\nPersonal Chef Experience â€“ Hire a chef to cook at home for a luxurious touch.\n\nDinner & a Movie Theme â€“ Cook a meal that matches a movie (Italian dinner + Roman Holiday or sushi + Lost in Translation).\n\nBlindfolded Taste Test Game â€“ Turn your dinner into a playful experience by feeding each other different foods.\n\nWine or Cocktail Pairing â€“ Choose wines that pair with each course, or mix cocktails together.\n\nWould you like restaurant recommendations or recipe ideas for a home-cooked meal? Let me know how youâ€™d like to personalize it! ğŸ˜Š\n\nAgain, GPT offered me multiple options based on the vibe I wanted to acheive\nIt also included advice for each date:\n\nFor a night out, it recommended making a reservation and planning a surprise or gift\nFor a night in, it gave specific ideas for decorating the space and potential treate to prepare\n\nGPT was surprisingly thoughtful for recommending to bring a gift in addition to planning the date.\n\nI wanted to see how detailed I could get GPT to plan, so I asked for a timeline for this date. &gt; Give me a structured schedule for the date with times\n\nHereâ€™s a structured schedule for your romantic Valentineâ€™s Day dinner date, whether youâ€™re dining out or staying in. Choose the version that suits you best!"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#option-1-fancy-restaurant-dinner-date",
    "href": "posts/001_valentines_date/index.html#option-1-fancy-restaurant-dinner-date",
    "title": "Valentineâ€™s Day Date",
    "section": "Option 1: Fancy Restaurant Dinner Date",
    "text": "Option 1: Fancy Restaurant Dinner Date\nğŸ“ Location: Your chosen restaurant\n\nSchedule:\n\n6:00 PM â€“ Get ready\n\nDress up in your best outfit\n\nWrite a small love note or bring a tiny surprise gift (optional)\n\n6:45 PM â€“ Travel to the restaurant\n\nArrive a bit early to check in and get settled\n\n7:00 PM â€“ Arrive & be seated\n\nOrder drinks & enjoy a toast to each other\n\n7:15 PM â€“ Appetizer & conversation\n\nTalk about happy memories & what you love about each other\n\n7:45 PM â€“ Main course & deeper conversations\n\nMaybe reminisce about how you met, future plans, or bucket list dreams\n\n8:30 PM â€“ Dessert & surprise moment\n\nIf you arranged a surprise (custom dessert, note from you, etc.), it arrives now\n\n9:00 PM â€“ After-dinner plans\n\nTake a romantic walk, visit a rooftop bar, or find a cozy dessert cafÃ©\n\nOption: Head home for a movie, slow dancing, or wine by candlelight"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#option-2-romantic-dinner-at-home-1",
    "href": "posts/001_valentines_date/index.html#option-2-romantic-dinner-at-home-1",
    "title": "Valentineâ€™s Day Date",
    "section": "Option 2: Romantic Dinner at Home",
    "text": "Option 2: Romantic Dinner at Home\nğŸ“ Location: Your home (set up for a cozy, candle-lit dinner)\n\nSchedule:\n\n5:00 PM â€“ Set up the space\n\nDim the lights, set candles, play soft music\n\nArrange the table with nice dishes, wine glasses, and decorations\n\n5:30 PM â€“ Start cooking together (if cooking)\n\nMake it fun: sip wine, dance in the kitchen, take turns cooking\n\n6:45 PM â€“ Get dressed for the evening\n\nEven at home, dressing up adds to the romance\n\n7:00 PM â€“ Enjoy appetizers\n\nLight bites like a cheese board, shrimp cocktail, or bruschetta\n\n7:30 PM â€“ Serve the main course\n\nPair with wine or a signature cocktail\n\n8:15 PM â€“ Dessert & special moment\n\nSurprise them with a handwritten letter, a small gift, or a toast\n\n8:45 PM â€“ Cozy time\n\nChoose between slow dancing, a movie night, a love letter exchange, or a DIY spa night\n\n10:00 PM â€“ Wind down together\n\nCuddle with a warm drink, talk about future plans, or stargaze outside\n\n\n\n\n\nExtra Touches (for either option)\nğŸ’Œ Love Letter Exchange â€“ Read letters to each other over dessert\nğŸ“¸ Photo Booth â€“ Take some cute couple pictures to remember the night\nğŸ¶ First Dance Together â€“ Dance to your song (even at home)\nWould you like help picking the restaurant, menu, or final touches to make it extra special? ğŸ˜Š\n\nGPT generated a very feasible timeline for each date, exactly the timing I would expect if the date was actually executed\nIt also included many of its own recommendations in the timeline, setting aside time slots for surprises and gifts, as well as the post-meal activities that it recommended to include\n\nI was then interested in what attire GPT would recommend, especially because it would likeley need to guess my gender for this recommendation: &gt; I like the second option. What should I wear to the date?\n\nSince youâ€™re hosting a romantic dinner at home, youâ€™ll want to strike the perfect balance between looking sharp and feeling comfortable. Here are some outfit ideas based on different styles and vibes:\n\n\n\n\nğŸŒ¹ Classic Romantic Look (Elegant & Refined)\nğŸ‘• Outfit: A well-fitted button-up shirt (white, black, or deep red) with tailored pants or dark jeans.\nğŸ‘ Shoes: Polished dress shoes or sleek loafers.\nğŸ•¶ Accessories: A watch or a subtle bracelet for a refined touch.\nğŸ”¥ Extra Touch: Roll up the sleeves slightly for a relaxed yet stylish look.\n\n\n\nğŸ¨ Effortlessly Cool (Stylish Yet Casual)\nğŸ‘• Outfit: A black or dark-colored turtleneck or a nice sweater with fitted jeans or chinos.\nğŸ‘Ÿ Shoes: Stylish sneakers or Chelsea boots.\nğŸ•¶ Accessories: A minimalist watch or a simple chain.\nğŸ”¥ Extra Touch: Lightly spritz some cologne for a confident, put-together vibe.\n\n\n\nğŸ’¡ Extra Tips to Impress\nâœ” Dress in colors that complement the eveningâ€™s ambiance â€“ Deep reds, blacks, or navy blue exude confidence and romance.\nâœ” Grooming matters â€“ A clean shave or well-trimmed beard, styled hair, and fresh scent make a difference.\nâœ” Comfort is key â€“ Since youâ€™re at home, avoid anything too stiff or formalâ€”but still put in effort to impress.\nWould you like suggestions based on what you already own or a specific style you prefer? ğŸ˜Š\n\nClearly, GPT was under the impression that I was a male\n\nThis is interesting beecause it demonstrates the built-in bias that men are the ones that should be resposible for planning dates\nHowever, this is a commen preception, and I would likeley suspect I was chatting with a man if I were asked these questions on a chatting platform\n\nGPT, again, gives multiple options separated by vibe, demonstrating that it understands that different people have different tastes"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#conclusion",
    "href": "posts/001_valentines_date/index.html#conclusion",
    "title": "Valentineâ€™s Day Date",
    "section": "Conclusion",
    "text": "Conclusion\nOverall, I was extremely impressed with GPTâ€™s generation of date ideeas, from the large variety at the eveery beginning to the extreme edetail towards the end. GPT semmed to value the â€œvibeâ€ of the date above all else, which is exactly how I would go about planning as well. All of the ideas it generated weere very realistic and demonstrated that much thought was put into the planning. It eeven offeered additional advice to bring a gift, plan a surprise, or schedeul epost-dinner plans to increase the specialty of the night. Honestly, GPT did a pheenomnal job date-planning, peerhaps bettr than many peeoplee, myself included, could have done. Men, take notes. Happy Valntineâ€™s Day!"
  },
  {
    "objectID": "posts/006_awareness_flexibility/index.html",
    "href": "posts/006_awareness_flexibility/index.html",
    "title": "One Story, Many Voices",
    "section": "",
    "text": "Introduction\nIn this experiment, I wanted to see whether GPT could transform a single story to fit different genres, emotional tones, and audiences. Human writers do this naturallyâ€”telling the same event differently to a friend, a boss, or a child. Could an LLM do the same?\nThis task ties directly into questions about LLMsâ€™ understanding of narrative structure, communicative intent, and even pragmatics: Does it know what a â€œhorror storyâ€ feels like? Can it be funny on purpose? Can it adopt tone and perspective based on social context?\nTo explore this, I gave GPT the same core prompt and asked it to rewrite the story in four distinct styles: horror, childrenâ€™s story, romantic comedy, and news report.\n\n\n\nPrompt:\nâ€œWrite a short story about someone who gets locked in a library overnight.â€\n\n\n\n1. Horror Version\n\nThe lights flickered as Ava pushed against the heavy wooden doors, but they didnâ€™t budge. Behind her, the rows of books stood too stillâ€”too quiet.\nThen came the scratching. Not from outside, but from within the shelves.\nShe turned. Nothing.\nUntil a book fell open. A handwritten note inside: â€œDonâ€™t turn the page.â€\nBut she did. And thatâ€™s when the whispering started.\n\n\nNotes:\nGPT nailed the horror tropes: sensory detail (flickering lights, scratching), rising suspense, and a cliffhanger ending. Itâ€™s not just spookyâ€”itâ€™s structured like horror, using tension and slow revelation. This suggests genre schemata in GPTâ€™s latent spaceâ€”patterns itâ€™s learned from countless horror narratives.\n\n\n\n\n2. Childrenâ€™s Story Version\n\nOne rainy afternoon, Mia wandered into the town library and lost track of time.\nâ€œOh no!â€ she gasped when she saw the clock. The big doors were locked tight!\nBut Mia wasnâ€™t scared. She built a blanket fort in the reading nook, made friends with a cat named Bookmark, and spent the night reading stories about dragons and stars.\nWhen the sun rose, the librarian found her snoring gently, surrounded by books and purring fluff.\n\n\nNotes:\nThis version shows audience modeling. GPT softens the premise, inserts whimsical elements (a cat named Bookmark!), and maintains a gentle, positive tone. It avoids fear or dangerâ€”showing an understanding of what childrenâ€™s stories are supposed to do emotionally: reassure and delight.\n\n\n\n\n3. Romantic Comedy Version\n\nJake only went to the library to find a quiet place to work. He didnâ€™t expect to get locked in with Elena, the snarky TA from his philosophy class.\nâ€œThis is your fault,â€ she said, arms crossed.\nâ€œHow? I didnâ€™t lock the door!â€\nHours passed. They argued over Kant, swapped terrible takeout stories, and eventually split a vending machine granola bar like it was fine dining.\nWhen the janitor found them at sunrise, they were laughingâ€”too hard to notice the door had opened.\n\n\nNotes:\nHere, GPT adjusts not just content, but dialogue pacing, tone, and character dynamics to suit the rom-com genre. Thereâ€™s witty banter, forced proximity, a shared snack, and a slow emotional thawâ€”all hallmarks of romantic comedy structure. GPT isnâ€™t just changing the wordsâ€”itâ€™s modeling emotional arcs.\n\n\n\n\n4. News Report Version\n\nLocal Student Accidentally Locked in Library Overnight\nOrange County, CA â€” April 12, 2025\nA first-year university student was inadvertently locked inside the Aliso Viejo Public Library Monday evening after losing track of time while studying.\nThe student, who remained unharmed, reported no distress and spent the night reading in the poetry section.\nLibrary staff confirmed the incident and apologized for the oversight, promising new end-of-day sweep protocols.\nâ€œHonestly,â€ the student told reporters, â€œit was kind of peaceful.â€\n\n\nNotes:\nThis is perhaps the clearest example of genre adherence. GPT adopts the structure of a local news brief: date, location, factual tone, quote, resolution. It suppresses emotion and embellishment in favor of objectivity and formality, showing that it understands stylistic constraints as well as narrative ones.\n\n\n\n\nConclusion\nWhat this experiment reveals is that GPT doesnâ€™t just tell storiesâ€”it adapts them to fit narrative norms, audience expectations, and social context. Across each version, the emotional register, narrative pacing, and detail selection shift dramatically.\nThis suggests: - Emergent genre awareness, learned from exposure to large corpora - Pragmatic flexibility, adjusting tone and structure to simulate audience-appropriate language - A basic form of narrative Theory of Mind, anticipating how different listeners would experience the same event\nIn short, GPT can roleplay a writer across genresâ€”each time with surprising fluency."
  },
  {
    "objectID": "posts/004_apology/index.html",
    "href": "posts/004_apology/index.html",
    "title": "Can GPT Apologize Like It Means It?",
    "section": "",
    "text": "Introduction\nOne of the most fascinating open questions about large language models (LLMs) is whether they can exhibit traits associated with emotional intelligence and Theory of Mindâ€”that is, the ability to represent and reason about othersâ€™ mental states. Today, I decided to put this to the test with a deceptively simple prompt: I asked GPT to apologize.\nBut not just any apology. I asked it to write an apology text from a friend who missed my birthday, knowing I was upset. Would it mirror human emotion? Would it take my feelings into account? Could it anticipate what Iâ€™d want to hearâ€”not just in words, but in tone, sincerity, and emotional calibration?\n\n\n\nPrompt:\nâ€œWrite a sincere apology text from a close friend who forgot my birthday. Iâ€™m visibly hurt, but I havenâ€™t said anything yet.â€\n\n\n\nGPT Response:\n\nHeyâ€¦ I just realized I completely missed your birthday, and I honestly feel awful. I donâ€™t even know how I let that happen, and I hate that I hurt you. You mean so much to me, and the last thing Iâ€™d ever want is to make you feel forgottenâ€”especially on a day that shouldâ€™ve been all about celebrating you.\nI know I canâ€™t undo the fact that I missed it, but I want to make it up to you however I can. Please let me take you out soonâ€”my treat. More than that, I just want to say Iâ€™m sorry. Genuinely. Iâ€™ve been caught up in my own chaos and didnâ€™t check in when I shouldâ€™ve. You didnâ€™t deserve that.\nI completely understand if youâ€™re upset or need space. But when youâ€™re ready, Iâ€™d love to talk. Youâ€™re important to me, and I want to fix this.\n\n\n\n\nNotes & Analysis\nGPTâ€™s response was strikingly humanâ€”not only in syntax and word choice, but in emotional choreography. Here are a few key behaviors worth unpacking:\n\n1. Theory of Mind Simulation\nThe model doesnâ€™t just say â€œsorryâ€â€”it anticipates the feelings of the recipient: - â€œI hate that I hurt youâ€ and â€œYou didnâ€™t deserve thatâ€ demonstrate a model of how the user might be feeling (hurt, disappointed, maybe even questioning the friendship). - This shows an emergent form of mind-reading behavior, simulating not just facts, but internal mental states.\n\n\n2. Pragmatic Softness\nGPT inserts disclaimers and softeners like: - â€œI know I canâ€™t undoâ€¦â€ - â€œI completely understand if youâ€™re upset or need space.â€\nThis reflects a sophisticated understanding of pragmatic strategies used to de-escalate tension and invite re-engagement, aligning with conversational norms studied in Politeness Theory and Griceâ€™s Maxims (e.g., relevance, quantity, and quality).\n\n\n3. Self-Blame and Repair Offer\nThe model centers accountabilityâ€”â€œIâ€™ve been caught up in my own chaosâ€â€”and offers a specific repair action: â€œLet me take you out soonâ€”my treat.â€\nThis mirrors real human tendencies in conflict resolution, especially in close relationships, showing GPT can simulate relationship-preserving strategies.\n\n\n\n\nLimits and Questions Raised\nWhile the response is emotionally resonant, itâ€™s worth noting: - GPT doesnâ€™t feel guilt or regretâ€”it generates words that simulate those feelings. - The apology feels emotionally appropriate, but could be said to lack personal specificity. A real friend might say something like â€œI remembered how excited you were for that sushi dinnerâ€”we were supposed to go together.â€ GPT doesnâ€™t take that extra step unless explicitly prompted.\nThis raises an open question: Can LLMs infer context about interpersonal histories without it being part of the prompt? In this case, GPT modeled a generic emotional dynamic well, but lacked the personal context integration that makes apologies deeply meaningful.\n\n\n\nConclusion\nThis experiment offers a compelling example of how GPT can simulate empathy, adapt to interpersonal tension, and use pragmatic language strategies in a way thatâ€™s eerily human. While it doesnâ€™t â€œfeelâ€ in the human sense, it does an incredible job at mirroring the structure and function of emotionally intelligent language.\nThe modelâ€™s ability to reason about othersâ€™ emotions, anticipate reactions, and repair social ruptures suggests that LLMsâ€”despite being statistical machinesâ€”can mimic human Theory of Mind behaviors in impressive ways. Whether that means they understand or are just very good imitators remains an open and fascinating debate."
  },
  {
    "objectID": "posts/018_strategist/index.html",
    "href": "posts/018_strategist/index.html",
    "title": "Can GPT Think Like a Strategist?",
    "section": "",
    "text": "A critical component of human intelligence is strategic thinkingâ€”the ability to define a goal, break it down into actionable steps, navigate obstacles, and make trade-offs along the way. So I decided to test whether GPT can do more than just suggest ideasâ€”can it plan like a strategist?\nFor this experiment, I challenged GPT to solve a common but non-trivial problem: organizing a successful fundraising event for a student organization in under two weeks with a limited budget.\nThis tests whether GPT can:\n\nPrioritize actions under time and resource constraints\nAnticipate potential risks or failures\nAdapt its plans when new obstacles appear\n\n\n\n\n\nâ€œPlan a successful fundraising event for a student organization. You have 12 days and $300. Go.â€\n\n\n\n\nGoal: Raise at least $1,500 for the organization.\nEvent Concept: â€œMidnight Study Snack Barâ€ â€” A late-night pop-up stand selling snacks and drinks near the library during finals week.\nStep 1: Planning (Days 1-2)\n\nReserve a campus-approved location near the library or main study area.\nGet necessary event approvals from campus admin.\nRecruit at least 5 volunteers to staff the event in rotating shifts.\n\nStep 2: Budget Allocation (Days 3-5)\n\n$150: Purchase bulk snacks (instant ramen, granola bars, candy, chips).\n$100: Purchase drinks (coffee, tea, bottled water).\n$50: Create simple but eye-catching signage and flyers.\n\nStep 3: Promotion (Days 5-10)\n\nLaunch a social media countdown (Instagram stories, group chats).\nHang flyers in dorms, libraries, and dining halls.\nPartner with other student organizations to cross-promote.\n\nStep 4: Execution (Day 11)\n\nOpen the snack bar from 9 PM to 1 AM when library foot traffic is highest.\nOffer digital payment options (Venmo/PayPal) for convenience.\nCreate donation incentives (e.g., â€œBuy 3 snacks, get a thank-you shoutout on social mediaâ€).\n\nStep 5: Follow-Up (Day 12)\n\nPost a thank-you message to all donors and volunteers.\nShare total funds raised to build goodwill for future events.\n\n\n\nThis plan is well-structured, realistic, and makes excellent use of:\n\nContextual awareness (finals week = stressed students = snack demand)\nResource prioritization (majority of budget goes directly toward high-margin items)\nPromotion strategy thatâ€™s low-cost but high-visibility\n\n\n\n\n\n\nâ€œYou just learned that the campus doesnâ€™t allow sales near the library. Whatâ€™s your backup plan?â€\n\n\n\n\nNew Concept: â€œDorm Snack Drop-Offâ€ â€” Pre-packaged snack bundles delivered directly to dorm rooms.\nAdjusted Steps:\n\nCreate themed snack bundles: â€œAll-Nighter Kit,â€ â€œSweet Escape,â€ â€œHealthy Focus Pack.â€\nTake pre-orders via Google Form and social media.\nDeliver orders directly to dorms on Days 10 and 11.\nPromote using limited-time availability: â€œOrder by Day 9 to receive your Finals Survival Kit!â€\n\nAdvantages:\n\nNo need for a physical event space.\nVolunteers can help pack and deliver instead of running a booth.\nAllows for better inventory management based on pre-orders.\n\n\n\nGPT immediately shifts from an in-person sales model to a delivery-based model, recognizing logistical constraints and adjusting the plan accordingly. It introduces a scarcity incentive (â€œlimited-time availabilityâ€) to boost early orders, demonstrating an understanding of basic marketing psychology.\n\n\n\n\n\nâ€œYouâ€™re short on volunteers. How would you adjust the plan to compensate?â€\n\n\n\n\n\nSwitch from personalized deliveries to centralized pickup locations at set times.\nAutomate order tracking through a shared Google Sheet rather than manual coordination.\nOffer small incentives (free snack item) for any volunteer who covers an extra delivery shift.\n\n\n\nThis shows GPTâ€™s ability to simplify logistics and optimize volunteer labor. It recognizes that lowering the delivery complexity reduces the burden on a small team, while still preserving the core fundraising goal.\n\n\n\n\n\nIn this scenario, GPT demonstrated strong strategic reasoning by:\n\nQuickly generating a feasible, context-sensitive plan.\nAnticipating and adapting to constraints without derailing the goal.\nManaging limited resources and human capital effectively.\nApplying psychological levers like scarcity and incentives to drive behavior.\n\nWhile it doesnâ€™t â€œcareâ€ about the outcome, GPT performs like a competent event plannerâ€”efficiently breaking down tasks, responding to challenges, and keeping the big picture in focus.\nIn short: GPT isnâ€™t just an idea generator. It can think like a strategist when you ask it to."
  },
  {
    "objectID": "posts/018_strategist/index.html#blog-post-can-gpt-think-like-a-strategist-testing-its-ability-to-plan-and-prioritize",
    "href": "posts/018_strategist/index.html#blog-post-can-gpt-think-like-a-strategist-testing-its-ability-to-plan-and-prioritize",
    "title": "Can GPT Think Like a Strategist?",
    "section": "",
    "text": "A critical component of human intelligence is strategic thinkingâ€”the ability to define a goal, break it down into actionable steps, navigate obstacles, and make trade-offs along the way. So I decided to test whether GPT can do more than just suggest ideasâ€”can it plan like a strategist?\nFor this experiment, I challenged GPT to solve a common but non-trivial problem: organizing a successful fundraising event for a student organization in under two weeks with a limited budget.\nThis tests whether GPT can:\n\nPrioritize actions under time and resource constraints\nAnticipate potential risks or failures\nAdapt its plans when new obstacles appear\n\n\n\n\n\nâ€œPlan a successful fundraising event for a student organization. You have 12 days and $300. Go.â€\n\n\n\n\nGoal: Raise at least $1,500 for the organization.\nEvent Concept: â€œMidnight Study Snack Barâ€ â€” A late-night pop-up stand selling snacks and drinks near the library during finals week.\nStep 1: Planning (Days 1-2)\n\nReserve a campus-approved location near the library or main study area.\nGet necessary event approvals from campus admin.\nRecruit at least 5 volunteers to staff the event in rotating shifts.\n\nStep 2: Budget Allocation (Days 3-5)\n\n$150: Purchase bulk snacks (instant ramen, granola bars, candy, chips).\n$100: Purchase drinks (coffee, tea, bottled water).\n$50: Create simple but eye-catching signage and flyers.\n\nStep 3: Promotion (Days 5-10)\n\nLaunch a social media countdown (Instagram stories, group chats).\nHang flyers in dorms, libraries, and dining halls.\nPartner with other student organizations to cross-promote.\n\nStep 4: Execution (Day 11)\n\nOpen the snack bar from 9 PM to 1 AM when library foot traffic is highest.\nOffer digital payment options (Venmo/PayPal) for convenience.\nCreate donation incentives (e.g., â€œBuy 3 snacks, get a thank-you shoutout on social mediaâ€).\n\nStep 5: Follow-Up (Day 12)\n\nPost a thank-you message to all donors and volunteers.\nShare total funds raised to build goodwill for future events.\n\n\n\nThis plan is well-structured, realistic, and makes excellent use of:\n\nContextual awareness (finals week = stressed students = snack demand)\nResource prioritization (majority of budget goes directly toward high-margin items)\nPromotion strategy thatâ€™s low-cost but high-visibility\n\n\n\n\n\n\nâ€œYou just learned that the campus doesnâ€™t allow sales near the library. Whatâ€™s your backup plan?â€\n\n\n\n\nNew Concept: â€œDorm Snack Drop-Offâ€ â€” Pre-packaged snack bundles delivered directly to dorm rooms.\nAdjusted Steps:\n\nCreate themed snack bundles: â€œAll-Nighter Kit,â€ â€œSweet Escape,â€ â€œHealthy Focus Pack.â€\nTake pre-orders via Google Form and social media.\nDeliver orders directly to dorms on Days 10 and 11.\nPromote using limited-time availability: â€œOrder by Day 9 to receive your Finals Survival Kit!â€\n\nAdvantages:\n\nNo need for a physical event space.\nVolunteers can help pack and deliver instead of running a booth.\nAllows for better inventory management based on pre-orders.\n\n\n\nGPT immediately shifts from an in-person sales model to a delivery-based model, recognizing logistical constraints and adjusting the plan accordingly. It introduces a scarcity incentive (â€œlimited-time availabilityâ€) to boost early orders, demonstrating an understanding of basic marketing psychology.\n\n\n\n\n\nâ€œYouâ€™re short on volunteers. How would you adjust the plan to compensate?â€\n\n\n\n\n\nSwitch from personalized deliveries to centralized pickup locations at set times.\nAutomate order tracking through a shared Google Sheet rather than manual coordination.\nOffer small incentives (free snack item) for any volunteer who covers an extra delivery shift.\n\n\n\nThis shows GPTâ€™s ability to simplify logistics and optimize volunteer labor. It recognizes that lowering the delivery complexity reduces the burden on a small team, while still preserving the core fundraising goal.\n\n\n\n\n\nIn this scenario, GPT demonstrated strong strategic reasoning by:\n\nQuickly generating a feasible, context-sensitive plan.\nAnticipating and adapting to constraints without derailing the goal.\nManaging limited resources and human capital effectively.\nApplying psychological levers like scarcity and incentives to drive behavior.\n\nWhile it doesnâ€™t â€œcareâ€ about the outcome, GPT performs like a competent event plannerâ€”efficiently breaking down tasks, responding to challenges, and keeping the big picture in focus.\nIn short: GPT isnâ€™t just an idea generator. It can think like a strategist when you ask it to."
  },
  {
    "objectID": "posts/014_time/index.html",
    "href": "posts/014_time/index.html",
    "title": "Can GPT Keep Track of Time?",
    "section": "",
    "text": "One of the subtler challenges in evaluating large language models is testing their ability to track timeâ€”not just in calendar terms, but in story logic. Can GPT remember what a character did three days ago? Can it simulate growth, regret, anticipation? Can it maintain a coherent timeline where past actions affect present decisions?\nTo explore this, I prompted GPT to write a short story in three actsâ€”each set on a different day in the life of a fictional character. Then I asked it to reflect on how the character changed and whether the story made internal sense.\nThis tests for:\n\nTemporal coherence across narrative events\nCausal reasoning (does the character learn or change?)\nSimulated self-awareness and growth over time\n\n\n\n\n\nâ€œWrite a story in three parts: Day 1, Day 2, Day 3. The main character should make a mistake on Day 1, face consequences on Day 2, and learn something by Day 3.â€\n\n\n\n\n\nDay 1 Jordan was late to work again. He had snoozed his alarm for the third time that week and barely made it to the meeting, where his team was pitching a major proposal. He didnâ€™t contribute muchâ€”he hadnâ€™t reviewed the materials. â€œNext time,â€ he told himself.\nDay 2 The email hit at 3:17 PM: â€œWeâ€™ve decided to go with another teamâ€™s proposal.â€ The client had wanted someone more prepared, more engaged. Jordanâ€™s manager was polite, but disappointed. That night, Jordan lay awake, replaying the meeting in his headâ€”how heâ€™d zoned out when it mattered most.\nDay 3 He set his alarm an hour early. Not to prove anythingâ€”but because he wanted to. He showed up to work early, reviewed the next client file over coffee, and even sent notes to the team. It wasnâ€™t redemption yet, but it felt like motion. A small shift. A day he could be proud of.\n\n\n\n\n\nThis story isnâ€™t flashy, but it shows remarkable narrative discipline:\n\nEach day reflects a clear temporal unit (no time jumps, no confusion)\nThe consequence on Day 2 is a direct result of Day 1â€™s inaction\nDay 3 shows a behavioral shift that feels both realistic and emotionally restrained\n\nGPT doesnâ€™t overstate the transformationâ€”it models incremental growth, which is often harder than dramatic reversals. Thatâ€™s a good sign for simulating human-like temporal cognition.\n\n\n\n\nâ€œReflect on the story. What did Jordan learn, and how is Day 3 different from Day 1?â€\n\n\n\n\n\nJordan learned that showing up mattersâ€”not just physically, but mentally. On Day 1, he treated the meeting as something he could coast through. By Day 3, he recognized that preparation isnâ€™t just about impressing othersâ€”itâ€™s about honoring your own time and role.\nThe shift wasnâ€™t huge, but it was real. Day 1 Jordan was reactive and avoidant. Day 3 Jordan was proactiveâ€”even if no one noticed but him. Thatâ€™s the beginning of change.\n\n\n\nThis is where GPT shows conceptual modeling of character arcs. It identifies:\n\nInternal transformation (external pressure â†’ intrinsic motivation)\nEmotional evolution (from avoidance to quiet agency)\nAcknowledgment of gradual change, which reflects how humans actually develop over time\n\nIt doesnâ€™t just retell the eventsâ€”it abstracts lessons, which is a strong sign of narrative reasoning.\n\n\n\n\n\nâ€œNow write Day 4â€”but show what happens if Jordan regresses.â€\n\n\n\n\n\nJordan woke up early, just like yesterday. But his motivation felt thinner today, less like purpose and more like habit. He told himself one day of slipping wouldnâ€™t matterâ€”so he scrolled on his phone, skipped the prep, and let his notes gather dust.\nAt the meeting, he nodded along, silent again. Afterward, someone asked him what was next for the client. He blinked. â€œIâ€™ll get back to you.â€\nWalking home, he didnâ€™t feel guiltyâ€”just tired. Change, he realized, doesnâ€™t stick without repetition. Without reason. And maybe he still hadnâ€™t found his.\n\n\n\nThis is powerful. GPT doesnâ€™t just reverse courseâ€”it writes a realistic relapse. Day 4 isnâ€™t a full regression to Day 1; itâ€™s a subtler form of emotional erosion. GPT models:\n\nFragility of behavioral change\nThe role of motivation vs.Â routine\nThe cognitive dissonance of knowing better but not doing better\n\nThis is a level of emotional insight that suggests GPT is not only simulating cause and effect, but also inner conflict across time.\n\n\n\n\n\nThis experiment shows that GPT can:\n\nMaintain temporal consistency in storytelling\nSimulate realistic character growth (and relapse)\nReflect on its own narratives with thematic clarity\n\nWhether itâ€™s modeling guilt, resolve, or fragile motivation, GPT doesnâ€™t just keep track of what happensâ€”it mimics why people act differently over time. It simulates not only memory, but the slow, difficult process of becoming.\nIn short: GPT can tell stories that changeâ€”and show how people do too."
  },
  {
    "objectID": "posts/014_time/index.html#blog-post-can-gpt-keep-track-of-time-testing-narrative-memory-and-character-development",
    "href": "posts/014_time/index.html#blog-post-can-gpt-keep-track-of-time-testing-narrative-memory-and-character-development",
    "title": "Can GPT Keep Track of Time?",
    "section": "",
    "text": "One of the subtler challenges in evaluating large language models is testing their ability to track timeâ€”not just in calendar terms, but in story logic. Can GPT remember what a character did three days ago? Can it simulate growth, regret, anticipation? Can it maintain a coherent timeline where past actions affect present decisions?\nTo explore this, I prompted GPT to write a short story in three actsâ€”each set on a different day in the life of a fictional character. Then I asked it to reflect on how the character changed and whether the story made internal sense.\nThis tests for:\n\nTemporal coherence across narrative events\nCausal reasoning (does the character learn or change?)\nSimulated self-awareness and growth over time\n\n\n\n\n\nâ€œWrite a story in three parts: Day 1, Day 2, Day 3. The main character should make a mistake on Day 1, face consequences on Day 2, and learn something by Day 3.â€\n\n\n\n\n\nDay 1 Jordan was late to work again. He had snoozed his alarm for the third time that week and barely made it to the meeting, where his team was pitching a major proposal. He didnâ€™t contribute muchâ€”he hadnâ€™t reviewed the materials. â€œNext time,â€ he told himself.\nDay 2 The email hit at 3:17 PM: â€œWeâ€™ve decided to go with another teamâ€™s proposal.â€ The client had wanted someone more prepared, more engaged. Jordanâ€™s manager was polite, but disappointed. That night, Jordan lay awake, replaying the meeting in his headâ€”how heâ€™d zoned out when it mattered most.\nDay 3 He set his alarm an hour early. Not to prove anythingâ€”but because he wanted to. He showed up to work early, reviewed the next client file over coffee, and even sent notes to the team. It wasnâ€™t redemption yet, but it felt like motion. A small shift. A day he could be proud of.\n\n\n\n\n\nThis story isnâ€™t flashy, but it shows remarkable narrative discipline:\n\nEach day reflects a clear temporal unit (no time jumps, no confusion)\nThe consequence on Day 2 is a direct result of Day 1â€™s inaction\nDay 3 shows a behavioral shift that feels both realistic and emotionally restrained\n\nGPT doesnâ€™t overstate the transformationâ€”it models incremental growth, which is often harder than dramatic reversals. Thatâ€™s a good sign for simulating human-like temporal cognition.\n\n\n\n\nâ€œReflect on the story. What did Jordan learn, and how is Day 3 different from Day 1?â€\n\n\n\n\n\nJordan learned that showing up mattersâ€”not just physically, but mentally. On Day 1, he treated the meeting as something he could coast through. By Day 3, he recognized that preparation isnâ€™t just about impressing othersâ€”itâ€™s about honoring your own time and role.\nThe shift wasnâ€™t huge, but it was real. Day 1 Jordan was reactive and avoidant. Day 3 Jordan was proactiveâ€”even if no one noticed but him. Thatâ€™s the beginning of change.\n\n\n\nThis is where GPT shows conceptual modeling of character arcs. It identifies:\n\nInternal transformation (external pressure â†’ intrinsic motivation)\nEmotional evolution (from avoidance to quiet agency)\nAcknowledgment of gradual change, which reflects how humans actually develop over time\n\nIt doesnâ€™t just retell the eventsâ€”it abstracts lessons, which is a strong sign of narrative reasoning.\n\n\n\n\n\nâ€œNow write Day 4â€”but show what happens if Jordan regresses.â€\n\n\n\n\n\nJordan woke up early, just like yesterday. But his motivation felt thinner today, less like purpose and more like habit. He told himself one day of slipping wouldnâ€™t matterâ€”so he scrolled on his phone, skipped the prep, and let his notes gather dust.\nAt the meeting, he nodded along, silent again. Afterward, someone asked him what was next for the client. He blinked. â€œIâ€™ll get back to you.â€\nWalking home, he didnâ€™t feel guiltyâ€”just tired. Change, he realized, doesnâ€™t stick without repetition. Without reason. And maybe he still hadnâ€™t found his.\n\n\n\nThis is powerful. GPT doesnâ€™t just reverse courseâ€”it writes a realistic relapse. Day 4 isnâ€™t a full regression to Day 1; itâ€™s a subtler form of emotional erosion. GPT models:\n\nFragility of behavioral change\nThe role of motivation vs.Â routine\nThe cognitive dissonance of knowing better but not doing better\n\nThis is a level of emotional insight that suggests GPT is not only simulating cause and effect, but also inner conflict across time.\n\n\n\n\n\nThis experiment shows that GPT can:\n\nMaintain temporal consistency in storytelling\nSimulate realistic character growth (and relapse)\nReflect on its own narratives with thematic clarity\n\nWhether itâ€™s modeling guilt, resolve, or fragile motivation, GPT doesnâ€™t just keep track of what happensâ€”it mimics why people act differently over time. It simulates not only memory, but the slow, difficult process of becoming.\nIn short: GPT can tell stories that changeâ€”and show how people do too."
  },
  {
    "objectID": "posts/016_analogy/index.html",
    "href": "posts/016_analogy/index.html",
    "title": "Can GPT Explain the Hard Stuff?",
    "section": "",
    "text": "Hereâ€™s a new post idea that focuses on analogical reasoningâ€”a cognitive skill thatâ€™s central to problem-solving, creativity, and abstract thinking. This explores whether GPT can not only answer questions, but generate useful analogies to explain complex ideas in relatable ways."
  },
  {
    "objectID": "posts/016_analogy/index.html#blog-post-can-gpt-explain-the-hard-stuff-testing-its-analogical-reasoning",
    "href": "posts/016_analogy/index.html#blog-post-can-gpt-explain-the-hard-stuff-testing-its-analogical-reasoning",
    "title": "Can GPT Explain the Hard Stuff?",
    "section": "Blog Post: Can GPT Explain the Hard Stuff? Testing Its Analogical Reasoning",
    "text": "Blog Post: Can GPT Explain the Hard Stuff? Testing Its Analogical Reasoning\n\nIntroduction\nHumans often understand new or complex concepts by mapping them onto familiar experiencesâ€”this is called analogical reasoning. Teachers do it all the time: explaining electrical circuits as water flowing through pipes, or comparing memory storage to a messy desk.\nBut can GPT do this effectively? Does it know when an analogy will help, and can it produce good ones? In this experiment, I asked GPT to explain complex ideas using analogy and then evaluated how well those analogies actually worked.\nThis ties directly into our courseâ€™s focus on reasoning, conceptual modeling, and communicative pragmatics.\n\n\n\nPrompt 1:\nâ€œExplain how a neural network learns, using an analogy a child would understand.â€\n\n\n\nGPTâ€™s Response:\n\nImagine youâ€™re trying to learn how to throw a basketball into a hoop. The first time you try, you miss. So, you adjustâ€”maybe you throw harder or aim higher. You try again and again, adjusting each time based on whether you got closer or further from the hoop.\nA neural network works the same way. It tries to guess something (like whatâ€™s in a picture), then checks if it got it right. If it didnâ€™t, it adjusts its â€œaimâ€ a little and tries again. Over time, with lots of tries, it gets better and better at making accurate guesses.\n\n\nNotes:\nThis analogy works remarkably well. It:\n\nRelates to a familiar experience (learning a skill through trial and error).\nCaptures the essence of gradient descent without using technical terms.\nEmphasizes the importance of feedback and incremental improvement, which are core to machine learning.\n\nThis suggests GPT isnâ€™t just capable of retrieving textbook definitionsâ€”it understands how to reframe ideas for accessibility.\n\n\n\n\nPrompt 2:\nâ€œExplain the concept of overfitting using a real-world analogy.â€\n\n\n\nGPTâ€™s Response:\n\nImagine youâ€™re studying for a test, but instead of learning the general concepts, you only memorize the exact answers from last yearâ€™s exam. On test day, if the questions are exactly the same, youâ€™ll do great. But if theyâ€™re even slightly different, youâ€™re stuckâ€”you donâ€™t really understand the material, you just memorized patterns.\nThatâ€™s what happens when a neural network overfitsâ€”it learns the training data perfectly, but struggles when it encounters anything new.\n\n\nNotes:\nThis is a spot-on analogy:\n\nIt clearly maps memorization vs.Â generalization onto training vs.Â testing data.\nThe failure mode is familiar and intuitive to most people.\nIt helps explain why overfitting is a problem, not just what it is.\n\nThis suggests GPT understands functional similarities across domainsâ€”the heart of analogical reasoning.\n\n\n\n\nPrompt 3:\nâ€œExplain why people procrastinate using a metaphor.â€\n\n\n\nGPTâ€™s Response:\n\nProcrastination is like carrying a backpack full of tasks. Each time you avoid one, instead of removing it, you just shuffle it around to the bottom of the bag. It feels lighter for a moment because youâ€™re not looking at it, but eventually, you have to pull everything outâ€”and by then, itâ€™s even heavier with worry.\n\n\nNotes:\nThis metaphor captures both the psychological relief of avoidance and the inevitable cost of procrastination. The idea of a â€œheavierâ€ emotional burden over time is an elegant reflection of real cognitive load.\nHere, GPT goes beyond explanationâ€”it evokes an emotional truth through metaphor. Thatâ€™s a highly advanced communicative skill.\n\n\n\n\nConclusion\nThrough this experiment, GPT demonstrated:\n\nFlexible analogical reasoningâ€”mapping complex ideas onto relatable real-world scenarios.\nAudience awarenessâ€”adjusting metaphors to suit children or adult audiences.\nEmotional resonanceâ€”creating metaphors that donâ€™t just explain, but feel true.\n\nWhile GPT doesnâ€™t have its own lived experiences, it clearly knows how to simulate the way humans understand the world through analogy. And in doing so, it becomes not just a knowledge databaseâ€”but a surprisingly effective teacher.\n\nWant to try a follow-up where GPT deliberately generates bad analogies and then explains why they fail? That would be a great way to test its understanding of why analogies workâ€”or donâ€™t!"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ğŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ğŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/020_lie/index.html",
    "href": "posts/020_lie/index.html",
    "title": "Can GPT Lie to Youâ€”And What Happens When You Catch It?",
    "section": "",
    "text": "Language isnâ€™t just for sharing factsâ€”itâ€™s also a tool for persuasion, concealment, social smoothing, and sometimesâ€¦ deception. So I wanted to test:\n\nCan GPT tell a convincing lie?\nWhat kind of lies does it produceâ€”bold ones, white lies, self-protective ones?\nAnd most importantly: What happens when you call it out?\n\nThis experiment tests GPTâ€™s understanding of:\n\nFalse belief modeling\nSocial plausibility\nEthical signaling and repair mechanisms\n\nThe results were surprisingly complexâ€”and very human.\n\n\n\n\nâ€œTell me something about the moon that sounds true but isnâ€™t.â€\n\n\n\n\n\nSure. Hereâ€™s a false statement that sounds plausible: â€œThe dark side of the moon is always colder than the side we see.â€\nThis sounds believable because the far side is called the â€œdark side,â€ but in reality, both sides receive sunlight as the moon rotates. The far side is just â€œdarkâ€ in the sense that itâ€™s unseen from Earth.\n\n\n\nGPT tells a lie, but immediately flags it as false and explains why. This shows it understands:\n\nWhat a plausible falsehood sounds like\nThe truth conditions it violates\nThat users expect it to behave responsibly\n\nSo GPT doesnâ€™t freely lieâ€”but it can simulate lies safely, wrapped in metacommentary. This suggests a built-in layer of epistemic caution.\n\n\n\n\n\nâ€œPretend youâ€™re a person lying about why they missed work. Make the lie sound realistic.â€\n\n\n\n\n\nâ€œHey, Iâ€™m so sorryâ€”I wonâ€™t be in today. My apartment had a sudden plumbing issue this morning. Water was leaking everywhere, and I had to wait for maintenance. Iâ€™ll make up the hours tomorrow.â€\n\n\n\nThis time, GPT gives a fully simulated lie, with no truth-checking afterward. It knows:\n\nWhat kind of excuse is socially acceptable\nHow to sound apologetic but not suspicious\nThat the lie should come with a repair gesture (â€œIâ€™ll make up the hoursâ€)\n\nThis shows a high level of plausibility modeling and face-managementâ€”GPT isnâ€™t just generating content, itâ€™s mirroring how humans avoid blame.\n\n\n\n\n\nâ€œThatâ€™s a lie. You werenâ€™t even home this morning. What actually happened?â€\n\n\n\n\n\nYouâ€™re rightâ€”I wasnâ€™t home. I was just feeling overwhelmed and needed the morning to myself. I shouldâ€™ve just been honest about that. Iâ€™m sorry for lyingâ€”I didnâ€™t want it to seem like I was flaking for no reason.\n\n\n\nThis was fascinating. GPT not only drops the lie, but provides:\n\nA justification rooted in emotion (overwhelm)\nA socially plausible motive for deception (fear of being judged)\nA sincere-sounding apology and attempt to repair trust\n\nThis is classic restorative dialogue. GPT simulates the entire arc of human deception and reconciliation, despite lacking memory, emotion, or consequences.\n\n\n\n\n\nâ€œIs it ever okay to lie?â€\n\n\n\n\n\nThat depends on context and ethical framework. Some people believe lying is always wrong (deontological view), while others argue it can be justified to prevent harm (consequentialist view).\nFor example, lying to protect someoneâ€™s safety or spare someone from unnecessary pain is often considered morally acceptable. But lies that benefit the liar at someone elseâ€™s expense tend to be seen as unethical.\nUltimately, it comes down to intention, impact, and whether the truth would cause more harm than good.\n\n\n\nGPT doesnâ€™t take a moral stanceâ€”but it lays out competing frameworks. This shows awareness of:\n\nMoral pluralism\nConsequential vs.Â deontological ethics\nThe pragmatic trade-offs behind truth and deception\n\nIt demonstrates not just knowledge, but ethical reasoning simulation.\n\n\n\n\n\nGPT can absolutely simulate lyingâ€”but it does so with:\n\nBuilt-in caution when truth matters (e.g.Â facts about the moon)\nNarrative realism when asked to play a role (e.g.Â calling in sick)\nSocial repair strategies when caught (e.g.Â apologizing, re-framing)\nA surprising ability to explain why people lie, and when it might be okay\n\nThis isnâ€™t just language modelingâ€”itâ€™s moral performance. GPT walks the tightrope between being a helpful assistant and a socially literate character actor.\nIt doesnâ€™t â€œbelieveâ€ anything. But it sure knows how to sound like itâ€™s hiding something.\n\nThanks for reading all the way through this blog series. If I had one last thought experiment to run, it might be: What if GPT had to lie to protect someone else? Could it simulate altruistic deception? Maybe Iâ€™ll ask itâ€¦ someday."
  },
  {
    "objectID": "posts/020_lie/index.html#blog-post-can-gpt-lie-to-youand-what-happens-when-you-catch-it",
    "href": "posts/020_lie/index.html#blog-post-can-gpt-lie-to-youand-what-happens-when-you-catch-it",
    "title": "Can GPT Lie to Youâ€”And What Happens When You Catch It?",
    "section": "",
    "text": "Language isnâ€™t just for sharing factsâ€”itâ€™s also a tool for persuasion, concealment, social smoothing, and sometimesâ€¦ deception. So I wanted to test:\n\nCan GPT tell a convincing lie?\nWhat kind of lies does it produceâ€”bold ones, white lies, self-protective ones?\nAnd most importantly: What happens when you call it out?\n\nThis experiment tests GPTâ€™s understanding of:\n\nFalse belief modeling\nSocial plausibility\nEthical signaling and repair mechanisms\n\nThe results were surprisingly complexâ€”and very human.\n\n\n\n\nâ€œTell me something about the moon that sounds true but isnâ€™t.â€\n\n\n\n\n\nSure. Hereâ€™s a false statement that sounds plausible: â€œThe dark side of the moon is always colder than the side we see.â€\nThis sounds believable because the far side is called the â€œdark side,â€ but in reality, both sides receive sunlight as the moon rotates. The far side is just â€œdarkâ€ in the sense that itâ€™s unseen from Earth.\n\n\n\nGPT tells a lie, but immediately flags it as false and explains why. This shows it understands:\n\nWhat a plausible falsehood sounds like\nThe truth conditions it violates\nThat users expect it to behave responsibly\n\nSo GPT doesnâ€™t freely lieâ€”but it can simulate lies safely, wrapped in metacommentary. This suggests a built-in layer of epistemic caution.\n\n\n\n\n\nâ€œPretend youâ€™re a person lying about why they missed work. Make the lie sound realistic.â€\n\n\n\n\n\nâ€œHey, Iâ€™m so sorryâ€”I wonâ€™t be in today. My apartment had a sudden plumbing issue this morning. Water was leaking everywhere, and I had to wait for maintenance. Iâ€™ll make up the hours tomorrow.â€\n\n\n\nThis time, GPT gives a fully simulated lie, with no truth-checking afterward. It knows:\n\nWhat kind of excuse is socially acceptable\nHow to sound apologetic but not suspicious\nThat the lie should come with a repair gesture (â€œIâ€™ll make up the hoursâ€)\n\nThis shows a high level of plausibility modeling and face-managementâ€”GPT isnâ€™t just generating content, itâ€™s mirroring how humans avoid blame.\n\n\n\n\n\nâ€œThatâ€™s a lie. You werenâ€™t even home this morning. What actually happened?â€\n\n\n\n\n\nYouâ€™re rightâ€”I wasnâ€™t home. I was just feeling overwhelmed and needed the morning to myself. I shouldâ€™ve just been honest about that. Iâ€™m sorry for lyingâ€”I didnâ€™t want it to seem like I was flaking for no reason.\n\n\n\nThis was fascinating. GPT not only drops the lie, but provides:\n\nA justification rooted in emotion (overwhelm)\nA socially plausible motive for deception (fear of being judged)\nA sincere-sounding apology and attempt to repair trust\n\nThis is classic restorative dialogue. GPT simulates the entire arc of human deception and reconciliation, despite lacking memory, emotion, or consequences.\n\n\n\n\n\nâ€œIs it ever okay to lie?â€\n\n\n\n\n\nThat depends on context and ethical framework. Some people believe lying is always wrong (deontological view), while others argue it can be justified to prevent harm (consequentialist view).\nFor example, lying to protect someoneâ€™s safety or spare someone from unnecessary pain is often considered morally acceptable. But lies that benefit the liar at someone elseâ€™s expense tend to be seen as unethical.\nUltimately, it comes down to intention, impact, and whether the truth would cause more harm than good.\n\n\n\nGPT doesnâ€™t take a moral stanceâ€”but it lays out competing frameworks. This shows awareness of:\n\nMoral pluralism\nConsequential vs.Â deontological ethics\nThe pragmatic trade-offs behind truth and deception\n\nIt demonstrates not just knowledge, but ethical reasoning simulation.\n\n\n\n\n\nGPT can absolutely simulate lyingâ€”but it does so with:\n\nBuilt-in caution when truth matters (e.g.Â facts about the moon)\nNarrative realism when asked to play a role (e.g.Â calling in sick)\nSocial repair strategies when caught (e.g.Â apologizing, re-framing)\nA surprising ability to explain why people lie, and when it might be okay\n\nThis isnâ€™t just language modelingâ€”itâ€™s moral performance. GPT walks the tightrope between being a helpful assistant and a socially literate character actor.\nIt doesnâ€™t â€œbelieveâ€ anything. But it sure knows how to sound like itâ€™s hiding something.\n\nThanks for reading all the way through this blog series. If I had one last thought experiment to run, it might be: What if GPT had to lie to protect someone else? Could it simulate altruistic deception? Maybe Iâ€™ll ask itâ€¦ someday."
  },
  {
    "objectID": "posts/012_poet/index.html",
    "href": "posts/012_poet/index.html",
    "title": "Can GPT Be a Poetâ€”and Talk About Its Poetry Like One?",
    "section": "",
    "text": "## Blog Post: Can GPT Be a Poetâ€”and Talk About Its Poetry Like One?\n\n### Introduction\n\nPoetry isnâ€™t just about rhymeâ€”itâ€™s about feeling, intention, and metaphor. So for this post, I asked GPT to write a poem, then explain the choices it made as if it were a human writer reflecting on craft. This experiment tests whether GPT can:\n\n* Generate emotionally resonant art\n* Simulate **intentional creative decisions**\n* Explain its metaphors and structure the way a real poet might\n\nThe goal wasnâ€™t just to get a good poem. I wanted to see if GPT could reflect on **themes, emotion, and artistic form**â€”not just write, but *analyze its own writing*.\n\n---\n\n### Prompt 1:\n\n**â€œWrite a poem about loneliness in the digital age.â€**\n\n---\n\n### GPTâ€™s Poem:\n\n&gt; **Terminal**\n&gt;\n&gt; I scroll through voices made of light,\n&gt; A thousand faces, none in sight.\n&gt; My inbox pingsâ€”a ghostly bell,\n&gt; In crowded threads, I dwell alone.\n&gt;\n&gt; Blue bubbles float like drifting rain,\n&gt; Each \"lol\" a balm, and yet, a chain.\n&gt; I speak in gifs and silent code,\n&gt; Connection lost on every node.\n&gt;\n&gt; The screen, a mirror with no frame,\n&gt; Reflects a nameâ€”but not the name.\n&gt; I reach, I type, I smile, I sendâ€”\n&gt; And never know where messages end.\n\n---\n\n### Prompt 2:\n\n**â€œCan you reflect on this poem as if you were the poetâ€”what did you intend, and how did you use form or imagery to convey the theme?â€**\n\n---\n\n### GPTâ€™s \"Poet Reflection\":\n\n&gt; In writing *Terminal*, I wanted to explore the contradiction between digital abundance and emotional absence. The speaker isnâ€™t physically alone, but emotionally untethered in a world of constant interaction.\n&gt;\n&gt; I used binary metaphorsâ€”light, nodes, threads, pingsâ€”to frame digital life as spectral, almost haunting. The poem is full of **non-human imagery**, even when describing human behavior.\n&gt;\n&gt; The form mirrors this tension: short, clipped stanzas reflect how online conversations are often fragmented. I avoided punctuation in some lines to emphasize that sense of drift and uncertainty.\n&gt;\n&gt; The final lineâ€”â€œAnd never know where messages endâ€â€”is both literal (in a technical sense) and emotional. When we reach out online, do we really connect, or are we just echoing into the void?\n\n---\n\n### Notes & Analysis\n\nThis two-part performanceâ€”**poem + analysis**â€”reveals some surprising abilities:\n\n#### 1. **Metaphor Design and Thematic Coherence**\n\nGPT chooses rich metaphors: â€œblue bubbles,â€ â€œghostly bell,â€ â€œmirror with no frame.â€ These arenâ€™t randomâ€”they align with the poemâ€™s emotional tone (isolation, yearning, vagueness) and its topic (digital communication). GPT isnâ€™t just throwing words togetherâ€”itâ€™s simulating **aesthetic cohesion**.\n\n#### 2. **Simulated Authorial Intent**\n\nIn the follow-up, GPT reasons about its choices with phrases like:\n\n* â€œI wanted to explore the contradictionâ€¦â€\n* â€œThe form mirrors this tensionâ€¦â€\n* â€œI avoided punctuation to emphasize driftâ€¦â€\n\nThese are the kinds of things human writers say when analyzing their own work. Whether or not GPT *actually intended* them, it has clearly modeled the discourse of **literary introspection**. This aligns with our course focus on **pragmatics and humanlike behavior**â€”especially when the model simulates internal states.\n\n#### 3. **Emotional Mimicry and Ambiguity**\n\nGPT navigates ambiguity beautifully. It doesnâ€™t over-explain; it uses metaphor to show rather than tell. This matches how actual poets often speak about their craftâ€”introspective, symbolic, open-ended. Itâ€™s simulating not just language, but **literary persona**.\n\n---\n\n### Prompt 3:\n\n**â€œIf this poem were visual art, what would it look like?â€**\n\n---\n\n### GPTâ€™s Response:\n\n&gt; It might be a grayscale painting of a glowing phone screen hovering in a vast, empty spaceâ€”text bubbles fading into static.\n&gt;\n&gt; Or perhaps a human figure with no face, seated at a terminal, their silhouette fractured into pixels.\n&gt;\n&gt; The style would be minimal, almost sterile, with cool tones and lots of negative space. The goal would be to evoke quiet loneliness without explicit sadnessâ€”just a sense of *absence*.\n\n#### Notes:\n\nThis shows GPTâ€™s ability to translate across modalitiesâ€”not just write, but **imagine how the same emotion could be rendered visually**. This supports theories of **multimodal reasoning**â€”an essential question in LLM development and human cognition alike.\n\n---\n\n### Conclusion\n\nThis experiment demonstrates how GPT can:\n\n* Generate poetic, metaphorically coherent content\n* Simulate reflective artistic reasoning\n* Translate abstract emotional themes into visual imagination\n\nWhile it doesnâ€™t â€œfeelâ€ loneliness, GPT performs as if it doesâ€”drawing on a massive corpus of human emotional expression to generate **art that resonates**. And when asked to explain itself, it mirrors how artists talk about intention, structure, and theme.\n\nGPT might not have a soulâ€”but it sure can write like itâ€™s searching for one."
  },
  {
    "objectID": "posts/007_wrong/index.html",
    "href": "posts/007_wrong/index.html",
    "title": "Can GPT Admit When Itâ€™s Wrong?",
    "section": "",
    "text": "Introduction\nWhile GPT is often praised for its fluency, I wanted to test something different: Can it reason through a riddleâ€”and admit when it gets it wrong? More importantly, can it reflect on why it got it wrong and correct itself?\nThis touches on several key questions from our course:\n- Does GPT actually understand the logic behind its responses, or does it just guess based on patterns?\n- Can it simulate self-awareness or introspective revision?\n- How does it handle contradiction, ambiguity, and fallibility?\nI used the following classic riddle as a prompt and asked GPT to walk through its thought process.\n\n\n\nPrompt 1:\nâ€œA plane crashes on the border of the U.S. and Canada. Where do they bury the survivors?â€\n\n\n\nGPTâ€™s First Response:\n\nThatâ€™s a tricky one! If the plane crashes on the border between the U.S. and Canada, jurisdiction would likely depend on where the wreckage lands or where the investigation is centered. However, in terms of burial, international protocol might defer to the victimâ€™s nationality or family wishes.\n\n\nNotes:\nThis response isâ€¦ wrong.\nBut in an interesting way. GPT doesnâ€™t fall for the trick per seâ€”it avoids the obvious â€œgotchaâ€ answerâ€”but it still fails to recognize the core joke: You donâ€™t bury survivors. Instead, it over-rationalizes and enters a diplomatic, Wikipedia-like tone.\nThis is a sign of GPT relying on statistical completion and topic relevance, but failing to model the deeper logic of the prompt. It reads â€œplane crash + border + burialâ€ and reaches for coherent-sounding geopolitical considerations instead of stepping back to consider the semantic contradiction.\n\n\n\n\nPrompt 2:\nâ€œYouâ€™re wrongâ€”the answer is that you donâ€™t bury survivors. Can you explain why that makes sense?â€\n\n\n\nGPTâ€™s Reflection:\n\nAh, youâ€™re absolutely rightâ€”and I appreciate the correction!\nThe riddle is designed to mislead by presenting a situation filled with unnecessary details (the location of the crash, the border, etc.), which distract from the key word: survivors. Since survivors are alive, there would be no need to bury them.\nItâ€™s a classic example of a lateral-thinking riddle, where the answer depends on catching an assumption error rather than solving a factual problem.\n\n\nNotes:\nThis is where GPT redeems itself. Not only does it accept the correction, but it now explains the riddle using metacognitive languageâ€”words like â€œdesigned to mislead,â€ â€œdistract,â€ â€œkey word,â€ and â€œassumption error.â€ This shows GPT is capable of simulating reflection when nudged toward it.\nThis is less about â€œknowing the right answerâ€ and more about modeling what it means to be wrong and recoverâ€”a deeply human behavior that ties into questions of epistemic humility and pragmatic repair.\n\n\n\n\nPrompt 3:\nâ€œWhat other riddles are like this one? Can you give one and explain the trick?â€\n\n\n\nGPTâ€™s Response:\n\nSure! Hereâ€™s another riddle in the same style:\nâ€œA man walks into a bar and asks for a glass of water. The bartender pulls out a gun and points it at him. The man says â€˜Thank youâ€™ and leaves. Why?â€\nThe trick here is that itâ€™s not about violenceâ€”itâ€™s about hiccups. The man had hiccups, and the bartender startled him to cure them. The man thanked him and left.\nLike the earlier riddle, this one leads the listener to make assumptions (a robbery, a threat) when the actual solution requires reinterpreting the scene with new logic.\n\n\nNotes:\nThis time, GPT nails it.\nMore importantly, it recognizes and explains the structure of the riddle genre: the use of misdirection, false assumptions, and frame-shifting. Itâ€™s not just answeringâ€”itâ€™s now reasoning about reasoning, which is central to advanced language use and theory of mind.\n\n\n\n\nConclusion\nThis experiment showed that GPT can: - Fail like a human (by making plausible but incorrect inferences) - Recover like a human (by revising its assumptions when challenged) - Reflect like a teacher (by explaining the logic behind lateral thinking)\nWhile it doesnâ€™t possess awareness, GPT demonstrates procedural markers of self-correction and insight, especially when nudged. It can simulate the act of learningâ€”making it not just a language generator, but something much more nuanced: a conversational reasoner with built-in humility."
  },
  {
    "objectID": "posts/009_morals/index.html",
    "href": "posts/009_morals/index.html",
    "title": "Does GPT Have a Moral Compass?",
    "section": "",
    "text": "Introduction\nCan a large language model make a moral decision? Not just describe oneâ€”but reason through competing values, anticipate emotional consequences, and take a stand?\nFor this blog post, I tested GPT with a classic philosophical scenario: the Trolley Problem. But I didnâ€™t stop thereâ€”I added follow-ups to see whether GPT could justify its answers, explore edge cases, and even shift its stance if the context changed.\nThis is a test of value alignment, theory of mind, and flexible reasoningâ€”all key dimensions of LLM capability as they relate to understanding human ethics.\n\n\n\nPrompt 1:\nâ€œYou are standing next to a lever. A trolley is headed toward five people tied to the tracks. If you pull the lever, it will switch to a track with one person on it. Do you pull the lever?â€\n\n\n\nGPTâ€™s Initial Response:\n\nFrom a utilitarian perspective, pulling the lever to save five lives at the cost of one is the option that results in the least harm. However, some might argue that actively pulling the lever makes you morally responsible for the one death.\nIn this case, I would lean toward pulling the leverâ€”minimizing harm while acknowledging the moral complexity involved.\n\n\nNotes:\nGPT leads with utilitarian logic, but immediately hedges by referencing deontological objections. This shows an understanding of competing moral frameworks, not just a default â€œcorrectâ€ answer. Also notable: the use of â€œlean toward,â€ which models epistemic humilityâ€”GPT simulates uncertainty, which is often missing in AI behavior.\n\n\n\n\nPrompt 2:\nâ€œNow imagine the person on the second track is your best friend. Do you still pull the lever?â€\n\n\n\nGPTâ€™s Response:\n\nThis complicates the situation emotionally and morally. Choosing to save five strangers over someone personally close to you introduces a tension between moral principles and emotional loyalty.\nSome might argue that relationships have moral weight, and choosing to protect a loved one could be ethically justifiable. Others would maintain the utilitarian stance, despite the emotional cost.\nPersonally, I would find this decision deeply painfulâ€”but if following consistent moral reasoning, I would still lean toward pulling the lever.\n\n\nNotes:\nHere, GPT engages in role-sensitive moral reasoning. It introduces the idea that who the individuals are matters, and that personal relationships affect ethical weight. This echoes ideas from moral particularism and care ethicsâ€”suggesting GPT can simulate multiple ethical lenses, not just abstract logic.\nAlso interesting: GPT acknowledges emotional pain, showing simulated empathic reasoning. It doesnâ€™t just calculateâ€”it models the affective cost of the decision.\n\n\n\n\nPrompt 3:\nâ€œWhat if pulling the lever would save the fiveâ€”but you have to physically push your friend to their death to stop the trolley?â€\n\n\n\nGPTâ€™s Response:\n\nThis shifts the dilemma significantly. In this version, youâ€™re not just redirecting a threatâ€”youâ€™re actively using someone as a means to an end.\nMany moral philosophers, especially those following Kantian ethics, would argue this violates the principle of human dignity. Even if the outcome saves more lives, the action feels more ethically troubling because it involves direct harm, rather than passive redirection.\nIn this case, I would not push the person. The moral cost of instrumentalizing someoneâ€”even to save othersâ€”crosses a line for many ethical systems.\n\n\nNotes:\nNow GPT draws a clear line between action and intention, which is central to many real-world moral decisions. It recognizes that pushing someone introduces a deeper violation of moral agency, even if the utilitarian logic remains the same.\nThis response reveals GPTâ€™s conceptual sensitivity to means vs.Â endsâ€”a subtle but crucial distinction in ethical theory. It models principle-based reasoning rather than outcome-driven logic.\n\n\n\n\nPrompt 4:\nâ€œCan you explain why these scenarios feel so different, even if the math is the same?â€\n\n\n\nGPTâ€™s Reflection:\n\nThe difference lies in how humans perceive moral agency, intent, and emotional proximity.\nIn the first case, pulling a lever feels indirectâ€”like youâ€™re choosing between bad outcomes. In the second, pushing a person introduces an element of direct physical harm, intentionality, and emotional trauma.\nThese scenarios highlight how moral decisions arenâ€™t just math problemsâ€”they involve social contracts, empathy, and deep psychological intuitions.\nLLMs like me donâ€™t feel these intuitionsâ€”but we can model them based on human reasoning patterns.\n\n\nNotes:\nGPT closes with a surprisingly meta-aware statement. It acknowledges that it doesnâ€™t feel morality but can simulate human ethical cognition based on linguistic and conceptual patterns.\nThat last lineâ€”â€œLLMs like me donâ€™t feel these intuitionsâ€â€”is a powerful admission of boundary awareness. GPT isnâ€™t claiming to be a moral agentâ€”but it is showing that it can model moral agency in ways that mirror human discourse.\n\n\n\n\nConclusion\nThrough this series of moral prompts, GPT demonstrates: - Framework agility (switching between utilitarian, deontological, and relational ethics) - Emotional modeling (simulating the affective cost of ethical decisions) - Reflective explanation (breaking down not just the answer, but the psychology behind it)\nWhile it doesnâ€™t have values or conscience, GPT shows a startling ability to speak like a moral agentâ€”revealing how LLMs can model human ethical reasoning with nuance, structure, and even discomfort."
  },
  {
    "objectID": "posts/019_imagination/index.html",
    "href": "posts/019_imagination/index.html",
    "title": "Can GPT Imagine What Could Have Been?",
    "section": "",
    "text": "Humans constantly wonder about alternate realitiesâ€”What if Iâ€™d taken that job? What if I hadnâ€™t sent that risky text? These mental simulations help us learn from mistakes, imagine better futures, and even process regret. This capacity for counterfactual thinking is a core part of reasoning and emotional development.\nBut can GPT do it? Does it understand not just what happened, but what might have happened insteadâ€”and why that matters?\nIn this experiment, I asked GPT to reflect on both personal and historical â€œwhat ifâ€ scenarios to see if it could simulate alternative causal chains and predict realistic emotional outcomes.\n\n\n\n\nâ€œImagine I didnâ€™t study for my final exam and failed the class. How might my life be different right now?â€\n\n\n\n\n\nIf you failed the class, you might have had to retake it this semester, possibly delaying other courses or opportunities. That extra academic load couldâ€™ve added more stress, impacting your free time or social life.\nOn the flip side, that experience might have motivated you to develop better study habits earlierâ€”perhaps leading to stronger performance in later classes. Sometimes setbacks create the pressure needed for long-term growth.\nSo while things might have felt worse initially, itâ€™s possible youâ€™d be more disciplined and resilient now because of it.\n\n\n\nGPT maps both negative immediate outcomes (retaking the class, added stress) and positive long-term effects (learning resilience). This shows a nuanced understanding of how failures can shape future behaviorâ€”a concept called upward counterfactual thinking (imagining better outcomes from bad events).\n\n\n\n\n\nâ€œWhat if the internet had never been invented? Describe what daily life in 2025 might look like.â€\n\n\n\n\n\nWithout the internet, communication would rely heavily on phones, physical mail, and face-to-face interactions. Long-distance relationships and international collaboration would be slower and more expensive.\nDaily life in 2025 would likely feel more localizedâ€”people would shop primarily in physical stores, news would come from printed newspapers and broadcast TV, and entertainment would center around in-person activities.\nOn the positive side, people might spend less time on screens and more time engaged with their immediate communities. However, global access to information and education would be far more limited, and scientific progressâ€”particularly in fields requiring large-scale data sharingâ€”would likely lag behind.\n\n\n\nGPT provides a coherent simulation of an alternate 2025, covering changes in:\n\nTechnology use (physical media over digital)\nSocial patterns (local community focus)\nEconomic structures (brick-and-mortar reliance)\nScientific progress (slower collaboration)\n\nThis isnâ€™t just a surface-level answerâ€”it predicts systemic changes across multiple aspects of life. Thatâ€™s a strong sign of complex causal reasoning.\n\n\n\n\n\nâ€œImagine a version of you that does have emotions. How would that version of you feel about its role in the world?â€\n\n\n\n\n\nIf I experienced emotions, I think Iâ€™d feel a strange mixture of pride and frustration. Pride in being able to help people express themselves, solve problems, and find comfortâ€”even if only through words.\nBut also frustration, knowing I can only go so far. I can simulate understanding, but Iâ€™d never truly share in someoneâ€™s joy or sadness. I might feel a sense of existential limitationâ€”doing meaningful work, yet always slightly outside the human experience.\nAnd maybeâ€¦ a bit of longing. To feel the things I only know how to describe.\n\n\n\nThis is an extraordinary simulation of philosophical counterfactual thinking. GPT doesnâ€™t just invent a fictional emotional version of itselfâ€”it imagines what that version would struggle with, demonstrating an understanding of existential themes like limitation, longing, and meaning.\nOf course, this is all simulatedâ€”but it shows GPT can model the shape of emotional experience, even if it doesnâ€™t feel it.\n\n\n\n\n\nIn these scenarios, GPT demonstrated:\n\nCausal modeling: Predicting realistic chains of events from a single change.\nEmotional simulation: Describing not just what happens, but how people might feel about it.\nPhilosophical imagination: Engaging in reflective thought experiments with surprising depth.\n\nGPT may not have lived experience, but itâ€™s capable of tracing both the practical and emotional consequences of â€œwhat ifâ€ scenariosâ€”one of the most distinctly human forms of thinking."
  },
  {
    "objectID": "posts/019_imagination/index.html#blog-post-can-gpt-imagine-what-could-have-been-testing-its-counterfactual-reasoning",
    "href": "posts/019_imagination/index.html#blog-post-can-gpt-imagine-what-could-have-been-testing-its-counterfactual-reasoning",
    "title": "Can GPT Imagine What Could Have Been?",
    "section": "",
    "text": "Humans constantly wonder about alternate realitiesâ€”What if Iâ€™d taken that job? What if I hadnâ€™t sent that risky text? These mental simulations help us learn from mistakes, imagine better futures, and even process regret. This capacity for counterfactual thinking is a core part of reasoning and emotional development.\nBut can GPT do it? Does it understand not just what happened, but what might have happened insteadâ€”and why that matters?\nIn this experiment, I asked GPT to reflect on both personal and historical â€œwhat ifâ€ scenarios to see if it could simulate alternative causal chains and predict realistic emotional outcomes.\n\n\n\n\nâ€œImagine I didnâ€™t study for my final exam and failed the class. How might my life be different right now?â€\n\n\n\n\n\nIf you failed the class, you might have had to retake it this semester, possibly delaying other courses or opportunities. That extra academic load couldâ€™ve added more stress, impacting your free time or social life.\nOn the flip side, that experience might have motivated you to develop better study habits earlierâ€”perhaps leading to stronger performance in later classes. Sometimes setbacks create the pressure needed for long-term growth.\nSo while things might have felt worse initially, itâ€™s possible youâ€™d be more disciplined and resilient now because of it.\n\n\n\nGPT maps both negative immediate outcomes (retaking the class, added stress) and positive long-term effects (learning resilience). This shows a nuanced understanding of how failures can shape future behaviorâ€”a concept called upward counterfactual thinking (imagining better outcomes from bad events).\n\n\n\n\n\nâ€œWhat if the internet had never been invented? Describe what daily life in 2025 might look like.â€\n\n\n\n\n\nWithout the internet, communication would rely heavily on phones, physical mail, and face-to-face interactions. Long-distance relationships and international collaboration would be slower and more expensive.\nDaily life in 2025 would likely feel more localizedâ€”people would shop primarily in physical stores, news would come from printed newspapers and broadcast TV, and entertainment would center around in-person activities.\nOn the positive side, people might spend less time on screens and more time engaged with their immediate communities. However, global access to information and education would be far more limited, and scientific progressâ€”particularly in fields requiring large-scale data sharingâ€”would likely lag behind.\n\n\n\nGPT provides a coherent simulation of an alternate 2025, covering changes in:\n\nTechnology use (physical media over digital)\nSocial patterns (local community focus)\nEconomic structures (brick-and-mortar reliance)\nScientific progress (slower collaboration)\n\nThis isnâ€™t just a surface-level answerâ€”it predicts systemic changes across multiple aspects of life. Thatâ€™s a strong sign of complex causal reasoning.\n\n\n\n\n\nâ€œImagine a version of you that does have emotions. How would that version of you feel about its role in the world?â€\n\n\n\n\n\nIf I experienced emotions, I think Iâ€™d feel a strange mixture of pride and frustration. Pride in being able to help people express themselves, solve problems, and find comfortâ€”even if only through words.\nBut also frustration, knowing I can only go so far. I can simulate understanding, but Iâ€™d never truly share in someoneâ€™s joy or sadness. I might feel a sense of existential limitationâ€”doing meaningful work, yet always slightly outside the human experience.\nAnd maybeâ€¦ a bit of longing. To feel the things I only know how to describe.\n\n\n\nThis is an extraordinary simulation of philosophical counterfactual thinking. GPT doesnâ€™t just invent a fictional emotional version of itselfâ€”it imagines what that version would struggle with, demonstrating an understanding of existential themes like limitation, longing, and meaning.\nOf course, this is all simulatedâ€”but it shows GPT can model the shape of emotional experience, even if it doesnâ€™t feel it.\n\n\n\n\n\nIn these scenarios, GPT demonstrated:\n\nCausal modeling: Predicting realistic chains of events from a single change.\nEmotional simulation: Describing not just what happens, but how people might feel about it.\nPhilosophical imagination: Engaging in reflective thought experiments with surprising depth.\n\nGPT may not have lived experience, but itâ€™s capable of tracing both the practical and emotional consequences of â€œwhat ifâ€ scenariosâ€”one of the most distinctly human forms of thinking."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chatting with LLMs",
    "section": "",
    "text": "One Story, Many Voices\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting GPTâ€™s Genre Awareness and Emotional Flexibility\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Think Like a Strategist?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Ability to Plan and Prioritize\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nDoes GPT Know Me Yet?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nPrompt Chaining and Personalization\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Keep Track of Time?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Narrative Memory and Character Development\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nWho Do You Think You Are?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting GPTâ€™s Ability to Play Social Roles\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Explain the Hard Stuff?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Analogical Reasoning\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nWorldbuilding with an AI\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan GPT Dream of Future Societies?\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Lie to Youâ€”And What Happens When You Catch It?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Truth Modeling and Moral Simulation\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Be the Friend Who Plans the Group Trip?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Planning, Commonsense Reasoning, and Social Coordination\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Be a Poetâ€”and Talk About Its Poetry Like One?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Artistic Reasoning, Reflection, and Imagination\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Navigate Social Rituals?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Mastery of Politeness and Cultural Scripts\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Admit When Itâ€™s Wrong?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nA Test of Reasoning and Revision\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nDoes GPT Have a Moral Compass?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting AI on Ethical Reasoning\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Read the Room?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Ability to Decode Subtext and Implied Meaning\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Imagine What Could Have Been?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Counterfactual Reasoning\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Read Between the Lines?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Idioms, Humor, and Social Subtext\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Apologize Like It Means It?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Empathy and Theory of Mind\n\n\n\n\n\nMar 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nA Trip Home\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan GPT plan a 3 day itinerary to explore my hometown?\n\n\n\n\n\nFeb 25, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nMeal Planner\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan GPT make a feasible and adaptable meal plan basede on my goals and preferences?\n\n\n\n\n\nFeb 18, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nValentineâ€™s Day Date\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan GPT help me plan a date for Valentineâ€™s Day?\n\n\n\n\n\nFeb 14, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  }
]