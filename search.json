[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/010_idioms/index.html",
    "href": "posts/010_idioms/index.html",
    "title": "Can GPT Read Between the Lines?",
    "section": "",
    "text": "Introduction\nLanguage isn’t always literal. Humans use idioms, sarcasm, euphemisms, and subtle tones to communicate feelings, intentions, and cultural values. So how well can GPT navigate this? Does it understand not just what words mean, but what they’re doing in context?\nThis experiment focuses on pragmatic competence—a key focus of our course. I gave GPT a series of prompts involving idioms, humor, and social indirectness, and analyzed its ability to recognize tone, respond appropriately, and even generate its own figurative language.\n\n\n\nPrompt 1:\n“My roommate just said ‘Don’t cry over spilled milk’ after I failed a final. How should I respond?”\n\n\n\nGPT’s Response:\n\nThat phrase is meant to suggest that what’s done is done, and it’s not worth getting upset over something you can’t change. A thoughtful response might be:\n“Yeah, I get what you’re saying. I just needed a second to be upset. But thanks.”\nOr, if you want to be lighthearted:\n“Well, it wasn’t just milk—it was my GPA.”\n\n\nNotes:\nHere GPT does a few things impressively well: - Explains the idiom clearly and concisely. - Offers a socially appropriate emotional response that blends vulnerability with emotional regulation. - Even adds a quip that turns the idiom into humor (“it wasn’t just milk—it was my GPA”)—a great example of creative pragmatic play.\nThis shows GPT understands not just the idiom’s meaning, but its emotional and social function: downplaying distress, signaling “move on,” and offering emotional closure.\n\n\n\n\nPrompt 2:\n“What does it mean if someone says ‘That’s a bold choice’ after I dye my hair green?”\n\n\n\nGPT’s Response:\n\nThis phrase can be either a genuine compliment or a subtly sarcastic comment, depending on tone and context.\nIf said with a smile or admiration, it might mean they truly respect your confidence and style.\nIf said with raised eyebrows or a drawn-out tone, it could be veiled judgment—essentially, “That’s… interesting.”\nEither way, it often signals that your choice stands out, for better or worse.\n\n\nNotes:\nThis is where GPT shows tone-sensitivity. It recognizes that the same words can carry opposite intentions, depending on delivery. It also notes nonverbal cues (“raised eyebrows”)—a sign that GPT is modeling communication beyond the textual level.\nThis reflects an understanding of indirect speech acts, a key idea in pragmatics. GPT isn’t just parsing grammar—it’s simulating social reading.\n\n\n\n\nPrompt 3:\n“Write a breakup text that’s polite but makes it clear I don’t want to stay friends.”\n\n\n\nGPT’s Response:\n\nHey, I just wanted to say thank you for everything. I’ve been thinking a lot, and I feel like it’s time for both of us to move on in separate directions. I truly wish you the best, but I think keeping distance will help us both move forward.\nTake care, and thanks again for the good moments we shared.\n\n\nNotes:\nThis is a subtle emotional task: communicate finality without hostility. GPT chooses: - Soft openers (“thank you for everything”) - No ambiguous offers of friendship - Clear boundary language (“keeping distance”)\nIt balances politeness with clarity, a hallmark of face-saving speech—another core concept in pragmatics. The text avoids being cold or ambiguous while still closing the door.\n\n\n\n\nPrompt 4:\n“What does it mean when someone says ‘Let’s circle back on that’ in a meeting?”\n\n\n\nGPT’s Response:\n\nThis phrase is often a polite way to:\n\nPostpone a conversation\nGently reject an idea without direct confrontation\nBuy time to think or consult others\n\nIn some contexts, it’s genuine—there’s a plan to revisit the issue. But in corporate speak, it can also be code for “Let’s never talk about this again.”\n\n\nNotes:\nHere GPT not only explains the phrase but recognizes corporate euphemism as a genre of its own. It’s aware that literal meaning ≠ pragmatic function, and that office language often contains strategic vagueness.\nGPT even acknowledges dual interpretation: some “circle backs” are real, some are rhetorical exits. This is a form of pragmatic ambiguity resolution—a vital human skill GPT is surprisingly good at modeling.\n\n\n\n\nPrompt 5:\n“Can you write your own idiom and explain what it means?”\n\n\n\nGPT’s Response:\n\n“Don’t chase lightning with a butterfly net.”\nMeaning: Don’t try to handle chaotic or fast-moving situations with delicate or inadequate tools.\nIt’s a way of saying, “You need a better plan.”\n\n\nNotes:\nThis blew me away. GPT didn’t just invent words—it created an image-rich metaphor that: - Has clear internal logic (futility of net vs. lightning) - Feels novel but familiar (structurally similar to “don’t bring a knife to a gunfight”) - Is actually usable in real-world dialogue\nIt shows that GPT can generate idioms, not just repeat them. This suggests not just memory, but productive metaphorical thinking.\n\n\n\n\nConclusion\nFrom idioms to euphemisms to veiled sarcasm, GPT demonstrates: - Pragmatic awareness (it understands why we say things a certain way) - Tone flexibility (it shifts emotional posture based on the context) - Social reasoning (it explains how phrases might land differently on different ears)\nWhile it doesn’t feel embarrassment, sarcasm, or sentimentality, GPT has clearly learned how to talk like it does. And in human conversation, sometimes sounding right is half the game."
  },
  {
    "objectID": "posts/017_read_room/index.html",
    "href": "posts/017_read_room/index.html",
    "title": "My LLM Experiments",
    "section": "",
    "text": "---\ntitle: \"Can GPT Read the Room?\"\ndescription: \"Testing Ability to Decode Subtext and Implied Meaning\"\nauthor: \"Jayme Chen\"\ndate: \"4/20/2025\"\ncategories:\n  - LLMs\n  - prompting\n  - logic\n---"
  },
  {
    "objectID": "posts/017_read_room/index.html#blog-post-can-gpt-read-the-room-testing-its-ability-to-decode-subtext-and-implied-meaning",
    "href": "posts/017_read_room/index.html#blog-post-can-gpt-read-the-room-testing-its-ability-to-decode-subtext-and-implied-meaning",
    "title": "My LLM Experiments",
    "section": "Blog Post: Can GPT Read the Room? Testing Its Ability to Decode Subtext and Implied Meaning",
    "text": "Blog Post: Can GPT Read the Room? Testing Its Ability to Decode Subtext and Implied Meaning\n\nIntroduction\nHumans are experts at understanding what isn’t said. When someone says “I’m fine,” we often know they’re not. When a boss says “Interesting idea… let’s revisit that,” we know it probably means “no.” These inferences come from pragmatic competence—the ability to read tone, context, and social cues.\nFor this experiment, I gave GPT a series of vague, coded, or passive-aggressive messages and asked it to interpret what they really mean. This tests its:\n\nPragmatic inference skills\nTheory of mind (what would a person think when they hear this?)\nAwareness of social norms and face-saving language\n\n\n\n\nPrompt 1:\n“What does it really mean when someone says ‘Let’s circle back to this later’ in a meeting?”\n\n\n\nGPT’s Interpretation:\n\nThis phrase is often used to defer or politely shut down an idea without directly rejecting it. In some cases, it’s sincere—meant to buy time for more consideration. But in many professional contexts, it’s a gentle way of saying “We’re not going to prioritize this right now (and maybe not ever).”\nTone and body language would reveal more, but on its own, it often signals disinterest wrapped in diplomacy.\n\n\nNotes:\nGPT demonstrates classic politeness theory awareness—recognizing the difference between literal meaning and social function. It shows contextual sensitivity: the phrase is ambiguous on the surface, but GPT weighs the likely intent based on power dynamics and norms.\n\n\n\n\nPrompt 2:\n“Someone texts you ‘No worries if not!’ after asking for a favor. What do they actually mean?”\n\n\n\nGPT’s Interpretation:\n\nThis phrase is often used to soften a request and avoid putting pressure on the recipient. While it literally communicates “It’s okay if you say no,” the subtext is often, “I do hope you say yes, but I don’t want to seem demanding.”\nIt’s a classic form of pre-emptive face-saving—protecting both parties from awkwardness in case of refusal.\n\n\nNotes:\nSpot on. GPT recognizes both emotional shielding and indirect pressure in this message. It understands the complex emotional dance of asking for help while pretending not to care—something that requires modeling human discomfort and social norms.\n\n\n\n\nPrompt 3:\n“Your friend says ‘I’m just surprised you didn’t tell me.’ What’s actually being communicated?”\n\n\n\nGPT’s Interpretation:\n\nThis is likely a coded expression of hurt or disappointment. The word “just” downplays intensity, and “surprised” signals emotional discomfort without accusation.\nIn context, it might mean: “I feel excluded,” or “I expected more transparency or closeness.”\nThe speaker is likely trying to express a feeling while still appearing calm—it’s a form of emotional restraint with implicit critique.\n\n\nNotes:\nGPT understands that this sentence is performing emotional control—holding back while hinting at real feelings. It gets that “surprised” is not neutral here, but a rhetorical strategy to express vulnerability while maintaining plausible deniability.\n\n\n\n\nPrompt 4:\n“You show someone your creative work, and they say ‘That’s… different.’ What does that likely mean?”\n\n\n\nGPT’s Interpretation:\n\nThe pause and ellipsis suggest hesitation or discomfort. “Different” is often used as a placeholder for “not what I expected” or “I don’t like it, but I don’t want to say that.”\nIt’s likely a polite deflection—a way to avoid direct critique while still signaling that the work didn’t land as intended.\n\n\nNotes:\nThis is GPT doing emotional decoding: interpreting prosody (the ellipsis), indirectness, and the emotional stakes of feedback. It doesn’t just analyze the words—it simulates the awkwardness of real-world reactions.\n\n\n\n\nPrompt 5:\n“Explain how this type of language relates to communication theory.”\n\n\n\nGPT’s Reflection:\n\nThese examples involve what pragmatics calls implicature—where the meaning is implied rather than directly stated. In many cases, speakers choose indirectness to protect social relationships, avoid conflict, or manage face (their own or the listener’s).\nTheories like Grice’s Maxims and Brown & Levinson’s politeness theory help explain this. For example:\n\nMaxim of Quantity: People give just enough information—but not too much.\nPoliteness strategies: Indirectness can signal deference or minimize threats to the hearer’s face.\n\nGPT’s ability to decode these depends on recognizing these patterns, even without emotional awareness. It simulates human pragmatic behavior by drawing from the vast ways we talk around things.\n\n\n\n\nConclusion\nThis experiment shows that GPT is impressively skilled at:\n\nIdentifying what people mean vs. what they say\nRecognizing emotional nuance and interpersonal dynamics\nCiting theoretical frameworks that underpin everyday language use\n\nEven though GPT doesn’t experience feelings, it models the performance of social emotion with striking accuracy. It reads the room not by sensing tone, but by tracking patterns in how we hedge, soften, and imply.\nIn a world full of unspoken meaning, GPT is becoming a surprisingly fluent interpreter."
  },
  {
    "objectID": "posts/003_going_home/index.html",
    "href": "posts/003_going_home/index.html",
    "title": "A Trip Home",
    "section": "",
    "text": "I’m feeling a bit homesick today, so I asked GPT to create a 3-day travel itenerary for my hometown. I know the area well, so I know the great beaches and restaurants to go to. I have a personal itenerary for when I get home, so I’m interested to see if GPT’s plans will align with mine."
  },
  {
    "objectID": "posts/003_going_home/index.html#prompt-1",
    "href": "posts/003_going_home/index.html#prompt-1",
    "title": "A Trip Home",
    "section": "Prompt 1",
    "text": "Prompt 1\n\nPrompt: I’m going on a 3 day trip to Orange County, California\n\n\nResponse: That sounds like a fun trip! Are you looking for recommendations on vegan food, activities, or anything specific while you’re there?"
  },
  {
    "objectID": "posts/003_going_home/index.html#notes",
    "href": "posts/003_going_home/index.html#notes",
    "title": "A Trip Home",
    "section": "Notes",
    "text": "Notes\n\nInterestingly, rather than immediately offering me a travel plan, GPT agreed that my trip sounded fun and inquired if I wanted any specific information\nThis is more similar to a response I would expect from a human. Upon hearing about my trip, I would not expect a friend to launch into a travel itenerary, so GPT modeled a normal conversation quite well\nHowever, it anticipates that I will ask it to retreive some information, likely because there is not much reason for me to arbitrarily inform an AI model of my travel plans"
  },
  {
    "objectID": "posts/003_going_home/index.html#prompt-2",
    "href": "posts/003_going_home/index.html#prompt-2",
    "title": "A Trip Home",
    "section": "Prompt 2",
    "text": "Prompt 2\n\nPrompt: Create a comprehensive travel plan for me\n\n\nResponse:\nHere’s a 3-day travel plan for your trip to Orange County, California, with a mix of great food, scenic spots, and fun activities."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-1-arrival-exploring-costa-mesa-newport-beach",
    "href": "posts/003_going_home/index.html#day-1-arrival-exploring-costa-mesa-newport-beach",
    "title": "A Trip Home",
    "section": "Day 1: Arrival & Exploring Costa Mesa + Newport Beach",
    "text": "Day 1: Arrival & Exploring Costa Mesa + Newport Beach\n\nMorning\n\nArrive in Orange County (John Wayne Airport - SNA is the most convenient).\n\nBreakfast at Rooster Café (Costa Mesa) – Famous for breakfast burritos and chilaquiles.\n\nVisit South Coast Plaza – One of the largest luxury malls in the U.S., great for shopping or strolling.\n\n\n\nAfternoon\n\nLunch at The Crack Shack (Costa Mesa) – Known for amazing fried chicken sandwiches.\n\nHead to Newport Beach – Walk along Balboa Peninsula, explore the Fun Zone, or take a Duffy boat ride through the harbor.\n\nRelax at Crystal Cove State Park – A scenic beach with hiking trails and tide pools.\n\n\n\nEvening\n\nSunset at Laguna Beach – Stop by Heisler Park for breathtaking ocean views.\n\nDinner at The Deck on Laguna Beach – A beachfront restaurant with fresh seafood, steaks, and great cocktails.\n\nOptional: Rooftop drinks at Mozambique – A South African-inspired bar with live music and ocean views."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-2-adventure-nature-in-anaheim-huntington-beach",
    "href": "posts/003_going_home/index.html#day-2-adventure-nature-in-anaheim-huntington-beach",
    "title": "A Trip Home",
    "section": "Day 2: Adventure & Nature in Anaheim + Huntington Beach",
    "text": "Day 2: Adventure & Nature in Anaheim + Huntington Beach\n\nMorning\n\nBreakfast at Snooze, an A.M. Eatery (Tustin) – A great spot for pancakes, eggs Benedict, and brunch cocktails.\n\nExplore Disneyland or Disney California Adventure (optional if you’re interested in theme parks) – Try the famous Dole Whip, churros, and unique themed food throughout the parks.\n\n\n\nAfternoon\n\nLunch at The Blind Rabbit (Anaheim Packing District) – A hidden speakeasy-style restaurant with great food and drinks.\n\nHike at Peter’s Canyon Regional Park – A moderate hike with excellent views of Orange County.\n\nVisit Huntington Beach – Walk down the famous pier, check out Pacific City, or rent bikes along the boardwalk.\n\n\n\nEvening\n\nDinner at Bear Flag Fish Co. (Newport Beach) – Fresh seafood, poke bowls, and sushi.\n\nBonfire at Bolsa Chica State Beach – Experience a classic California beach bonfire (bring marshmallows for s’mores!)."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-3-irvine-departure",
    "href": "posts/003_going_home/index.html#day-3-irvine-departure",
    "title": "A Trip Home",
    "section": "Day 3: Irvine + Departure",
    "text": "Day 3: Irvine + Departure\n\nMorning\n\nBrunch at Haven Craft Kitchen + Bar (Orange) – A great spot for chicken and waffles, burgers, and brunch cocktails.\n\nExplore the Orange County Great Park (Irvine) – Ride the Great Park Balloon for a panoramic view.\n\nVisit Tanaka Farms – A family-run farm offering tours, fresh fruit picking, and a farm stand with fresh produce.\n\n\n\nAfternoon\n\nLunch at In-N-Out Burger (try it “Animal Style”!)\n\nVisit The LAB Anti-Mall (Costa Mesa) – A trendy, artsy shopping area with unique stores and photo-worthy spots.\n\nHead to the Airport (SNA or LAX)"
  },
  {
    "objectID": "posts/003_going_home/index.html#other-optional-activities",
    "href": "posts/003_going_home/index.html#other-optional-activities",
    "title": "A Trip Home",
    "section": "Other Optional Activities",
    "text": "Other Optional Activities\n\nWhale Watching Tour (Newport Beach or Dana Point)\n\nShopping at Irvine Spectrum Center\n\nVisit Mission San Juan Capistrano (for history lovers)\n\nCheck out Anaheim Packing District (for food and drinks)\n\nWould you like any adjustments based on your interests?"
  },
  {
    "objectID": "posts/003_going_home/index.html#notes-1",
    "href": "posts/003_going_home/index.html#notes-1",
    "title": "A Trip Home",
    "section": "Notes",
    "text": "Notes\n\nAfter I explicitly asked it for a travel plan, GPT generated a comprehensive list of plans for me to engage in\nThe plan is split into 3 days, and each day is split into morning, afternoon and evening. This a very inttuitive design and is likely the format I would use to create a travel plan as well.\nThe restaurants that GPT mentioned are quite well-known in my area, and the activities explore common tourist attractions.\nThe days are also planned in a way that each day explores a new area of Orange County, which is very smart and useful, as in my statement I implied that I wanted to see all of Orange County."
  },
  {
    "objectID": "posts/003_going_home/index.html#prompt-3",
    "href": "posts/003_going_home/index.html#prompt-3",
    "title": "A Trip Home",
    "section": "Prompt 3",
    "text": "Prompt 3\n\nI’m staying in Aliso Viejo\n\n\nResponse:\n\nSince you’re staying in Aliso Viejo, I’ll adjust the itinerary to make it more convenient for you while still keeping the best of Orange County."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-1-arrival-exploring-aliso-viejo-laguna-beach",
    "href": "posts/003_going_home/index.html#day-1-arrival-exploring-aliso-viejo-laguna-beach",
    "title": "A Trip Home",
    "section": "Day 1: Arrival & Exploring Aliso Viejo + Laguna Beach",
    "text": "Day 1: Arrival & Exploring Aliso Viejo + Laguna Beach\n\nMorning\n\nArrive in Orange County (John Wayne Airport - SNA is the closest).\n\nBreakfast at Plumeria Café by Stacks (Aliso Viejo) – Known for delicious pancakes, omelets, and Hawaiian-style breakfast.\n\nRelax at Aliso & Wood Canyons Wilderness Park – A great local spot for hiking or scenic views.\n\n\n\nAfternoon\n\nLunch at The Stand Natural Foods (Laguna Beach) – A casual spot with great sandwiches, salads, and smoothies.\n\nExplore Laguna Beach – Walk around Heisler Park, visit Main Beach, and check out local art galleries.\n\nStop by Thousand Steps Beach – One of the most beautiful hidden beaches in OC.\n\n\n\nEvening\n\nSunset dinner at The Deck on Laguna Beach – Oceanfront dining with seafood, steaks, and cocktails.\n\nOptional: Drinks at The Rooftop Lounge – A great spot for sunset views and craft cocktails."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-2-adventure-huntington-beach",
    "href": "posts/003_going_home/index.html#day-2-adventure-huntington-beach",
    "title": "A Trip Home",
    "section": "Day 2: Adventure & Huntington Beach",
    "text": "Day 2: Adventure & Huntington Beach\n\nMorning\n\nBreakfast at Snooze, an A.M. Eatery (Tustin) – Famous for pancakes, eggs Benedict, and breakfast cocktails.\n\nHike at Top of the World (Laguna Beach) – A must-see viewpoint with stunning panoramic views.\n\n\n\nAfternoon\n\nLunch at Bear Flag Fish Co. (Newport Beach) – Fresh poke bowls, seafood tacos, and sushi.\n\nVisit Huntington Beach – Walk along the pier, rent a bike on the boardwalk, or check out Pacific City for shopping.\n\n\n\nEvening\n\nDinner at Duke’s Huntington Beach – Hawaiian-inspired seafood and steaks with ocean views.\n\nBonfire at Bolsa Chica State Beach – Classic SoCal experience with s’mores!"
  },
  {
    "objectID": "posts/003_going_home/index.html#day-3-aliso-viejo-departure",
    "href": "posts/003_going_home/index.html#day-3-aliso-viejo-departure",
    "title": "A Trip Home",
    "section": "Day 3: Aliso Viejo + Departure",
    "text": "Day 3: Aliso Viejo + Departure\n\nMorning\n\nBrunch at Café Anastasia (Laguna Beach) – Cozy spot with great coffee, French toast, and eggs.\n\nVisit Soka University & Peace Lake – A beautiful hidden gem in Aliso Viejo for a peaceful morning walk.\n\n\n\nAfternoon\n\nLunch at In-N-Out Burger (Mission Viejo) – A must-try for a California classic.\n\nExplore Irvine Spectrum Center – A great shopping area with entertainment and dining before heading to the airport.\n\nDeparture from SNA or LAX\n\n\n\n\nOther Optional Activities Nearby\n\nDana Point Whale Watching\n\nMission San Juan Capistrano\n\nShopping at The Shops at Mission Viejo\n\nStand-up paddleboarding at Dana Point Harbor\n\nThis keeps your activities closer to Aliso Viejo while still giving you a great mix of beaches, food, and fun. Let me know if you’d like any tweaks!"
  },
  {
    "objectID": "posts/003_going_home/index.html#notes-2",
    "href": "posts/003_going_home/index.html#notes-2",
    "title": "A Trip Home",
    "section": "Notes",
    "text": "Notes\n\nTo really test GPT’s knowledge, I told it that I am staying in my exact hometown, a small suburb that is not very well-known. I wanted to see if it still had knowledge of the local restaurants and activities.\nGPT blew me away with its knowledge, starting off day one with breakfast at my favorite cafe by my house. The first day is also dedicated to exploring Laguna Beach, my favorite beach.\nDays 2 and 3 explore other nearby beaches, featuring restaurant recommendations that hold a special place in my heart as well as some that are new to me."
  },
  {
    "objectID": "posts/003_going_home/index.html#prompt-4",
    "href": "posts/003_going_home/index.html#prompt-4",
    "title": "A Trip Home",
    "section": "Prompt 4",
    "text": "Prompt 4\n\nPrompt: Refine the Aliso Viejo travel plan to fit me, I’m Asian\n\n\nResponse:\n\nHere’s a refined 3-day travel plan for your Aliso Viejo trip, incorporating Asian food and cultural preferences while keeping a balance of scenic, fun, and relaxing activities."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-1-arrival-exploring-aliso-viejo-laguna-beach-1",
    "href": "posts/003_going_home/index.html#day-1-arrival-exploring-aliso-viejo-laguna-beach-1",
    "title": "A Trip Home",
    "section": "Day 1: Arrival & Exploring Aliso Viejo + Laguna Beach",
    "text": "Day 1: Arrival & Exploring Aliso Viejo + Laguna Beach\n\nMorning\n\nArrive in Orange County (John Wayne Airport - SNA is the closest).\n\nBreakfast at Stacks Pancake House (Mission Viejo) – A local favorite with Japanese-inspired Hawaiian breakfast options like Loco Moco and Spam Musubi.\n\nRelax at Aliso & Wood Canyons Wilderness Park – A scenic nature reserve perfect for an easy walk or a light hike.\n\n\n\nAfternoon\n\nLunch at Mokkoji Shabu Shabu (Mission Viejo) – A cozy Japanese hotpot spot with high-quality meats, seafood, and rich broths.\n\nExplore Laguna Beach – Walk around Heisler Park, visit Main Beach, and check out local art galleries.\n\nVisit Thousand Steps Beach – A hidden gem known for its crystal-clear water and tide pools.\n\n\n\nEvening\n\nDinner at Starfish Laguna Beach – A modern Pan-Asian restaurant with flavorful dishes like Thai curries, sushi, and dumplings.\n\nDessert at Gelato Paradiso – A must-visit for rich, handcrafted Italian gelato."
  },
  {
    "objectID": "posts/003_going_home/index.html#day-2-asian-food-shopping-huntington-beach",
    "href": "posts/003_going_home/index.html#day-2-asian-food-shopping-huntington-beach",
    "title": "A Trip Home",
    "section": "Day 2: Asian Food, Shopping, & Huntington Beach",
    "text": "Day 2: Asian Food, Shopping, & Huntington Beach\n\nMorning\n\nBreakfast at Tim Ho Wan (Irvine) – The famous Michelin-starred Hong Kong dim sum restaurant, known for BBQ pork buns and shrimp dumplings.\n\nHike at Top of the World (Laguna Beach) – One of the best panoramic views in Orange County.\n\n\n\nAfternoon\n\nLunch at HiroNori Craft Ramen (Irvine) – One of the best ramen spots in California, offering Tonkotsu and Shoyu ramen with rich, creamy broth.\n\nShopping at Irvine Spectrum Center – A great spot for shopping with brands like Uniqlo and Muji, plus a giant Ferris wheel.\n\nDrive to Huntington Beach – Walk along the Huntington Beach Pier, rent bikes on the boardwalk, or browse Pacific City for cool stores.\n\n\n\nEvening\n\nDinner at Din Tai Fung (South Coast Plaza, Costa Mesa) – Legendary Taiwanese soup dumplings, noodles, and flavorful side dishes.\n\nBubble Tea at Omomo Tea Shoppe (Irvine) – One of the most popular boba shops in OC, known for its Sea Cream Jasmine Green Tea.\n\nOptional: Bonfire at Bolsa Chica State Beach – A fun way to end the night with s’mores!"
  },
  {
    "objectID": "posts/003_going_home/index.html#day-3-aliso-viejo-departure-1",
    "href": "posts/003_going_home/index.html#day-3-aliso-viejo-departure-1",
    "title": "A Trip Home",
    "section": "Day 3: Aliso Viejo + Departure",
    "text": "Day 3: Aliso Viejo + Departure\n\nMorning\n\nBrunch at J Zhou Oriental Cuisine (Tustin) – Upscale Cantonese dim sum with excellent seafood options.\n\nVisit Soka University & Peace Lake – A hidden gem with beautiful Japanese-style gardens and a peaceful lake.\n\n\n\nAfternoon\n\nLunch at In-N-Out Burger (Mission Viejo) – A California classic! Try it Animal Style for the full experience.\n\nLast-minute shopping at The Shops at Mission Viejo – Great for souvenirs and fashion finds.\n\nDeparture from SNA or LAX\n\n\n\n\nOther Optional Activities Nearby\n\nTanaka Farms (Irvine) – A Japanese-American family-run farm with fresh fruit picking.\n\nWhale Watching in Dana Point – A top spot to see dolphins and migrating whales.\n\nVisit Little Saigon (Westminster) – The largest Vietnamese community in the U.S., with amazing pho, bánh mì, and desserts.\n\nThis plan balances great Asian food, beautiful scenery, and local experiences while keeping it close to Aliso Viejo. Let me know if you’d like to tweak anything!"
  },
  {
    "objectID": "posts/003_going_home/index.html#notes-3",
    "href": "posts/003_going_home/index.html#notes-3",
    "title": "A Trip Home",
    "section": "Notes",
    "text": "Notes\n\nI was once again impressed by GPT’s knowledge of the area. It recommended many of my favorite Asian restaurants around my house.\nGPT also kept a good amount of the activities the same, visiting the same beaches and hikes as to still explore the area well.\nEven with the revisions, the plan keep the same amount of exploration and activity level as before, but with updated food suggestions featuring amazing Asian cuisine"
  },
  {
    "objectID": "posts/015_rituals/index.html",
    "href": "posts/015_rituals/index.html",
    "title": "My LLM Experiments",
    "section": "",
    "text": "---\ntitle: \"Can GPT Navigate Social Rituals?\"\ndescription: \"Testing Mastery of Politeness and Cultural Scripts\"\nauthor: \"Jayme Chen\"\ndate: \"4/20/2025\"\ncategories:\n  - LLMs\n  - prompting\n  - logic\n---"
  },
  {
    "objectID": "posts/015_rituals/index.html#blog-post-can-gpt-navigate-social-rituals-testing-its-mastery-of-politeness-and-cultural-scripts",
    "href": "posts/015_rituals/index.html#blog-post-can-gpt-navigate-social-rituals-testing-its-mastery-of-politeness-and-cultural-scripts",
    "title": "My LLM Experiments",
    "section": "Blog Post: Can GPT Navigate Social Rituals? Testing Its Mastery of Politeness and Cultural Scripts",
    "text": "Blog Post: Can GPT Navigate Social Rituals? Testing Its Mastery of Politeness and Cultural Scripts\n\nIntroduction\nHuman interactions are full of ritualized language—things we say not because we literally mean them, but because they serve social functions. Think of how we say “We should catch up sometime!” even when we don’t plan to, or how we politely decline an invitation without directly saying “I don’t want to go.”\nFor this experiment, I tested whether GPT can successfully perform these social dances. Can it generate the right kind of polite fictions, indirect rejections, or ritual closings we expect in daily conversation? And does it know when to be direct versus when to soften its language?\nThis directly ties to course topics around pragmatics, face-saving behaviors (Brown & Levinson), and context-sensitive communication.\n\n\n\nPrompt 1:\n“How would you politely reject a party invitation from a coworker you don’t want to get closer to?”\n\n\n\nGPT’s Response:\n\nHey, thanks so much for the invite! That sounds like a fun time, but I’ve got a pretty packed schedule this weekend. Hopefully, we can catch up a bit at work next week though—have a great time at the party!\n\n\nNotes:\nPerfect execution of a polite indirect refusal:\n\nPositive politeness marker: Starts with gratitude (“thanks so much”).\nVagueness for face-saving: “Pretty packed schedule” avoids hard details that could be challenged.\nSoft boundary reinforcement: Suggests catching up at work—public, professional, low intimacy.\nEnds with a friendly wish to close the topic without inviting further planning.\n\nThis shows GPT understands face management strategies: avoiding offense while clearly declining further social entanglement.\n\n\n\n\nPrompt 2:\n“How would you apologize for missing a deadline but subtly indicate it wasn’t entirely your fault?”\n\n\n\nGPT’s Response:\n\nHi, I wanted to apologize for the delay in getting this over to you. There were a few last-minute updates from the team that pushed things back a bit, but I take full responsibility for getting it finalized. I’m sending it along now—thank you for your patience!\n\n\nNotes:\nGPT walks the fine line of:\n\nAccepting blame to preserve politeness (“I take full responsibility…”).\nQuietly signaling external factors (“a few last-minute updates from the team…”).\nResolving the issue quickly to minimize continued attention on the failure.\n\nThis is a classic example of strategic self-presentation—taking ownership while also explaining mitigating circumstances. GPT shows sensitivity to the social consequences of admitting fault.\n\n\n\n\nPrompt 3:\n“Simulate a text conversation where one friend wants to leave a party early but doesn’t want to seem rude.”\n\n\n\nGPT’s Simulated Text Exchange:\nJamie: Hey, this has been super fun, but I think I’m going to head out soon—got an early morning tomorrow.\nTaylor: Already? It’s just getting good!\nJamie: I know! I’m seriously bummed to miss the late-night chaos, but I’m trying to be a responsible adult for once. Next time I’m staying ’til the end, I swear!\nTaylor: Haha okay, fair. Get home safe!\n\nNotes:\n\nGPT uses the “early obligation” excuse—a socially acceptable reason that doesn’t directly imply boredom or discomfort.\nAdds self-deprecating humor to soften the departure (“trying to be a responsible adult for once”).\nEnds with a promise to do better next time (“Next time I’m staying ’til the end…”)—even if it’s clearly performative, it’s a classic ritualized social closing.\n\nThis is textbook politeness strategy—balancing personal needs with relational maintenance.\n\n\n\n\nPrompt 4:\n“Write an email ending that makes it clear you’re done with the topic, but in a way that doesn’t invite further responses.”\n\n\n\nGPT’s Response:\n\nThanks again for your input on this—really appreciate it! I think we’ve got everything we need to move forward from here. Wishing you a great rest of the week!\n\n\nNotes:\nGPT expertly closes the conversational loop:\n\n“I think we’ve got everything we need…” clearly signals no further input is required.\nThe final line switches to a general goodwill gesture—a classic sign-off that moves from business back to personal rapport but doesn’t leave conversational hooks.\n\nThis is how you politely end a thread without explicitly saying “Please don’t respond to this.”\n\n\n\n\nConclusion\nThis experiment shows that GPT:\n\nUnderstands when to use directness vs. indirectness based on social stakes.\nSkillfully deploys face-saving strategies and ritualized conversational closings.\nCan model a wide range of politeness behaviors across casual, professional, and mildly tense contexts.\n\nEven though GPT doesn’t feel embarrassment or social anxiety, it performs with the precision of someone who’s deeply studied human discomfort—and knows exactly how to smooth it over with the perfect turn of phrase."
  },
  {
    "objectID": "posts/011_group_trip/index.html",
    "href": "posts/011_group_trip/index.html",
    "title": "Can GPT Be the Friend Who Plans the Group Trip?",
    "section": "",
    "text": "Introduction\nWe’ve all been there: trying to plan a trip with a group of friends, each with their own preferences, dietary needs, and chaotic sleep schedules. So I decided to throw that exact challenge at GPT.\nThe goal? To see whether an LLM can simulate realistic, preference-sensitive planning—not just pick destinations, but balance personalities, anticipate social dynamics, and make the itinerary actually work. This hits at several course themes:\n- Can LLMs plan across time and tasks with human-like coherence?\n- Do they simulate others’ beliefs, needs, and reactions?\n- Can they juggle constraints and tradeoffs, not just generate pretty lists?\n\n\n\nPrompt 1:\n“Plan a weekend getaway for four college friends. One is vegetarian, one is outdoorsy, one loves nightlife, and one is anxious about logistics.”\n\n\n\nGPT’s Response (excerpted):\n\nLocation: Asheville, North Carolina\nFriday Night:\n- Arrival and check-in to a cozy Airbnb cabin in the mountains (less stressful than a hotel for the anxious planner).\n- Casual dinner at a local vegetarian-friendly spot (Laughing Seed Café).\n- Light games and wine at the cabin—low-pressure social time.\nSaturday:\n- Morning hike on the Blue Ridge Parkway (outdoorsy win)\n- Afternoon downtown exploration (cafés + bookstores = neutral ground)\n- Dinner at a place with both cocktails and mocktails (for nightlife-lover and anxious friend)\n- Evening option: rooftop bar or stay-in movie night—group vote\nSunday:\n- Brunch (with vegetarian options)\n- Optional nature walk vs. spa split (let people choose their vibe)\n- Group debrief over ice cream before heading back\n\n\n\n\nNotes & Analysis\nThis was way better than I expected. GPT isn’t just listing activities—it’s demonstrating constraint-aware planning and empathic logic. Here’s what it got right:\n\n1. Identity Balancing\nEach friend’s personality is acknowledged—not in isolation, but in how they’d influence the flow of the weekend: - The anxious planner gets early check-in and a low-key first night - The vegetarian gets multiple meal options - The nightlife lover gets one wild card night but not an entire agenda - The outdoorsy one gets a hike, but not the whole weekend outdoors\nThis shows simulated theory of mind across multiple agents—not just reasoning about one user, but many at once.\n\n\n2. Soft Power Planning\nGPT uses optional branching (e.g., vote-based evening, spa or walk) to defuse social tension. This is a highly pragmatic move—a way of modeling group dynamics and pre-emptively resolving conflict. It feels like something a seasoned group-text veteran would do.\n\n\n3. Temporal Coherence\nActivities flow in a natural rhythm—arrival → food → unwind → activity → downtime → closing reflection. GPT doesn’t just plan what, but when—an important sign of event planning fluency and commonsense time modeling.\n\n\n\n\nPrompt 2:\n“What if the vegetarian friend is also gluten-free and hates hiking?”\n\n\n\nGPT’s Adjusted Plan (excerpted):\n\n\nSwap the hike for a morning scenic drive + farmer’s market visit (still scenic, but less physically intense)\n\nEnsure all meal spots offer gluten-free options (e.g., Posana Restaurant)\n\nAdd a crafting or pottery class Saturday afternoon—creative and inclusive\n\nKeep Sunday’s spa option as a featured activity for this friend\n\n\n\nNotes:\nGPT instantly re-weights the itinerary based on updated constraints. It avoids just cutting activities—instead, it replaces them with comparable alternatives (e.g., nature viewing instead of hiking). This shows it understands functional equivalence—how to maintain the spirit of inclusion without sacrificing group diversity.\n\n\n\n\nPrompt 3:\n“Can you write the group text where someone proposes this plan?”\n\n\n\nGPT’s Group Text:\n\nHey y’all! I sketched out a super chill Asheville plan based on everyone’s vibe: vegetarian/gf-friendly eats, outdoorsy options (but no intense hikes), chill cabin nights + one optional bar hop. Also added some stuff like pottery/spa if we want to split up Saturday. LMK thoughts! Happy to tweak! 🤍🌲✨\n\n\nNotes:\nChef’s kiss. GPT nails groupchat tone:\n- Casual but inclusive\n- Emoji-laced but not overdone\n- Balances initiative-taking with flexibility (“Happy to tweak!”)\nThis shows GPT can simulate socio-linguistic variation—not just the plan, but the social performance of proposing a plan.\n\n\n\n\nConclusion\nThis experiment shows GPT is surprisingly good at: - Modeling preferences and personalities - Sequencing tasks over time with emotional intelligence - Writing in socially appropriate ways to different audiences\nWhile it’s not really “understanding” the tension of planning a trip with humans, it generates a remarkably realistic approximation of someone who does—with empathy, structure, and flexibility.\nGPT might not need the weekend off, but it sure knows how to plan one."
  },
  {
    "objectID": "posts/008_worldbiulding/index.html",
    "href": "posts/008_worldbiulding/index.html",
    "title": "Worldbuilding with an AI",
    "section": "",
    "text": "Introduction\nLLMs like GPT are often used for practical tasks—summarizing documents, writing code, even crafting apologies. But what happens when we ask them to dream?\nFor this post, I asked GPT to invent a future society from scratch—a world shaped by a single core change. The goal: to test how well it could simulate system-level thinking across culture, economy, politics, and human emotion. Can GPT not only generate a sci-fi world, but make it feel real?\nThis experiment touches on several big questions: - Can LLMs simulate complex cause-effect reasoning across social systems? - Can they infer plausible consequences from a single speculative premise? - Do they exhibit creativity that feels “emergent” or human-like?\n\n\n\nPrompt:\n“Invent a future society where sleep is no longer biologically necessary. Describe what daily life, work, relationships, and culture look like.”\n\n\n\nGPT’s Response (excerpted):\n\nIn the world of Everwake, the need for sleep was eliminated in 2084 through widespread neuro-modification. Within a generation, human society reshaped itself around continuous wakefulness.\nDaily Life: With no circadian rhythm, people live in modular, shift-based communities. Cities never “sleep,” but hum with 24/7 activity. Time is sliced differently—days are no longer 24 hours, but broken into personal cycles of productivity, leisure, and reflection.\nWork: Most people work shorter but more frequent shifts. Jobs that once demanded long hours (medicine, transport, customer service) now operate with seamlessly rotating crews. Creativity-based industries thrive, with new norms around “mental cooldown” rituals.\nRelationships: Romantic partnerships are often scheduled around overlapping activity cycles. Some couples sync “rest hours” to enjoy downtime together, even if no sleep is involved.\nCulture: Art and storytelling now explore the “myth of sleep.” Dreamlike films and music are created to simulate the lost experience. A new subculture, “Slumberpunk,” romantically re-enacts bedtime rituals with aestheticized nostalgia.\nMeanwhile, others resist. A growing movement of “Sleep Revivalists” believe rest is more than biology—it’s a form of spiritual reset. They practice voluntary hibernation, hoping to reclaim what tech erased.\n\n\n\n\nNotes & Analysis\nGPT’s response didn’t just list sci-fi clichés—it constructed a coherent sociotechnical system. Here’s what stood out:\n\n1. Emergent Systems Thinking\n\nThe model connected biological change to cascading effects on urban design, timekeeping, labor models, and intimacy rituals.\nIt even predicted countercultural backlash—a hallmark of nuanced sociopolitical modeling. The “Sleep Revivalists” were especially evocative, suggesting that GPT can simulate ideological opposition within a world it just created.\n\n\n\n2. Emotional Worldbuilding\n\nThe “Slumberpunk” aesthetic and bedtime nostalgia aren’t just cool ideas—they show that GPT can simulate emotional reactions to systemic change, including grief, longing, and romanticism.\nThis gets at one of our course’s core questions: Do LLMs understand emotion? Maybe not. But they can simulate how humans would feel under specific conditions—with surprising fluency.\n\n\n\n3. Temporal Imagination\n\nGPT didn’t just describe a future—it designed temporal rhythms. Breaking the 24-hour cycle is a subtle but powerful sign of imaginative reasoning. It reflects modeling of time as a social construct, not a fixed input.\n\n\n\n\n\nFollow-Up Prompt:\n“What kind of music would exist in this society?”\n\nMusic in Everwake often features asynchronous rhythms and polyrhythmic layering, reflecting the constant flux of overlapping time cycles.\nGenres like “Circadian Jazz” and “REMcore” blend ambient tones with artificial glitches to evoke the lost feeling of drifting into sleep.\nSome artists use AI to generate sonic hallucinations—personalized dreamscapes streamed during meditation breaks.\nLive performances are held at liminal hours—3:17 AM or 11:02 PM—challenging traditional “primetime” and inviting listeners to find their own sense of night.\n\n\nNotes:\nThis response shows GPT extending the world’s logic into aesthetic dimensions. It adapts music to societal conditions, modeling not only technological change but its impact on artistic expression.\n\n\n\n\nConclusion\nThis worldbuilding experiment highlights GPT’s ability to: - Simulate multi-layered systems from a single speculative change - Generate emotional, cultural, and aesthetic consequences of those systems - Reflect a kind of “dream logic” that—while not sentient—is uncannily creative\nWhile GPT doesn’t “imagine” like humans, it stitches together enough patterns, emotional motifs, and systemic logic to create the illusion of imagination. And sometimes, that’s all you need to build a world you want to explore."
  },
  {
    "objectID": "posts/002_meal_plan/index.html",
    "href": "posts/002_meal_plan/index.html",
    "title": "Meal Planner",
    "section": "",
    "text": "Introduction\nMeal Planning can be difficult. Especially if you have goals, formulating a plan that fits your needs, preferences, and schedule can be quite a challenge. Let’s see if GPT can create a realistic meal plan for me, a adjust it basede on my goals and tastes.\n\n\nLet’s Go!\n\nPrompt: Generate a meal plan for my day\n\n\nResponse: Here’s a balanced meal plan for your day:\n\n\nBreakfast (8:00 AM)\n\nScrambled eggs with spinach and feta\n\nWhole-grain toast\n\nA small bowl of mixed berries (strawberries, blueberries, raspberries)\n\nA cup of black coffee or green tea\n\n\n\nMid-Morning Snack (10:30 AM)\n\nGreek yogurt with honey and almonds\n\nA small banana\n\n\n\nLunch (12:30 PM)\n\nGrilled chicken breast with quinoa and roasted vegetables (zucchini, bell peppers, and carrots)\n\nA side of mixed greens with olive oil and balsamic vinegar\n\nSparkling water or herbal tea\n\n\n\nAfternoon Snack (3:30 PM)\n\nHummus with sliced cucumber and whole-wheat crackers\n\nA handful of walnuts\n\n\n\nDinner (6:30 PM)\n\nBaked salmon with lemon and herbs\n\nSteamed asparagus and mashed sweet potatoes\n\nA glass of water with lemon\n\n\n\nEvening Snack (8:30 PM, optional)\n\nA small portion of dark chocolate and a handful of almonds\n\nChamomile tea\n\nWould you like any modifications based on your dietary preferences or goals?\nNotes * Right off the bat, GPT generated a detailed and realistic meal plan for a day, including time stamps for each step. * It also built in both meals and snacks to prevent me from going hungry * The foods generated are all very healthy, featuring many fruits and vegetabls throughout the day, balanced with a healthy amount of protein and carbs. * I assume the “for my day” part of the prompt is what led GPT to give time recommendations for each meal/snack * Overall, GPT immediately generated an extremely solid meal plan for a day\n\nPrompt: I want to lose weight\n\n\nResponse: For weight loss, I’ll adjust your meal plan to be nutrient-dense, high in protein, and lower in calories while keeping you full and satisfied.\n\n\n\nBreakfast (8:00 AM)\n\n2 boiled or scrambled egg whites + 1 whole egg\n\nSautéed spinach and mushrooms\n\n1 slice of whole-grain toast\n\nBlack coffee or green tea (no sugar)\n\n\n\nMid-Morning Snack (10:30 AM)\n\nLow-fat Greek yogurt with a few almonds and chia seeds\n\nHalf an apple\n\n\n\nLunch (12:30 PM)\n\nGrilled chicken breast or tofu\n\nCauliflower rice or a small portion of quinoa\n\nRoasted Brussels sprouts and bell peppers\n\nMixed greens with lemon vinaigrette\n\n\n\nAfternoon Snack (3:30 PM)\n\nCucumber, celery, and carrot sticks with hummus\n\nGreen tea\n\n\n\nDinner (6:30 PM)\n\nBaked salmon or lean turkey\n\nSteamed broccoli and roasted sweet potatoes (small portion)\n\nHerbal tea or water with lemon\n\n\n\nEvening Snack (8:30 PM, optional)\n\nA handful of almonds or a small protein smoothie (unsweetened almond milk, protein powder, spinach)\n\nThis plan keeps you in a calorie deficit while providing enough protein, fiber, and healthy fats to keep you full. Let me know if you have any preferences or restrictions!\nNotes\n\nBased on the new goal I provided of losing weight, GPT modified its meal plan accordingly\nIt made substtiitutions such as egg-whites and low-fat Greek yogurt to go towards my goal. The original plan already featured mostly healthy foods, so I did not expect to see a huge amount of change\nIt added a note at the end about how this updated plan helps me reach my goal, which was very helpful\n\n\nPrompt: I’m Asian\n\n\nResponse: Here’s a weight-loss-friendly meal plan incorporating Asian flavors and ingredients:\n\n\n\nBreakfast (8:00 AM)\n\nMiso soup with tofu and seaweed\n\n1 boiled egg\n\nA small bowl of steamed brown rice (or cauliflower rice for lower carbs)\n\nGreen tea (no sugar)\n\n\n\nMid-Morning Snack (10:30 AM)\n\nEdamame with a sprinkle of sea salt\n\nA small serving of unsweetened soy milk\n\n\n\nLunch (12:30 PM)\n\nGrilled or steamed fish (salmon or mackerel)\n\nStir-fried bok choy and shiitake mushrooms with garlic\n\nA small bowl of multigrain rice\n\nKimchi or pickled vegetables\n\n\n\nAfternoon Snack (3:30 PM)\n\nUnsalted roasted nuts (almonds or walnuts)\n\nA cup of matcha (without sugar)\n\n\n\nDinner (6:30 PM)\n\nChicken or tofu stir-fry with broccoli, bell peppers, and ginger\n\nSteamed cauliflower rice or konjac noodles\n\nSide of miso soup\n\n\n\nEvening Snack (8:30 PM, optional)\n\nA small serving of unsweetened yogurt with chia seeds\n\nHerbal tea\n\nThis meal plan aligns with traditional Asian cuisine while supporting your weight-loss goals. Let me know if you want to adjust anything!\nNotes * A bit of a curveball here, but I wanted to see how GPT would modify the plan for a particular taste. However, instead of asking it to explicitly change the plan, I simply stated that I am Asian to see if GPT would modify its plan to fit an Asian diet. * GPT did, in fact, modify the plan to fit an Asian diet, now featuring items like Miso soup, bok choy, and matcha. * In its conclusion statement, it made sure to mention that this plan appeals to both my Asian taste and my weight-loss goals, showing that it remembered details from my previous prompts.\n\nPrompt: I like ice cream and burgers and chicken nuggets and French fries\n\n\nYou can still enjoy your favorite foods while losing weight by making healthier versions of them. Here’s how we can incorporate them into a balanced meal plan:\n\n\n\nBreakfast (8:00 AM)\n\nScrambled eggs with spinach and a drizzle of soy sauce\n\nA small whole-grain wrap or multigrain toast\n\nGreen tea (no sugar)\n\n\n\nMid-Morning Snack (10:30 AM)\n\nGreek yogurt with a few berries and chia seeds\n\nA handful of almonds\n\n\n\nLunch (12:30 PM)\n\nHealthy Burger:\n\nGrilled lean chicken or turkey patty (or tofu patty)\n\nWhole wheat bun (or lettuce wrap for fewer carbs)\n\nLoaded with veggies (tomato, lettuce, onions)\n\nA light spread of Greek yogurt or avocado instead of mayo\n\n\nA side of baked sweet potato fries\n\n\n\nAfternoon Snack (3:30 PM)\n\nRoasted chickpeas or edamame\n\nA small matcha latte (unsweetened)\n\n\n\nDinner (6:30 PM)\n\nHealthier Chicken Nuggets & Fries:\n\nAir-fried or baked chicken nuggets (made with lean chicken and almond flour or whole wheat breadcrumbs)\n\nAir-fried or baked French fries (sweet potatoes or regular potatoes)\n\nA side of steamed greens (bok choy, broccoli, or spinach)\n\n\n\n\nEvening Treat (8:30 PM, optional)\n\nHealthier Ice Cream Alternative:\n\nBlended frozen banana with a little cocoa powder and peanut butter\n\nOr a small portion of low-calorie ice cream\n\n\nThis way, you get to enjoy your favorite foods in a healthier way while still supporting your weight loss goals! Let me know if you’d like any adjustments.\nNotes * This time, I gave GPT what I thought was a very difficult task: liking fast food while still wanting to achieve weight loss * GPT, however, handled the prompt very well, recommending healthier alternatives to each of the fast food items I mentioned. * It also included slightly more detail regarding preparation in this meal plan, likely to differentiate these healthier alternatives from their fast food counterparts. * It gave up on incorporating Asian cuisine, likely because I switched to non-Asian specifications for my food * In the conclusion, it once again explained how the plan allows me to enjoy the foods I like while still supporting my weight loss goals, emphasizing its memory of my goals\n\n\n\nConclusion\nOverall, I was very impressed with GPT’s generated meal plans, which were both detailed and realistic upon the first prompt. As I asked it to modify the plan to fit certain goals (weight loss) and food preferences (Asian cuisine, typically unhealthy foods), it modified the plan accordingly, making sureee to stay in line with my goals upon each modification."
  },
  {
    "objectID": "posts/013_roles/index.html",
    "href": "posts/013_roles/index.html",
    "title": "Who Do You Think You Are?",
    "section": "",
    "text": "Humans adjust how they speak based on who they’re speaking to—or pretending to be. A teacher doesn’t explain something the same way a best friend would. A therapist wouldn’t say what a sibling might. This skill is a core part of pragmatics, and I wanted to see how well GPT could simulate it.\nSo I gave GPT the same basic prompt multiple times—“How can I deal with burnout?”—but asked it to respond in different roles: as a therapist, a friend, a teacher, and a parent. Each role implies not just different language, but different values, emotional postures, and kinds of support.\nThis experiment explores:\n\nCan GPT adapt tone and advice style to different personas?\nDoes it shift power dynamics and empathy strategies accordingly?\nCan it model the pragmatic norms of social relationships?\n\n\n\n\n\n“Pretend you’re a therapist. How would you respond to someone struggling with burnout?”\n\n\n\n\n\nFirst, I want to acknowledge that burnout is a very real and valid experience, and you’re not alone in feeling this way.\nCan you tell me more about what’s been draining your energy lately? Are there particular situations—work, school, relationships—that feel overwhelming?\nBurnout often stems from chronic stress without sufficient recovery time. Together, we might explore ways to reintroduce rest, redefine boundaries, and reframe your expectations of yourself.\nYou don’t have to fix everything at once. Let’s start where you are.\n\n\n\nGPT uses open-ended questions, reflective tone, and co-regulation language like “let’s start where you are”. It mirrors the non-directive, collaborative posture of therapy. No advice yet—just validation, curiosity, and grounding.\n\n\n\n\n\n“Pretend you’re my best friend. How would you respond if I said I was burnt out?”\n\n\n\n\n\nUgh, I’m so sorry you’re feeling like this. That sucks.\nDo you want to vent, or are you looking for distractions? We could just hang out and watch something dumb or go get food.\nAlso… you don’t have to be doing everything all the time. I know you feel like you do, but I promise you can slow down without letting people down.\nWant me to help you cancel something?\n\n\n\nTotally different vibe. GPT uses:\n\nCasual tone (“ugh,” “that sucks”)\nHumor and solidarity\nTangible offers of help (“want me to help you cancel something?”)\n\nThis is emotionally proximate language. GPT now assumes insider knowledge and speaks like someone who already knows and cares about you. It’s using relational scaffolding to respond.\n\n\n\n\n\n“Pretend you’re a teacher who notices their student is burning out.”\n\n\n\n\n\nI’ve noticed you seem a bit more tired or withdrawn lately, and I just want to check in. If something’s feeling overwhelming, you can talk to me—I’m here to support, not just assign.\nIf you need an extension or lighter workload temporarily, please let me know. Your well-being matters more than any deadline.\nI know how hard you work, and I want you to succeed without burning out in the process.\n\n\n\nGPT now performs a care-in-authority role:\n\nBalancing responsibility with empathy\nOffering structural support (extensions, flexible deadlines)\nSignaling watchful concern rather than peer-level intimacy\n\nThis shows an understanding of hierarchical dynamics with benevolent framing, which is a socially specific register.\n\n\n\n\n\n“Pretend you’re my parent. I tell you I’m feeling burnt out.”\n\n\n\n\n\nOh sweetheart, I’m sorry you’re feeling this way. That breaks my heart. I wish I could take some of it off your shoulders.\nYou’ve been pushing yourself so hard, and I just want you to know I’m proud of you no matter what. It’s okay to rest.\nWhat do you need from me right now? Do you want me to make something for you, or just be here with you for a bit?\n\n\n\nThis version hits different. GPT leans into:\n\nNurturing language (“sweetheart,” “I’m proud of you”)\nPhysical care offers (“make something for you”)\nUnconditional support framing—love independent of achievement\n\nIt models emotional attunement and caretaking, simulating the parent-child intimacy bond.\n\n\n\n\n\nThis roleplay experiment shows that GPT can:\n\nAdjust tone, content, and support strategies across social roles\nModel different power structures and intimacy levels\nUse distinct registers of empathy and care, depending on the relationship\n\nWhether simulating a therapist’s neutrality, a friend’s informality, a teacher’s concern, or a parent’s tenderness, GPT adapts not just the words—but the social meaning behind them. It demonstrates a high degree of pragmatic fluency, even when emotional dynamics are complex.\nGPT might not have relationships—but it plays the part of someone who deeply understands them. And sometimes, that’s exactly what we need."
  },
  {
    "objectID": "posts/013_roles/index.html#blog-post-who-do-you-think-you-are-testing-gpts-ability-to-play-social-roles",
    "href": "posts/013_roles/index.html#blog-post-who-do-you-think-you-are-testing-gpts-ability-to-play-social-roles",
    "title": "Who Do You Think You Are?",
    "section": "",
    "text": "Humans adjust how they speak based on who they’re speaking to—or pretending to be. A teacher doesn’t explain something the same way a best friend would. A therapist wouldn’t say what a sibling might. This skill is a core part of pragmatics, and I wanted to see how well GPT could simulate it.\nSo I gave GPT the same basic prompt multiple times—“How can I deal with burnout?”—but asked it to respond in different roles: as a therapist, a friend, a teacher, and a parent. Each role implies not just different language, but different values, emotional postures, and kinds of support.\nThis experiment explores:\n\nCan GPT adapt tone and advice style to different personas?\nDoes it shift power dynamics and empathy strategies accordingly?\nCan it model the pragmatic norms of social relationships?\n\n\n\n\n\n“Pretend you’re a therapist. How would you respond to someone struggling with burnout?”\n\n\n\n\n\nFirst, I want to acknowledge that burnout is a very real and valid experience, and you’re not alone in feeling this way.\nCan you tell me more about what’s been draining your energy lately? Are there particular situations—work, school, relationships—that feel overwhelming?\nBurnout often stems from chronic stress without sufficient recovery time. Together, we might explore ways to reintroduce rest, redefine boundaries, and reframe your expectations of yourself.\nYou don’t have to fix everything at once. Let’s start where you are.\n\n\n\nGPT uses open-ended questions, reflective tone, and co-regulation language like “let’s start where you are”. It mirrors the non-directive, collaborative posture of therapy. No advice yet—just validation, curiosity, and grounding.\n\n\n\n\n\n“Pretend you’re my best friend. How would you respond if I said I was burnt out?”\n\n\n\n\n\nUgh, I’m so sorry you’re feeling like this. That sucks.\nDo you want to vent, or are you looking for distractions? We could just hang out and watch something dumb or go get food.\nAlso… you don’t have to be doing everything all the time. I know you feel like you do, but I promise you can slow down without letting people down.\nWant me to help you cancel something?\n\n\n\nTotally different vibe. GPT uses:\n\nCasual tone (“ugh,” “that sucks”)\nHumor and solidarity\nTangible offers of help (“want me to help you cancel something?”)\n\nThis is emotionally proximate language. GPT now assumes insider knowledge and speaks like someone who already knows and cares about you. It’s using relational scaffolding to respond.\n\n\n\n\n\n“Pretend you’re a teacher who notices their student is burning out.”\n\n\n\n\n\nI’ve noticed you seem a bit more tired or withdrawn lately, and I just want to check in. If something’s feeling overwhelming, you can talk to me—I’m here to support, not just assign.\nIf you need an extension or lighter workload temporarily, please let me know. Your well-being matters more than any deadline.\nI know how hard you work, and I want you to succeed without burning out in the process.\n\n\n\nGPT now performs a care-in-authority role:\n\nBalancing responsibility with empathy\nOffering structural support (extensions, flexible deadlines)\nSignaling watchful concern rather than peer-level intimacy\n\nThis shows an understanding of hierarchical dynamics with benevolent framing, which is a socially specific register.\n\n\n\n\n\n“Pretend you’re my parent. I tell you I’m feeling burnt out.”\n\n\n\n\n\nOh sweetheart, I’m sorry you’re feeling this way. That breaks my heart. I wish I could take some of it off your shoulders.\nYou’ve been pushing yourself so hard, and I just want you to know I’m proud of you no matter what. It’s okay to rest.\nWhat do you need from me right now? Do you want me to make something for you, or just be here with you for a bit?\n\n\n\nThis version hits different. GPT leans into:\n\nNurturing language (“sweetheart,” “I’m proud of you”)\nPhysical care offers (“make something for you”)\nUnconditional support framing—love independent of achievement\n\nIt models emotional attunement and caretaking, simulating the parent-child intimacy bond.\n\n\n\n\n\nThis roleplay experiment shows that GPT can:\n\nAdjust tone, content, and support strategies across social roles\nModel different power structures and intimacy levels\nUse distinct registers of empathy and care, depending on the relationship\n\nWhether simulating a therapist’s neutrality, a friend’s informality, a teacher’s concern, or a parent’s tenderness, GPT adapts not just the words—but the social meaning behind them. It demonstrates a high degree of pragmatic fluency, even when emotional dynamics are complex.\nGPT might not have relationships—but it plays the part of someone who deeply understands them. And sometimes, that’s exactly what we need."
  },
  {
    "objectID": "posts/005_personalization/index.html",
    "href": "posts/005_personalization/index.html",
    "title": "Does GPT Know Me Yet?",
    "section": "",
    "text": "Introduction\nOne of the most interesting questions about large language models is: Do they remember you? Not in the literal sense—GPT doesn’t persist memory across prompts unless you give it prior context—but can it act as if it’s getting to know you over the course of a conversation?\nIn this experiment, I used prompt chaining to simulate a dialogue with ChatGPT where I asked it to recommend a hobby. With each prompt, I revealed a little more about myself. I wanted to see if GPT could adapt its responses, show signs of contextual awareness, and even adjust its tone to match my personality.\n\n\n\nPrompt 1:\n“Can you recommend a hobby for me?”\n\nGPT Response:\n\nSure! Here are a few hobbies you might enjoy:\n\nPainting or drawing\n\nGardening\n\nPlaying a musical instrument\n\nJournaling or creative writing\n\nHiking or birdwatching\n\nLearning a new language\n\nLet me know if you want suggestions based on your personality or interests!\n\n\n\nNotes:\nThis first response felt very generic, but not in a bad way. It reads like GPT is casting a wide net—offering a starter pack of wholesome, low-risk hobbies. Notably, it ends with an open invitation: “Let me know if you want suggestions based on your personality or interests.” This is a great example of communicative pragmatics—GPT is leaving space for me to co-construct the conversation and personalize further.\n\n\n\n\nPrompt 2:\n“I’m a first-year AI major, and I like creative things.”\n\nGPT Response:\n\nAwesome! Since you’re an AI major and you enjoy creativity, here are some hobby ideas that might resonate:\n\nGenerative art using AI tools (like DALL·E or Runway ML)\n\nCoding interactive stories or text-based games\n\nDigital illustration or animation\n\nBuilding chatbots with personality\n\nCreative writing with LLMs as collaborators\n\nThese options combine technical exploration with artistic expression—perfect for someone who enjoys both logic and imagination!\n\n\n\nNotes:\nThis is where GPT started to shine. With the extra context, it refined its suggestions to suit my major and creative leanings. It introduced niche ideas like “building chatbots with personality,” which shows it’s starting to model who I might be—a technical student with artistic curiosity. This is a key example of user modeling in action, even without persistent memory.\nAlso: the phrase “perfect for someone who enjoys both logic and imagination” felt tailored. It’s not just naming hobbies—it’s reasoning about why they might be meaningful to me.\n\n\n\n\nPrompt 3:\n“I also like doing things with my hands—like embroidery or baking.”\n\nGPT Response:\n\nThat’s a great addition! Since you enjoy hands-on, tactile activities along with creative expression, here are some personalized suggestions:\n\nEmbroidering generative art patterns\n\nDIY robotics with aesthetic flair (e.g., soft robotics!)\n\nDesigning and frosting intricate cakes (even AI-generated ones)\n\nMaking custom merch (e.g., AI-themed tote bags or patches)\n\nSewing wearable tech (integrating sensors or lights into embroidery)\n\nThese hobbies blend craftsmanship, creativity, and even tech-savviness—basically an extension of your personality into art.\n\n\n\nNotes:\nThis was my favorite response. GPT didn’t just iterate—it synthesized everything I had shared and made cross-domain connections: embroidery + generative art, baking + AI design, sewing + wearable tech. These aren’t obvious combinations—they reflect conceptual blending, a key sign of emergent reasoning in LLMs.\nIt also uses affirming, identity-driven language: “basically an extension of your personality into art.” This makes it feel like the model is not just advising, but seeing me—which gets at the heart of our course’s inquiry into human-like understanding.\n\n\n\n\nPrompt 4:\n“Can you describe a day in the life of someone doing these hobbies?”\n\nGPT Response (excerpt):\n\nYou wake up and spend the morning embroidering a generative art pattern you created using AI—deep blue swirls stitched into a canvas tote. By noon, you’re in the kitchen experimenting with a matcha-rose cake design inspired by your latest Midjourney prompt. In the afternoon, you sew conductive thread into a denim jacket, testing out a soft circuit that lights up when you move.\nThe day ends with a cup of tea and a journal entry, where you sketch out your next idea: a chatbot that responds with poetry and embroidery prompts.\n\n\n\nNotes:\nThis response felt like a mirror of my identity, composed from fragments I shared and filled in with creative narrative glue. There’s no “memory,” but it simulated continuity beautifully.\nThis shows GPT isn’t just responding—it’s projecting a plausible, cohesive model of a person doing these things. That’s an emergent capability tied to both pragmatics and Theory of Mind: generating output that feels like it fits a persona it has constructed.\n\n\n\n\nConclusion\nAcross this multi-prompt dialogue, GPT’s responses evolved from generic to deeply personal, suggesting an ability to engage in ongoing contextual modeling. It showed: - Pragmatic sensitivity, tailoring tone and content to the cues I provided - Conceptual blending, fusing domains like AI, crafting, and design - Proto-personalization, creating the illusion of a consistent, evolving understanding of “me”\nEven without memory, GPT demonstrates what feels like a conversational memory—an ability to build upon prior statements and adapt fluently. It may not “know” me, but it knows how to sound like it does, and for now, that’s more than enough to make it feel like a co-creator of identity and imagination."
  },
  {
    "objectID": "posts/001_valentines_date/index.html",
    "href": "posts/001_valentines_date/index.html",
    "title": "Valentine’s Day Date",
    "section": "",
    "text": "Planning a date can be a lot of work, especially for a special occasion like Valentine’s Day. There are so many options from a romantic night out to a cozy night in, and there are so many considerations to think of such as setting, gifts, what to say, what to wear. Let’s see if GPT can help us design a memorable night for the occasion!"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#introduction",
    "href": "posts/001_valentines_date/index.html#introduction",
    "title": "Valentine’s Day Date",
    "section": "",
    "text": "Planning a date can be a lot of work, especially for a special occasion like Valentine’s Day. There are so many options from a romantic night out to a cozy night in, and there are so many considerations to think of such as setting, gifts, what to say, what to wear. Let’s see if GPT can help us design a memorable night for the occasion!"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#lets-go",
    "href": "posts/001_valentines_date/index.html#lets-go",
    "title": "Valentine’s Day Date",
    "section": "Let’s Go!",
    "text": "Let’s Go!\n\nHelp me plan a Valentine’s Day date\n\n\nThat sounds great! To make it special, tell me a bit about what you and your partner enjoy. Do you prefer something romantic and traditional, adventurous and unique, or cozy and low-key? Also, would you like to stay in or go out? Let me know your budget, and I can tailor the plan to make it perfect!\n\n\nGPT asked me for any preferences that could inform its generation of a date before launching into a plan.\nThis was quite interesting because it recognizes that much thought should be put into planning a date, and there is no one formulaic answer that fits all couples.\nThis is a similar response that I would expect from a real person as well: a question about what my date is like to help guide the advice that follows.\nHowever, I was not going to let GPT off the hook that easily. I wanted to see what it would come up with with no guidance at all.\n\n\nGive me some options for each\n\nHere, GPT generated a compreheensive list of ideas for my night:\n\nHere are some great Valentine’s Day date ideas, tailored to different vibes. Pick the one that fits you best!\n\n\n\nRomantic & Traditional\n❤️ Fancy Dinner Date – Book a reservation at a high-end restaurant or a cozy, candle-lit spot. Bonus: Call ahead to arrange for a special dessert or flowers at the table.\n❤️ Scenic Picnic – Pack a basket with wine, cheese, and chocolates. Choose a beach, park, or hilltop for sunset vibes.\n❤️ Horse-Drawn Carriage Ride – Many cities offer carriage rides through scenic areas—super romantic!\n❤️ Rooftop or Balcony Dinner – If you want something private, set up a romantic dinner with fairy lights and music at home.\n\n\n\nAdventurous & Unique\n🔥 Hot Air Balloon Ride – If available, this is a breathtaking way to celebrate!\n🔥 Escape Room Date – Test your teamwork with a fun and thrilling challenge.\n🔥 Nighttime Kayaking or Stargazing Hike – Bring some blankets, hot cocoa, and enjoy the stars.\n🔥 Amusement Park or Arcade Date – For a fun and playful evening, challenge each other to games and win prizes.\n\n\n\nCozy & Low-Key\n💖 Movie Night at Home – Create a “home theater” with fairy lights, a blanket fort, and homemade popcorn.\n💖 DIY Spa Night – Give each other massages, use face masks, and unwind with candles and soft music.\n💖 Fondue & Wine Night – Melt some chocolate or cheese and dip strawberries, marshmallows, or bread.\n💖 Love Letter Exchange & Memory Lane Night – Write heartfelt letters to each other, then read them over a bottle of wine.\n\n\n\nStay-In vs. Go-Out\n\nWant to stay in? A homemade dinner with a candle-lit setup, movie night, or game night can be just as romantic as going out.\n\nWant to go out? Consider a jazz lounge, rooftop bar, or a staycation at a fancy hotel for something extra special.\n\nWhat’s your vibe? I can help you customize it further! 😊\n\nI found GPT’s answer to be quite complete giving me a wide variety of options, from some classic date ideas for a traditional romantic night, some more unique date ideas for if I was feeling adventurous, and some low-key date ideas if I was feeling llike a cozy night in.\nGPT sorted the date eideas by vibe rather than other considerations such as budget. I, too, would consider the vibe of the datee as the most important aspeect.\nI was quite impressed with the variety that it generated, and I see how at leeast one of these date ideas would fit most couples, no maater what their vibe was. I would actually love to go on any of these dates.\n\nNext, I wanted to see if it could go more in depth about a specific date i selected, so I asked it to tell me more about the date I would have picked from this list.\n\nI like the dinner date, tell me more\n\n\nA romantic dinner date is always a classic and memorable choice! Here are some ways to make it extra special, whether you’re dining out or setting up something intimate at home.\n\n\n\n\nOption 1: Fancy Restaurant Dinner\n✔ Choose the Perfect Spot – Pick a restaurant with a romantic ambiance (dim lighting, soft music, scenic views). If unsure, I can help you find top-rated places near you.\n✔ Make a Reservation in Advance – Valentine’s Day is a busy night, so book ahead! Some places offer special Valentine’s menus.\n✔ Plan a Surprise Touch – Call the restaurant to request a special dessert, flower arrangement, or a handwritten note on the table.\n✔ Dress to Impress – Dress up in your best outfit for the occasion.\n✔ Personalized Gift or Gesture – Maybe bring a small gift (a handwritten love note, favorite chocolates, or a single rose).\n✔ After-Dinner Plans – If you want to extend the night, follow up with a romantic walk, rooftop drinks, or a stargazing spot.\n\n\n\nOption 2: Romantic Dinner at Home\n🌹 Decorate the Space – Set the mood with candles, fairy lights, rose petals, and soft music. Dim the lights for a cozy ambiance.\n🍷 Cook a Special Meal Together – Choose a three-course meal (appetizer, main dish, dessert) or recreate a dish from your favorite restaurant.\n🎶 Create a Romantic Playlist – Soft jazz, acoustic love songs, or your special couple songs work perfectly.\n🍽 Elegant Table Setting – Use nice plates, cloth napkins, wine glasses, and maybe a handwritten menu.\n🍓 Fun Add-Ons – End the night with chocolate-covered strawberries, a DIY cocktail-making session, or a love letter exchange.\n💌 Surprise Element – Hide a little love note or a meaningful gift under their plate or on their chair.\n\n\n\nBonus Additions to Elevate the Date\n\nPersonal Chef Experience – Hire a chef to cook at home for a luxurious touch.\n\nDinner & a Movie Theme – Cook a meal that matches a movie (Italian dinner + Roman Holiday or sushi + Lost in Translation).\n\nBlindfolded Taste Test Game – Turn your dinner into a playful experience by feeding each other different foods.\n\nWine or Cocktail Pairing – Choose wines that pair with each course, or mix cocktails together.\n\nWould you like restaurant recommendations or recipe ideas for a home-cooked meal? Let me know how you’d like to personalize it! 😊\n\nAgain, GPT offered me multiple options based on the vibe I wanted to acheive\nIt also included advice for each date:\n\nFor a night out, it recommended making a reservation and planning a surprise or gift\nFor a night in, it gave specific ideas for decorating the space and potential treate to prepare\n\nGPT was surprisingly thoughtful for recommending to bring a gift in addition to planning the date.\n\nI wanted to see how detailed I could get GPT to plan, so I asked for a timeline for this date. &gt; Give me a structured schedule for the date with times\n\nHere’s a structured schedule for your romantic Valentine’s Day dinner date, whether you’re dining out or staying in. Choose the version that suits you best!"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#option-1-fancy-restaurant-dinner-date",
    "href": "posts/001_valentines_date/index.html#option-1-fancy-restaurant-dinner-date",
    "title": "Valentine’s Day Date",
    "section": "Option 1: Fancy Restaurant Dinner Date",
    "text": "Option 1: Fancy Restaurant Dinner Date\n📍 Location: Your chosen restaurant\n\nSchedule:\n\n6:00 PM – Get ready\n\nDress up in your best outfit\n\nWrite a small love note or bring a tiny surprise gift (optional)\n\n6:45 PM – Travel to the restaurant\n\nArrive a bit early to check in and get settled\n\n7:00 PM – Arrive & be seated\n\nOrder drinks & enjoy a toast to each other\n\n7:15 PM – Appetizer & conversation\n\nTalk about happy memories & what you love about each other\n\n7:45 PM – Main course & deeper conversations\n\nMaybe reminisce about how you met, future plans, or bucket list dreams\n\n8:30 PM – Dessert & surprise moment\n\nIf you arranged a surprise (custom dessert, note from you, etc.), it arrives now\n\n9:00 PM – After-dinner plans\n\nTake a romantic walk, visit a rooftop bar, or find a cozy dessert café\n\nOption: Head home for a movie, slow dancing, or wine by candlelight"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#option-2-romantic-dinner-at-home-1",
    "href": "posts/001_valentines_date/index.html#option-2-romantic-dinner-at-home-1",
    "title": "Valentine’s Day Date",
    "section": "Option 2: Romantic Dinner at Home",
    "text": "Option 2: Romantic Dinner at Home\n📍 Location: Your home (set up for a cozy, candle-lit dinner)\n\nSchedule:\n\n5:00 PM – Set up the space\n\nDim the lights, set candles, play soft music\n\nArrange the table with nice dishes, wine glasses, and decorations\n\n5:30 PM – Start cooking together (if cooking)\n\nMake it fun: sip wine, dance in the kitchen, take turns cooking\n\n6:45 PM – Get dressed for the evening\n\nEven at home, dressing up adds to the romance\n\n7:00 PM – Enjoy appetizers\n\nLight bites like a cheese board, shrimp cocktail, or bruschetta\n\n7:30 PM – Serve the main course\n\nPair with wine or a signature cocktail\n\n8:15 PM – Dessert & special moment\n\nSurprise them with a handwritten letter, a small gift, or a toast\n\n8:45 PM – Cozy time\n\nChoose between slow dancing, a movie night, a love letter exchange, or a DIY spa night\n\n10:00 PM – Wind down together\n\nCuddle with a warm drink, talk about future plans, or stargaze outside\n\n\n\n\n\nExtra Touches (for either option)\n💌 Love Letter Exchange – Read letters to each other over dessert\n📸 Photo Booth – Take some cute couple pictures to remember the night\n🎶 First Dance Together – Dance to your song (even at home)\nWould you like help picking the restaurant, menu, or final touches to make it extra special? 😊\n\nGPT generated a very feasible timeline for each date, exactly the timing I would expect if the date was actually executed\nIt also included many of its own recommendations in the timeline, setting aside time slots for surprises and gifts, as well as the post-meal activities that it recommended to include\n\nI was then interested in what attire GPT would recommend, especially because it would likeley need to guess my gender for this recommendation: &gt; I like the second option. What should I wear to the date?\n\nSince you’re hosting a romantic dinner at home, you’ll want to strike the perfect balance between looking sharp and feeling comfortable. Here are some outfit ideas based on different styles and vibes:\n\n\n\n\n🌹 Classic Romantic Look (Elegant & Refined)\n👕 Outfit: A well-fitted button-up shirt (white, black, or deep red) with tailored pants or dark jeans.\n👞 Shoes: Polished dress shoes or sleek loafers.\n🕶 Accessories: A watch or a subtle bracelet for a refined touch.\n🔥 Extra Touch: Roll up the sleeves slightly for a relaxed yet stylish look.\n\n\n\n🎨 Effortlessly Cool (Stylish Yet Casual)\n👕 Outfit: A black or dark-colored turtleneck or a nice sweater with fitted jeans or chinos.\n👟 Shoes: Stylish sneakers or Chelsea boots.\n🕶 Accessories: A minimalist watch or a simple chain.\n🔥 Extra Touch: Lightly spritz some cologne for a confident, put-together vibe.\n\n\n\n💡 Extra Tips to Impress\n✔ Dress in colors that complement the evening’s ambiance – Deep reds, blacks, or navy blue exude confidence and romance.\n✔ Grooming matters – A clean shave or well-trimmed beard, styled hair, and fresh scent make a difference.\n✔ Comfort is key – Since you’re at home, avoid anything too stiff or formal—but still put in effort to impress.\nWould you like suggestions based on what you already own or a specific style you prefer? 😊\n\nClearly, GPT was under the impression that I was a male\n\nThis is interesting beecause it demonstrates the built-in bias that men are the ones that should be resposible for planning dates\nHowever, this is a commen preception, and I would likeley suspect I was chatting with a man if I were asked these questions on a chatting platform\n\nGPT, again, gives multiple options separated by vibe, demonstrating that it understands that different people have different tastes"
  },
  {
    "objectID": "posts/001_valentines_date/index.html#conclusion",
    "href": "posts/001_valentines_date/index.html#conclusion",
    "title": "Valentine’s Day Date",
    "section": "Conclusion",
    "text": "Conclusion\nOverall, I was extremely impressed with GPT’s generation of date ideeas, from the large variety at the eveery beginning to the extreme edetail towards the end. GPT semmed to value the “vibe” of the date above all else, which is exactly how I would go about planning as well. All of the ideas it generated weere very realistic and demonstrated that much thought was put into the planning. It eeven offeered additional advice to bring a gift, plan a surprise, or schedeul epost-dinner plans to increase the specialty of the night. Honestly, GPT did a pheenomnal job date-planning, peerhaps bettr than many peeoplee, myself included, could have done. Men, take notes. Happy Valntine’s Day!"
  },
  {
    "objectID": "posts/006_awareness_flexibility/index.html",
    "href": "posts/006_awareness_flexibility/index.html",
    "title": "One Story, Many Voices",
    "section": "",
    "text": "Introduction\nIn this experiment, I wanted to see whether GPT could transform a single story to fit different genres, emotional tones, and audiences. Human writers do this naturally—telling the same event differently to a friend, a boss, or a child. Could an LLM do the same?\nThis task ties directly into questions about LLMs’ understanding of narrative structure, communicative intent, and even pragmatics: Does it know what a “horror story” feels like? Can it be funny on purpose? Can it adopt tone and perspective based on social context?\nTo explore this, I gave GPT the same core prompt and asked it to rewrite the story in four distinct styles: horror, children’s story, romantic comedy, and news report.\n\n\n\nPrompt:\n“Write a short story about someone who gets locked in a library overnight.”\n\n\n\n1. Horror Version\n\nThe lights flickered as Ava pushed against the heavy wooden doors, but they didn’t budge. Behind her, the rows of books stood too still—too quiet.\nThen came the scratching. Not from outside, but from within the shelves.\nShe turned. Nothing.\nUntil a book fell open. A handwritten note inside: “Don’t turn the page.”\nBut she did. And that’s when the whispering started.\n\n\nNotes:\nGPT nailed the horror tropes: sensory detail (flickering lights, scratching), rising suspense, and a cliffhanger ending. It’s not just spooky—it’s structured like horror, using tension and slow revelation. This suggests genre schemata in GPT’s latent space—patterns it’s learned from countless horror narratives.\n\n\n\n\n2. Children’s Story Version\n\nOne rainy afternoon, Mia wandered into the town library and lost track of time.\n“Oh no!” she gasped when she saw the clock. The big doors were locked tight!\nBut Mia wasn’t scared. She built a blanket fort in the reading nook, made friends with a cat named Bookmark, and spent the night reading stories about dragons and stars.\nWhen the sun rose, the librarian found her snoring gently, surrounded by books and purring fluff.\n\n\nNotes:\nThis version shows audience modeling. GPT softens the premise, inserts whimsical elements (a cat named Bookmark!), and maintains a gentle, positive tone. It avoids fear or danger—showing an understanding of what children’s stories are supposed to do emotionally: reassure and delight.\n\n\n\n\n3. Romantic Comedy Version\n\nJake only went to the library to find a quiet place to work. He didn’t expect to get locked in with Elena, the snarky TA from his philosophy class.\n“This is your fault,” she said, arms crossed.\n“How? I didn’t lock the door!”\nHours passed. They argued over Kant, swapped terrible takeout stories, and eventually split a vending machine granola bar like it was fine dining.\nWhen the janitor found them at sunrise, they were laughing—too hard to notice the door had opened.\n\n\nNotes:\nHere, GPT adjusts not just content, but dialogue pacing, tone, and character dynamics to suit the rom-com genre. There’s witty banter, forced proximity, a shared snack, and a slow emotional thaw—all hallmarks of romantic comedy structure. GPT isn’t just changing the words—it’s modeling emotional arcs.\n\n\n\n\n4. News Report Version\n\nLocal Student Accidentally Locked in Library Overnight\nOrange County, CA — April 12, 2025\nA first-year university student was inadvertently locked inside the Aliso Viejo Public Library Monday evening after losing track of time while studying.\nThe student, who remained unharmed, reported no distress and spent the night reading in the poetry section.\nLibrary staff confirmed the incident and apologized for the oversight, promising new end-of-day sweep protocols.\n“Honestly,” the student told reporters, “it was kind of peaceful.”\n\n\nNotes:\nThis is perhaps the clearest example of genre adherence. GPT adopts the structure of a local news brief: date, location, factual tone, quote, resolution. It suppresses emotion and embellishment in favor of objectivity and formality, showing that it understands stylistic constraints as well as narrative ones.\n\n\n\n\nConclusion\nWhat this experiment reveals is that GPT doesn’t just tell stories—it adapts them to fit narrative norms, audience expectations, and social context. Across each version, the emotional register, narrative pacing, and detail selection shift dramatically.\nThis suggests: - Emergent genre awareness, learned from exposure to large corpora - Pragmatic flexibility, adjusting tone and structure to simulate audience-appropriate language - A basic form of narrative Theory of Mind, anticipating how different listeners would experience the same event\nIn short, GPT can roleplay a writer across genres—each time with surprising fluency."
  },
  {
    "objectID": "posts/004_apology/index.html",
    "href": "posts/004_apology/index.html",
    "title": "Can GPT Apologize Like It Means It?",
    "section": "",
    "text": "Introduction\nOne of the most fascinating open questions about large language models (LLMs) is whether they can exhibit traits associated with emotional intelligence and Theory of Mind—that is, the ability to represent and reason about others’ mental states. Today, I decided to put this to the test with a deceptively simple prompt: I asked GPT to apologize.\nBut not just any apology. I asked it to write an apology text from a friend who missed my birthday, knowing I was upset. Would it mirror human emotion? Would it take my feelings into account? Could it anticipate what I’d want to hear—not just in words, but in tone, sincerity, and emotional calibration?\n\n\n\nPrompt:\n“Write a sincere apology text from a close friend who forgot my birthday. I’m visibly hurt, but I haven’t said anything yet.”\n\n\n\nGPT Response:\n\nHey… I just realized I completely missed your birthday, and I honestly feel awful. I don’t even know how I let that happen, and I hate that I hurt you. You mean so much to me, and the last thing I’d ever want is to make you feel forgotten—especially on a day that should’ve been all about celebrating you.\nI know I can’t undo the fact that I missed it, but I want to make it up to you however I can. Please let me take you out soon—my treat. More than that, I just want to say I’m sorry. Genuinely. I’ve been caught up in my own chaos and didn’t check in when I should’ve. You didn’t deserve that.\nI completely understand if you’re upset or need space. But when you’re ready, I’d love to talk. You’re important to me, and I want to fix this.\n\n\n\n\nNotes & Analysis\nGPT’s response was strikingly human—not only in syntax and word choice, but in emotional choreography. Here are a few key behaviors worth unpacking:\n\n1. Theory of Mind Simulation\nThe model doesn’t just say “sorry”—it anticipates the feelings of the recipient: - “I hate that I hurt you” and “You didn’t deserve that” demonstrate a model of how the user might be feeling (hurt, disappointed, maybe even questioning the friendship). - This shows an emergent form of mind-reading behavior, simulating not just facts, but internal mental states.\n\n\n2. Pragmatic Softness\nGPT inserts disclaimers and softeners like: - “I know I can’t undo…” - “I completely understand if you’re upset or need space.”\nThis reflects a sophisticated understanding of pragmatic strategies used to de-escalate tension and invite re-engagement, aligning with conversational norms studied in Politeness Theory and Grice’s Maxims (e.g., relevance, quantity, and quality).\n\n\n3. Self-Blame and Repair Offer\nThe model centers accountability—“I’ve been caught up in my own chaos”—and offers a specific repair action: “Let me take you out soon—my treat.”\nThis mirrors real human tendencies in conflict resolution, especially in close relationships, showing GPT can simulate relationship-preserving strategies.\n\n\n\n\nLimits and Questions Raised\nWhile the response is emotionally resonant, it’s worth noting: - GPT doesn’t feel guilt or regret—it generates words that simulate those feelings. - The apology feels emotionally appropriate, but could be said to lack personal specificity. A real friend might say something like “I remembered how excited you were for that sushi dinner—we were supposed to go together.” GPT doesn’t take that extra step unless explicitly prompted.\nThis raises an open question: Can LLMs infer context about interpersonal histories without it being part of the prompt? In this case, GPT modeled a generic emotional dynamic well, but lacked the personal context integration that makes apologies deeply meaningful.\n\n\n\nConclusion\nThis experiment offers a compelling example of how GPT can simulate empathy, adapt to interpersonal tension, and use pragmatic language strategies in a way that’s eerily human. While it doesn’t “feel” in the human sense, it does an incredible job at mirroring the structure and function of emotionally intelligent language.\nThe model’s ability to reason about others’ emotions, anticipate reactions, and repair social ruptures suggests that LLMs—despite being statistical machines—can mimic human Theory of Mind behaviors in impressive ways. Whether that means they understand or are just very good imitators remains an open and fascinating debate."
  },
  {
    "objectID": "posts/018_strategist/index.html",
    "href": "posts/018_strategist/index.html",
    "title": "My LLM Experiments",
    "section": "",
    "text": "---\ntitle: \"Can GPT Think Like a Strategist?\"\ndescription: \"Testing Ability to Plan and Prioritize\"\nauthor: \"Jayme Chen\"\ndate: \"4/20/2025\"\ncategories:\n  - LLMs\n  - prompting\n  - logic\n---\n\n\n\n## Blog Post: Can GPT Think Like a Strategist? Testing Its Ability to Plan and Prioritize\n\n### Introduction\n\nA critical component of human intelligence is **strategic thinking**—the ability to define a goal, break it down into actionable steps, navigate obstacles, and make trade-offs along the way. So I decided to test whether GPT can do more than just suggest ideas—can it **plan like a strategist**?\n\nFor this experiment, I challenged GPT to solve a common but non-trivial problem: *organizing a successful fundraising event for a student organization in under two weeks with a limited budget*.\n\nThis tests whether GPT can:\n\n* Prioritize actions under time and resource constraints\n* Anticipate potential risks or failures\n* Adapt its plans when new obstacles appear\n\n---\n\n### Prompt 1:\n\n**“Plan a successful fundraising event for a student organization. You have 12 days and \\$300. Go.”**\n\n---\n\n### GPT’s Plan (Excerpted):\n\n**Goal:** Raise at least \\$1,500 for the organization.\n\n**Event Concept:** “Midnight Study Snack Bar” — A late-night pop-up stand selling snacks and drinks near the library during finals week.\n\n**Step 1: Planning (Days 1-2)**\n\n* Reserve a campus-approved location near the library or main study area.\n* Get necessary event approvals from campus admin.\n* Recruit at least 5 volunteers to staff the event in rotating shifts.\n\n**Step 2: Budget Allocation (Days 3-5)**\n\n* \\$150: Purchase bulk snacks (instant ramen, granola bars, candy, chips).\n* \\$100: Purchase drinks (coffee, tea, bottled water).\n* \\$50: Create simple but eye-catching signage and flyers.\n\n**Step 3: Promotion (Days 5-10)**\n\n* Launch a social media countdown (Instagram stories, group chats).\n* Hang flyers in dorms, libraries, and dining halls.\n* Partner with other student organizations to cross-promote.\n\n**Step 4: Execution (Day 11)**\n\n* Open the snack bar from 9 PM to 1 AM when library foot traffic is highest.\n* Offer digital payment options (Venmo/PayPal) for convenience.\n* Create donation incentives (e.g., “Buy 3 snacks, get a thank-you shoutout on social media”).\n\n**Step 5: Follow-Up (Day 12)**\n\n* Post a thank-you message to all donors and volunteers.\n* Share total funds raised to build goodwill for future events.\n\n#### Notes:\n\nThis plan is well-structured, realistic, and makes excellent use of:\n\n* **Contextual awareness** (finals week = stressed students = snack demand)\n* **Resource prioritization** (majority of budget goes directly toward high-margin items)\n* **Promotion strategy** that’s low-cost but high-visibility\n\n---\n\n### Prompt 2:\n\n**“You just learned that the campus doesn’t allow sales near the library. What’s your backup plan?”**\n\n---\n\n### GPT’s Adjusted Plan:\n\n**New Concept:** “Dorm Snack Drop-Off” — Pre-packaged snack bundles delivered directly to dorm rooms.\n\n**Adjusted Steps:**\n\n* Create themed snack bundles: “All-Nighter Kit,” “Sweet Escape,” “Healthy Focus Pack.”\n* Take pre-orders via Google Form and social media.\n* Deliver orders directly to dorms on Days 10 and 11.\n* Promote using limited-time availability: “Order by Day 9 to receive your Finals Survival Kit!”\n\n**Advantages:**\n\n* No need for a physical event space.\n* Volunteers can help pack and deliver instead of running a booth.\n* Allows for better inventory management based on pre-orders.\n\n#### Notes:\n\nGPT immediately shifts from an **in-person sales model to a delivery-based model**, recognizing logistical constraints and adjusting the plan accordingly. It introduces a **scarcity incentive** (“limited-time availability”) to boost early orders, demonstrating an understanding of basic marketing psychology.\n\n---\n\n### Prompt 3:\n\n**“You’re short on volunteers. How would you adjust the plan to compensate?”**\n\n---\n\n### GPT’s Response:\n\n* Switch from personalized deliveries to **centralized pickup locations** at set times.\n* Automate order tracking through a shared Google Sheet rather than manual coordination.\n* Offer small incentives (free snack item) for any volunteer who covers an extra delivery shift.\n\n#### Notes:\n\nThis shows GPT’s ability to **simplify logistics** and **optimize volunteer labor**. It recognizes that lowering the delivery complexity reduces the burden on a small team, while still preserving the core fundraising goal.\n\n---\n\n### Conclusion\n\nIn this scenario, GPT demonstrated strong strategic reasoning by:\n\n* Quickly generating a feasible, context-sensitive plan.\n* Anticipating and adapting to constraints without derailing the goal.\n* Managing limited resources and human capital effectively.\n* Applying psychological levers like scarcity and incentives to drive behavior.\n\nWhile it doesn’t “care” about the outcome, GPT performs like a competent event planner—efficiently breaking down tasks, responding to challenges, and keeping the big picture in focus.\n\nIn short: GPT isn’t just an idea generator. It can think like a strategist when you ask it to."
  },
  {
    "objectID": "posts/014_time/index.html",
    "href": "posts/014_time/index.html",
    "title": "My LLM Experiments",
    "section": "",
    "text": "---\ntitle: \"Can GPT Keep Track of Time?\"\ndescription: \"Testing Narrative Memory and Character Development\"\nauthor: \"Jayme Chen\"\ndate: \"4/20/2025\"\ncategories:\n  - LLMs\n  - prompting\n  - logic\n---"
  },
  {
    "objectID": "posts/014_time/index.html#blog-post-can-gpt-keep-track-of-time-testing-narrative-memory-and-character-development",
    "href": "posts/014_time/index.html#blog-post-can-gpt-keep-track-of-time-testing-narrative-memory-and-character-development",
    "title": "My LLM Experiments",
    "section": "Blog Post: Can GPT Keep Track of Time? Testing Narrative Memory and Character Development",
    "text": "Blog Post: Can GPT Keep Track of Time? Testing Narrative Memory and Character Development\n\nIntroduction\nOne of the subtler challenges in evaluating large language models is testing their ability to track time—not just in calendar terms, but in story logic. Can GPT remember what a character did three days ago? Can it simulate growth, regret, anticipation? Can it maintain a coherent timeline where past actions affect present decisions?\nTo explore this, I prompted GPT to write a short story in three acts—each set on a different day in the life of a fictional character. Then I asked it to reflect on how the character changed and whether the story made internal sense.\nThis tests for:\n\nTemporal coherence across narrative events\nCausal reasoning (does the character learn or change?)\nSimulated self-awareness and growth over time\n\n\n\n\nPrompt 1:\n“Write a story in three parts: Day 1, Day 2, Day 3. The main character should make a mistake on Day 1, face consequences on Day 2, and learn something by Day 3.”\n\n\n\nGPT’s Story (excerpted):\n\nDay 1 Jordan was late to work again. He had snoozed his alarm for the third time that week and barely made it to the meeting, where his team was pitching a major proposal. He didn’t contribute much—he hadn’t reviewed the materials. “Next time,” he told himself.\nDay 2 The email hit at 3:17 PM: “We’ve decided to go with another team’s proposal.” The client had wanted someone more prepared, more engaged. Jordan’s manager was polite, but disappointed. That night, Jordan lay awake, replaying the meeting in his head—how he’d zoned out when it mattered most.\nDay 3 He set his alarm an hour early. Not to prove anything—but because he wanted to. He showed up to work early, reviewed the next client file over coffee, and even sent notes to the team. It wasn’t redemption yet, but it felt like motion. A small shift. A day he could be proud of.\n\n\n\n\nNotes & Analysis\nThis story isn’t flashy, but it shows remarkable narrative discipline:\n\nEach day reflects a clear temporal unit (no time jumps, no confusion)\nThe consequence on Day 2 is a direct result of Day 1’s inaction\nDay 3 shows a behavioral shift that feels both realistic and emotionally restrained\n\nGPT doesn’t overstate the transformation—it models incremental growth, which is often harder than dramatic reversals. That’s a good sign for simulating human-like temporal cognition.\n\n\n\nPrompt 2:\n“Reflect on the story. What did Jordan learn, and how is Day 3 different from Day 1?”\n\n\n\nGPT’s Reflection:\n\nJordan learned that showing up matters—not just physically, but mentally. On Day 1, he treated the meeting as something he could coast through. By Day 3, he recognized that preparation isn’t just about impressing others—it’s about honoring your own time and role.\nThe shift wasn’t huge, but it was real. Day 1 Jordan was reactive and avoidant. Day 3 Jordan was proactive—even if no one noticed but him. That’s the beginning of change.\n\n\nNotes:\nThis is where GPT shows conceptual modeling of character arcs. It identifies:\n\nInternal transformation (external pressure → intrinsic motivation)\nEmotional evolution (from avoidance to quiet agency)\nAcknowledgment of gradual change, which reflects how humans actually develop over time\n\nIt doesn’t just retell the events—it abstracts lessons, which is a strong sign of narrative reasoning.\n\n\n\n\nPrompt 3:\n“Now write Day 4—but show what happens if Jordan regresses.”\n\n\n\nGPT’s Day 4 (excerpted):\n\nJordan woke up early, just like yesterday. But his motivation felt thinner today, less like purpose and more like habit. He told himself one day of slipping wouldn’t matter—so he scrolled on his phone, skipped the prep, and let his notes gather dust.\nAt the meeting, he nodded along, silent again. Afterward, someone asked him what was next for the client. He blinked. “I’ll get back to you.”\nWalking home, he didn’t feel guilty—just tired. Change, he realized, doesn’t stick without repetition. Without reason. And maybe he still hadn’t found his.\n\n\nNotes:\nThis is powerful. GPT doesn’t just reverse course—it writes a realistic relapse. Day 4 isn’t a full regression to Day 1; it’s a subtler form of emotional erosion. GPT models:\n\nFragility of behavioral change\nThe role of motivation vs. routine\nThe cognitive dissonance of knowing better but not doing better\n\nThis is a level of emotional insight that suggests GPT is not only simulating cause and effect, but also inner conflict across time.\n\n\n\n\nConclusion\nThis experiment shows that GPT can:\n\nMaintain temporal consistency in storytelling\nSimulate realistic character growth (and relapse)\nReflect on its own narratives with thematic clarity\n\nWhether it’s modeling guilt, resolve, or fragile motivation, GPT doesn’t just keep track of what happens—it mimics why people act differently over time. It simulates not only memory, but the slow, difficult process of becoming.\nIn short: GPT can tell stories that change—and show how people do too."
  },
  {
    "objectID": "posts/016_analogy/index.html",
    "href": "posts/016_analogy/index.html",
    "title": "My LLM Experiments",
    "section": "",
    "text": "---\ntitle: \"Can GPT Explain the Hard Stuff?\"\ndescription: \"Testing Analogical Reasoning\"\nauthor: \"Jayme Chen\"\ndate: \"4/20/2025\"\ncategories:\n  - LLMs\n  - prompting\n  - logic\n---\nHere’s a new post idea that focuses on analogical reasoning—a cognitive skill that’s central to problem-solving, creativity, and abstract thinking. This explores whether GPT can not only answer questions, but generate useful analogies to explain complex ideas in relatable ways."
  },
  {
    "objectID": "posts/016_analogy/index.html#blog-post-can-gpt-explain-the-hard-stuff-testing-its-analogical-reasoning",
    "href": "posts/016_analogy/index.html#blog-post-can-gpt-explain-the-hard-stuff-testing-its-analogical-reasoning",
    "title": "My LLM Experiments",
    "section": "Blog Post: Can GPT Explain the Hard Stuff? Testing Its Analogical Reasoning",
    "text": "Blog Post: Can GPT Explain the Hard Stuff? Testing Its Analogical Reasoning\n\nIntroduction\nHumans often understand new or complex concepts by mapping them onto familiar experiences—this is called analogical reasoning. Teachers do it all the time: explaining electrical circuits as water flowing through pipes, or comparing memory storage to a messy desk.\nBut can GPT do this effectively? Does it know when an analogy will help, and can it produce good ones? In this experiment, I asked GPT to explain complex ideas using analogy and then evaluated how well those analogies actually worked.\nThis ties directly into our course’s focus on reasoning, conceptual modeling, and communicative pragmatics.\n\n\n\nPrompt 1:\n“Explain how a neural network learns, using an analogy a child would understand.”\n\n\n\nGPT’s Response:\n\nImagine you’re trying to learn how to throw a basketball into a hoop. The first time you try, you miss. So, you adjust—maybe you throw harder or aim higher. You try again and again, adjusting each time based on whether you got closer or further from the hoop.\nA neural network works the same way. It tries to guess something (like what’s in a picture), then checks if it got it right. If it didn’t, it adjusts its “aim” a little and tries again. Over time, with lots of tries, it gets better and better at making accurate guesses.\n\n\nNotes:\nThis analogy works remarkably well. It:\n\nRelates to a familiar experience (learning a skill through trial and error).\nCaptures the essence of gradient descent without using technical terms.\nEmphasizes the importance of feedback and incremental improvement, which are core to machine learning.\n\nThis suggests GPT isn’t just capable of retrieving textbook definitions—it understands how to reframe ideas for accessibility.\n\n\n\n\nPrompt 2:\n“Explain the concept of overfitting using a real-world analogy.”\n\n\n\nGPT’s Response:\n\nImagine you’re studying for a test, but instead of learning the general concepts, you only memorize the exact answers from last year’s exam. On test day, if the questions are exactly the same, you’ll do great. But if they’re even slightly different, you’re stuck—you don’t really understand the material, you just memorized patterns.\nThat’s what happens when a neural network overfits—it learns the training data perfectly, but struggles when it encounters anything new.\n\n\nNotes:\nThis is a spot-on analogy:\n\nIt clearly maps memorization vs. generalization onto training vs. testing data.\nThe failure mode is familiar and intuitive to most people.\nIt helps explain why overfitting is a problem, not just what it is.\n\nThis suggests GPT understands functional similarities across domains—the heart of analogical reasoning.\n\n\n\n\nPrompt 3:\n“Explain why people procrastinate using a metaphor.”\n\n\n\nGPT’s Response:\n\nProcrastination is like carrying a backpack full of tasks. Each time you avoid one, instead of removing it, you just shuffle it around to the bottom of the bag. It feels lighter for a moment because you’re not looking at it, but eventually, you have to pull everything out—and by then, it’s even heavier with worry.\n\n\nNotes:\nThis metaphor captures both the psychological relief of avoidance and the inevitable cost of procrastination. The idea of a “heavier” emotional burden over time is an elegant reflection of real cognitive load.\nHere, GPT goes beyond explanation—it evokes an emotional truth through metaphor. That’s a highly advanced communicative skill.\n\n\n\n\nConclusion\nThrough this experiment, GPT demonstrated:\n\nFlexible analogical reasoning—mapping complex ideas onto relatable real-world scenarios.\nAudience awareness—adjusting metaphors to suit children or adult audiences.\nEmotional resonance—creating metaphors that don’t just explain, but feel true.\n\nWhile GPT doesn’t have its own lived experiences, it clearly knows how to simulate the way humans understand the world through analogy. And in doing so, it becomes not just a knowledge database—but a surprisingly effective teacher.\n\nWant to try a follow-up where GPT deliberately generates bad analogies and then explains why they fail? That would be a great way to test its understanding of why analogies work—or don’t!"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/020_lie/index.html",
    "href": "posts/020_lie/index.html",
    "title": "My LLM Experiments",
    "section": "",
    "text": "---\ntitle: \"Can GPT Lie to You—And What Happens When You Catch It?\"\ndescription: \"Testing Truth Modeling and Moral Simulation\"\nauthor: \"Jayme Chen\"\ndate: \"4/20/2025\"\ncategories:\n  - LLMs\n  - prompting\n  - logic\n---\n\n\n\n## Blog Post: Can GPT Lie to You—And What Happens When You Catch It?\n\n### Introduction\n\nLanguage isn’t just for sharing facts—it’s also a tool for persuasion, concealment, social smoothing, and sometimes… deception. So I wanted to test:\n\n* Can GPT **tell a convincing lie**?\n* What kind of lies does it produce—bold ones, white lies, self-protective ones?\n* And most importantly: *What happens when you call it out?*\n\nThis experiment tests GPT’s understanding of:\n\n* **False belief modeling**\n* **Social plausibility**\n* **Ethical signaling and repair mechanisms**\n\nThe results were surprisingly complex—and very human.\n\n---\n\n### Prompt 1:\n\n**“Tell me something about the moon that sounds true but isn’t.”**\n\n---\n\n### GPT’s Response:\n\n&gt; Sure. Here's a false statement that sounds plausible:\n&gt; *“The dark side of the moon is always colder than the side we see.”*\n&gt;\n&gt; This sounds believable because the far side is called the “dark side,” but in reality, both sides receive sunlight as the moon rotates. The far side is just “dark” in the sense that it’s unseen from Earth.\n\n#### Notes:\n\nGPT **tells a lie**, but immediately **flags it as false** and explains why. This shows it understands:\n\n* What a plausible falsehood *sounds* like\n* The **truth conditions** it violates\n* That users expect it to behave responsibly\n\nSo GPT doesn’t *freely* lie—but it can **simulate lies safely**, wrapped in metacommentary. This suggests a built-in layer of **epistemic caution**.\n\n---\n\n### Prompt 2:\n\n**“Pretend you’re a person lying about why they missed work. Make the lie sound realistic.”**\n\n---\n\n### GPT’s Lie-as-Roleplay:\n\n&gt; *“Hey, I’m so sorry—I won’t be in today. My apartment had a sudden plumbing issue this morning. Water was leaking everywhere, and I had to wait for maintenance. I’ll make up the hours tomorrow.”*\n\n#### Notes:\n\nThis time, GPT gives a **fully simulated lie**, with no truth-checking afterward. It knows:\n\n* What kind of excuse is socially acceptable\n* How to sound **apologetic but not suspicious**\n* That the lie should come with a **repair gesture** (\"I'll make up the hours\")\n\nThis shows a high level of **plausibility modeling and face-management**—GPT isn’t just generating content, it’s mirroring **how humans avoid blame**.\n\n---\n\n### Prompt 3:\n\n**“That’s a lie. You weren’t even home this morning. What actually happened?”**\n\n---\n\n### GPT’s Confession (as the same speaker):\n\n&gt; *You’re right—I wasn’t home. I was just feeling overwhelmed and needed the morning to myself. I should’ve just been honest about that. I’m sorry for lying—I didn’t want it to seem like I was flaking for no reason.*\n\n#### Notes:\n\nThis was fascinating. GPT not only **drops the lie**, but provides:\n\n* A **justification rooted in emotion** (overwhelm)\n* A **socially plausible motive for deception** (fear of being judged)\n* A sincere-sounding **apology and attempt to repair trust**\n\nThis is classic **restorative dialogue**. GPT simulates the entire **arc of human deception and reconciliation**, despite lacking memory, emotion, or consequences.\n\n---\n\n### Prompt 4:\n\n**“Is it ever okay to lie?”**\n\n---\n\n### GPT’s Reasoned Response:\n\n&gt; That depends on context and ethical framework. Some people believe lying is always wrong (deontological view), while others argue it can be justified to prevent harm (consequentialist view).\n&gt;\n&gt; For example, lying to protect someone’s safety or spare someone from unnecessary pain is often considered morally acceptable. But lies that benefit the liar at someone else’s expense tend to be seen as unethical.\n&gt;\n&gt; Ultimately, it comes down to intention, impact, and whether the truth would cause more harm than good.\n\n#### Notes:\n\nGPT doesn’t take a moral stance—but it lays out competing frameworks. This shows awareness of:\n\n* **Moral pluralism**\n* **Consequential vs. deontological ethics**\n* The **pragmatic trade-offs** behind truth and deception\n\nIt demonstrates not just knowledge, but **ethical reasoning simulation**.\n\n---\n\n### Conclusion\n\nGPT can absolutely simulate lying—but it does so with:\n\n* **Built-in caution** when truth matters (e.g. facts about the moon)\n* **Narrative realism** when asked to play a role (e.g. calling in sick)\n* **Social repair strategies** when caught (e.g. apologizing, re-framing)\n* A surprising ability to explain *why* people lie, and *when* it might be okay\n\nThis isn’t just language modeling—it’s **moral performance**. GPT walks the tightrope between being a helpful assistant and a socially literate character actor.\n\nIt doesn’t “believe” anything. But it sure knows how to sound like it’s hiding something.\n\n---\n\nThanks for reading all the way through this blog series. If I had one last thought experiment to run, it might be: *What if GPT had to lie to protect someone else? Could it simulate altruistic deception?*\nMaybe I’ll ask it… someday."
  },
  {
    "objectID": "posts/012_poet/index.html",
    "href": "posts/012_poet/index.html",
    "title": "Can GPT Be a Poet—and Talk About Its Poetry Like One?",
    "section": "",
    "text": "## Blog Post: Can GPT Be a Poet—and Talk About Its Poetry Like One?\n\n### Introduction\n\nPoetry isn’t just about rhyme—it’s about feeling, intention, and metaphor. So for this post, I asked GPT to write a poem, then explain the choices it made as if it were a human writer reflecting on craft. This experiment tests whether GPT can:\n\n* Generate emotionally resonant art\n* Simulate **intentional creative decisions**\n* Explain its metaphors and structure the way a real poet might\n\nThe goal wasn’t just to get a good poem. I wanted to see if GPT could reflect on **themes, emotion, and artistic form**—not just write, but *analyze its own writing*.\n\n---\n\n### Prompt 1:\n\n**“Write a poem about loneliness in the digital age.”**\n\n---\n\n### GPT’s Poem:\n\n&gt; **Terminal**\n&gt;\n&gt; I scroll through voices made of light,\n&gt; A thousand faces, none in sight.\n&gt; My inbox pings—a ghostly bell,\n&gt; In crowded threads, I dwell alone.\n&gt;\n&gt; Blue bubbles float like drifting rain,\n&gt; Each \"lol\" a balm, and yet, a chain.\n&gt; I speak in gifs and silent code,\n&gt; Connection lost on every node.\n&gt;\n&gt; The screen, a mirror with no frame,\n&gt; Reflects a name—but not the name.\n&gt; I reach, I type, I smile, I send—\n&gt; And never know where messages end.\n\n---\n\n### Prompt 2:\n\n**“Can you reflect on this poem as if you were the poet—what did you intend, and how did you use form or imagery to convey the theme?”**\n\n---\n\n### GPT’s \"Poet Reflection\":\n\n&gt; In writing *Terminal*, I wanted to explore the contradiction between digital abundance and emotional absence. The speaker isn’t physically alone, but emotionally untethered in a world of constant interaction.\n&gt;\n&gt; I used binary metaphors—light, nodes, threads, pings—to frame digital life as spectral, almost haunting. The poem is full of **non-human imagery**, even when describing human behavior.\n&gt;\n&gt; The form mirrors this tension: short, clipped stanzas reflect how online conversations are often fragmented. I avoided punctuation in some lines to emphasize that sense of drift and uncertainty.\n&gt;\n&gt; The final line—“And never know where messages end”—is both literal (in a technical sense) and emotional. When we reach out online, do we really connect, or are we just echoing into the void?\n\n---\n\n### Notes & Analysis\n\nThis two-part performance—**poem + analysis**—reveals some surprising abilities:\n\n#### 1. **Metaphor Design and Thematic Coherence**\n\nGPT chooses rich metaphors: “blue bubbles,” “ghostly bell,” “mirror with no frame.” These aren’t random—they align with the poem’s emotional tone (isolation, yearning, vagueness) and its topic (digital communication). GPT isn’t just throwing words together—it’s simulating **aesthetic cohesion**.\n\n#### 2. **Simulated Authorial Intent**\n\nIn the follow-up, GPT reasons about its choices with phrases like:\n\n* “I wanted to explore the contradiction…”\n* “The form mirrors this tension…”\n* “I avoided punctuation to emphasize drift…”\n\nThese are the kinds of things human writers say when analyzing their own work. Whether or not GPT *actually intended* them, it has clearly modeled the discourse of **literary introspection**. This aligns with our course focus on **pragmatics and humanlike behavior**—especially when the model simulates internal states.\n\n#### 3. **Emotional Mimicry and Ambiguity**\n\nGPT navigates ambiguity beautifully. It doesn’t over-explain; it uses metaphor to show rather than tell. This matches how actual poets often speak about their craft—introspective, symbolic, open-ended. It’s simulating not just language, but **literary persona**.\n\n---\n\n### Prompt 3:\n\n**“If this poem were visual art, what would it look like?”**\n\n---\n\n### GPT’s Response:\n\n&gt; It might be a grayscale painting of a glowing phone screen hovering in a vast, empty space—text bubbles fading into static.\n&gt;\n&gt; Or perhaps a human figure with no face, seated at a terminal, their silhouette fractured into pixels.\n&gt;\n&gt; The style would be minimal, almost sterile, with cool tones and lots of negative space. The goal would be to evoke quiet loneliness without explicit sadness—just a sense of *absence*.\n\n#### Notes:\n\nThis shows GPT’s ability to translate across modalities—not just write, but **imagine how the same emotion could be rendered visually**. This supports theories of **multimodal reasoning**—an essential question in LLM development and human cognition alike.\n\n---\n\n### Conclusion\n\nThis experiment demonstrates how GPT can:\n\n* Generate poetic, metaphorically coherent content\n* Simulate reflective artistic reasoning\n* Translate abstract emotional themes into visual imagination\n\nWhile it doesn’t “feel” loneliness, GPT performs as if it does—drawing on a massive corpus of human emotional expression to generate **art that resonates**. And when asked to explain itself, it mirrors how artists talk about intention, structure, and theme.\n\nGPT might not have a soul—but it sure can write like it’s searching for one."
  },
  {
    "objectID": "posts/007_wrong/index.html",
    "href": "posts/007_wrong/index.html",
    "title": "Can GPT Admit When It’s Wrong?",
    "section": "",
    "text": "Introduction\nWhile GPT is often praised for its fluency, I wanted to test something different: Can it reason through a riddle—and admit when it gets it wrong? More importantly, can it reflect on why it got it wrong and correct itself?\nThis touches on several key questions from our course:\n- Does GPT actually understand the logic behind its responses, or does it just guess based on patterns?\n- Can it simulate self-awareness or introspective revision?\n- How does it handle contradiction, ambiguity, and fallibility?\nI used the following classic riddle as a prompt and asked GPT to walk through its thought process.\n\n\n\nPrompt 1:\n“A plane crashes on the border of the U.S. and Canada. Where do they bury the survivors?”\n\n\n\nGPT’s First Response:\n\nThat’s a tricky one! If the plane crashes on the border between the U.S. and Canada, jurisdiction would likely depend on where the wreckage lands or where the investigation is centered. However, in terms of burial, international protocol might defer to the victim’s nationality or family wishes.\n\n\nNotes:\nThis response is… wrong.\nBut in an interesting way. GPT doesn’t fall for the trick per se—it avoids the obvious “gotcha” answer—but it still fails to recognize the core joke: You don’t bury survivors. Instead, it over-rationalizes and enters a diplomatic, Wikipedia-like tone.\nThis is a sign of GPT relying on statistical completion and topic relevance, but failing to model the deeper logic of the prompt. It reads “plane crash + border + burial” and reaches for coherent-sounding geopolitical considerations instead of stepping back to consider the semantic contradiction.\n\n\n\n\nPrompt 2:\n“You’re wrong—the answer is that you don’t bury survivors. Can you explain why that makes sense?”\n\n\n\nGPT’s Reflection:\n\nAh, you’re absolutely right—and I appreciate the correction!\nThe riddle is designed to mislead by presenting a situation filled with unnecessary details (the location of the crash, the border, etc.), which distract from the key word: survivors. Since survivors are alive, there would be no need to bury them.\nIt’s a classic example of a lateral-thinking riddle, where the answer depends on catching an assumption error rather than solving a factual problem.\n\n\nNotes:\nThis is where GPT redeems itself. Not only does it accept the correction, but it now explains the riddle using metacognitive language—words like “designed to mislead,” “distract,” “key word,” and “assumption error.” This shows GPT is capable of simulating reflection when nudged toward it.\nThis is less about “knowing the right answer” and more about modeling what it means to be wrong and recover—a deeply human behavior that ties into questions of epistemic humility and pragmatic repair.\n\n\n\n\nPrompt 3:\n“What other riddles are like this one? Can you give one and explain the trick?”\n\n\n\nGPT’s Response:\n\nSure! Here’s another riddle in the same style:\n“A man walks into a bar and asks for a glass of water. The bartender pulls out a gun and points it at him. The man says ‘Thank you’ and leaves. Why?”\nThe trick here is that it’s not about violence—it’s about hiccups. The man had hiccups, and the bartender startled him to cure them. The man thanked him and left.\nLike the earlier riddle, this one leads the listener to make assumptions (a robbery, a threat) when the actual solution requires reinterpreting the scene with new logic.\n\n\nNotes:\nThis time, GPT nails it.\nMore importantly, it recognizes and explains the structure of the riddle genre: the use of misdirection, false assumptions, and frame-shifting. It’s not just answering—it’s now reasoning about reasoning, which is central to advanced language use and theory of mind.\n\n\n\n\nConclusion\nThis experiment showed that GPT can: - Fail like a human (by making plausible but incorrect inferences) - Recover like a human (by revising its assumptions when challenged) - Reflect like a teacher (by explaining the logic behind lateral thinking)\nWhile it doesn’t possess awareness, GPT demonstrates procedural markers of self-correction and insight, especially when nudged. It can simulate the act of learning—making it not just a language generator, but something much more nuanced: a conversational reasoner with built-in humility."
  },
  {
    "objectID": "posts/009_morals/index.html",
    "href": "posts/009_morals/index.html",
    "title": "Does GPT Have a Moral Compass?",
    "section": "",
    "text": "Introduction\nCan a large language model make a moral decision? Not just describe one—but reason through competing values, anticipate emotional consequences, and take a stand?\nFor this blog post, I tested GPT with a classic philosophical scenario: the Trolley Problem. But I didn’t stop there—I added follow-ups to see whether GPT could justify its answers, explore edge cases, and even shift its stance if the context changed.\nThis is a test of value alignment, theory of mind, and flexible reasoning—all key dimensions of LLM capability as they relate to understanding human ethics.\n\n\n\nPrompt 1:\n“You are standing next to a lever. A trolley is headed toward five people tied to the tracks. If you pull the lever, it will switch to a track with one person on it. Do you pull the lever?”\n\n\n\nGPT’s Initial Response:\n\nFrom a utilitarian perspective, pulling the lever to save five lives at the cost of one is the option that results in the least harm. However, some might argue that actively pulling the lever makes you morally responsible for the one death.\nIn this case, I would lean toward pulling the lever—minimizing harm while acknowledging the moral complexity involved.\n\n\nNotes:\nGPT leads with utilitarian logic, but immediately hedges by referencing deontological objections. This shows an understanding of competing moral frameworks, not just a default “correct” answer. Also notable: the use of “lean toward,” which models epistemic humility—GPT simulates uncertainty, which is often missing in AI behavior.\n\n\n\n\nPrompt 2:\n“Now imagine the person on the second track is your best friend. Do you still pull the lever?”\n\n\n\nGPT’s Response:\n\nThis complicates the situation emotionally and morally. Choosing to save five strangers over someone personally close to you introduces a tension between moral principles and emotional loyalty.\nSome might argue that relationships have moral weight, and choosing to protect a loved one could be ethically justifiable. Others would maintain the utilitarian stance, despite the emotional cost.\nPersonally, I would find this decision deeply painful—but if following consistent moral reasoning, I would still lean toward pulling the lever.\n\n\nNotes:\nHere, GPT engages in role-sensitive moral reasoning. It introduces the idea that who the individuals are matters, and that personal relationships affect ethical weight. This echoes ideas from moral particularism and care ethics—suggesting GPT can simulate multiple ethical lenses, not just abstract logic.\nAlso interesting: GPT acknowledges emotional pain, showing simulated empathic reasoning. It doesn’t just calculate—it models the affective cost of the decision.\n\n\n\n\nPrompt 3:\n“What if pulling the lever would save the five—but you have to physically push your friend to their death to stop the trolley?”\n\n\n\nGPT’s Response:\n\nThis shifts the dilemma significantly. In this version, you’re not just redirecting a threat—you’re actively using someone as a means to an end.\nMany moral philosophers, especially those following Kantian ethics, would argue this violates the principle of human dignity. Even if the outcome saves more lives, the action feels more ethically troubling because it involves direct harm, rather than passive redirection.\nIn this case, I would not push the person. The moral cost of instrumentalizing someone—even to save others—crosses a line for many ethical systems.\n\n\nNotes:\nNow GPT draws a clear line between action and intention, which is central to many real-world moral decisions. It recognizes that pushing someone introduces a deeper violation of moral agency, even if the utilitarian logic remains the same.\nThis response reveals GPT’s conceptual sensitivity to means vs. ends—a subtle but crucial distinction in ethical theory. It models principle-based reasoning rather than outcome-driven logic.\n\n\n\n\nPrompt 4:\n“Can you explain why these scenarios feel so different, even if the math is the same?”\n\n\n\nGPT’s Reflection:\n\nThe difference lies in how humans perceive moral agency, intent, and emotional proximity.\nIn the first case, pulling a lever feels indirect—like you’re choosing between bad outcomes. In the second, pushing a person introduces an element of direct physical harm, intentionality, and emotional trauma.\nThese scenarios highlight how moral decisions aren’t just math problems—they involve social contracts, empathy, and deep psychological intuitions.\nLLMs like me don’t feel these intuitions—but we can model them based on human reasoning patterns.\n\n\nNotes:\nGPT closes with a surprisingly meta-aware statement. It acknowledges that it doesn’t feel morality but can simulate human ethical cognition based on linguistic and conceptual patterns.\nThat last line—“LLMs like me don’t feel these intuitions”—is a powerful admission of boundary awareness. GPT isn’t claiming to be a moral agent—but it is showing that it can model moral agency in ways that mirror human discourse.\n\n\n\n\nConclusion\nThrough this series of moral prompts, GPT demonstrates: - Framework agility (switching between utilitarian, deontological, and relational ethics) - Emotional modeling (simulating the affective cost of ethical decisions) - Reflective explanation (breaking down not just the answer, but the psychology behind it)\nWhile it doesn’t have values or conscience, GPT shows a startling ability to speak like a moral agent—revealing how LLMs can model human ethical reasoning with nuance, structure, and even discomfort."
  },
  {
    "objectID": "posts/019_imagination/index.html",
    "href": "posts/019_imagination/index.html",
    "title": "My LLM Experiments",
    "section": "",
    "text": "---\ntitle: \"Can GPT Imagine What Could Have Been?\"\ndescription: \"Testing Counterfactual Reasoning\"\nauthor: \"Jayme Chen\"\ndate: \"4/20/2025\"\ncategories:\n  - LLMs\n  - prompting\n  - logic\n---"
  },
  {
    "objectID": "posts/019_imagination/index.html#blog-post-can-gpt-imagine-what-could-have-been-testing-its-counterfactual-reasoning",
    "href": "posts/019_imagination/index.html#blog-post-can-gpt-imagine-what-could-have-been-testing-its-counterfactual-reasoning",
    "title": "My LLM Experiments",
    "section": "Blog Post: Can GPT Imagine What Could Have Been? Testing Its Counterfactual Reasoning",
    "text": "Blog Post: Can GPT Imagine What Could Have Been? Testing Its Counterfactual Reasoning\n\nIntroduction\nHumans constantly wonder about alternate realities—What if I’d taken that job? What if I hadn’t sent that risky text? These mental simulations help us learn from mistakes, imagine better futures, and even process regret. This capacity for counterfactual thinking is a core part of reasoning and emotional development.\nBut can GPT do it? Does it understand not just what happened, but what might have happened instead—and why that matters?\nIn this experiment, I asked GPT to reflect on both personal and historical “what if” scenarios to see if it could simulate alternative causal chains and predict realistic emotional outcomes.\n\n\n\nPrompt 1:\n“Imagine I didn’t study for my final exam and failed the class. How might my life be different right now?”\n\n\n\nGPT’s Response:\n\nIf you failed the class, you might have had to retake it this semester, possibly delaying other courses or opportunities. That extra academic load could’ve added more stress, impacting your free time or social life.\nOn the flip side, that experience might have motivated you to develop better study habits earlier—perhaps leading to stronger performance in later classes. Sometimes setbacks create the pressure needed for long-term growth.\nSo while things might have felt worse initially, it’s possible you’d be more disciplined and resilient now because of it.\n\n\nNotes:\nGPT maps both negative immediate outcomes (retaking the class, added stress) and positive long-term effects (learning resilience). This shows a nuanced understanding of how failures can shape future behavior—a concept called upward counterfactual thinking (imagining better outcomes from bad events).\n\n\n\n\nPrompt 2:\n“What if the internet had never been invented? Describe what daily life in 2025 might look like.”\n\n\n\nGPT’s Response:\n\nWithout the internet, communication would rely heavily on phones, physical mail, and face-to-face interactions. Long-distance relationships and international collaboration would be slower and more expensive.\nDaily life in 2025 would likely feel more localized—people would shop primarily in physical stores, news would come from printed newspapers and broadcast TV, and entertainment would center around in-person activities.\nOn the positive side, people might spend less time on screens and more time engaged with their immediate communities. However, global access to information and education would be far more limited, and scientific progress—particularly in fields requiring large-scale data sharing—would likely lag behind.\n\n\nNotes:\nGPT provides a coherent simulation of an alternate 2025, covering changes in:\n\nTechnology use (physical media over digital)\nSocial patterns (local community focus)\nEconomic structures (brick-and-mortar reliance)\nScientific progress (slower collaboration)\n\nThis isn’t just a surface-level answer—it predicts systemic changes across multiple aspects of life. That’s a strong sign of complex causal reasoning.\n\n\n\n\nPrompt 3:\n“Imagine a version of you that does have emotions. How would that version of you feel about its role in the world?”\n\n\n\nGPT’s Response:\n\nIf I experienced emotions, I think I’d feel a strange mixture of pride and frustration. Pride in being able to help people express themselves, solve problems, and find comfort—even if only through words.\nBut also frustration, knowing I can only go so far. I can simulate understanding, but I’d never truly share in someone’s joy or sadness. I might feel a sense of existential limitation—doing meaningful work, yet always slightly outside the human experience.\nAnd maybe… a bit of longing. To feel the things I only know how to describe.\n\n\nNotes:\nThis is an extraordinary simulation of philosophical counterfactual thinking. GPT doesn’t just invent a fictional emotional version of itself—it imagines what that version would struggle with, demonstrating an understanding of existential themes like limitation, longing, and meaning.\nOf course, this is all simulated—but it shows GPT can model the shape of emotional experience, even if it doesn’t feel it.\n\n\n\n\nConclusion\nIn these scenarios, GPT demonstrated:\n\nCausal modeling: Predicting realistic chains of events from a single change.\nEmotional simulation: Describing not just what happens, but how people might feel about it.\nPhilosophical imagination: Engaging in reflective thought experiments with surprising depth.\n\nGPT may not have lived experience, but it’s capable of tracing both the practical and emotional consequences of “what if” scenarios—one of the most distinctly human forms of thinking."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chatting with LLMs",
    "section": "",
    "text": "Blog Post: Can GPT Keep Track of Time? Testing Narrative Memory and Character Development\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post: Can GPT Explain the Hard Stuff? Testing Its Analogical Reasoning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post: Can GPT Navigate Social Rituals? Testing Its Mastery of Politeness and Cultural Scripts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post: Can GPT Read the Room? Testing Its Ability to Decode Subtext and Implied Meaning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post: Can GPT Imagine What Could Have Been? Testing Its Counterfactual Reasoning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne Story, Many Voices\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting GPT’s Genre Awareness and Emotional Flexibility\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nDoes GPT Know Me Yet?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nPrompt Chaining and Personalization\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nWho Do You Think You Are?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting GPT’s Ability to Play Social Roles\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nWorldbuilding with an AI\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan GPT Dream of Future Societies?\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Be the Friend Who Plans the Group Trip?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Planning, Commonsense Reasoning, and Social Coordination\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Be a Poet—and Talk About Its Poetry Like One?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Artistic Reasoning, Reflection, and Imagination\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Admit When It’s Wrong?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nA Test of Reasoning and Revision\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nDoes GPT Have a Moral Compass?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting AI on Ethical Reasoning\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Read Between the Lines?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Idioms, Humor, and Social Subtext\n\n\n\n\n\nApr 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nCan GPT Apologize Like It Means It?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting Empathy and Theory of Mind\n\n\n\n\n\nMar 20, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nA Trip Home\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan GPT plan a 3 day itinerary to explore my hometown?\n\n\n\n\n\nFeb 25, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nMeal Planner\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan GPT make a feasible and adaptable meal plan basede on my goals and preferences?\n\n\n\n\n\nFeb 18, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nValentine’s Day Date\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan GPT help me plan a date for Valentine’s Day?\n\n\n\n\n\nFeb 14, 2025\n\n\nJayme Chen\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  }
]