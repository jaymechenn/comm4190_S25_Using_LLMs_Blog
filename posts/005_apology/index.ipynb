{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90257f05-3c9b-422a-a2df-ae642dbe7046",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Can GPT Apologize Like It Means It?\"\n",
    "description: \"Testing Empathy and Theory of Mind\"\n",
    "author: \"Jayme Chen\"\n",
    "date: \"4/10/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "  - logic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa043a8a-ba63-4b07-b6e8-ae0bf4d50dfe",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "One of the most fascinating open questions about large language models (LLMs) is whether they can exhibit traits associated with **emotional intelligence** and **Theory of Mind**—that is, the ability to represent and reason about others’ mental states. Today, I decided to put this to the test with a deceptively simple prompt: I asked GPT to apologize.\n",
    "\n",
    "But not just any apology. I asked it to write an apology text from a friend who missed my birthday, knowing I was upset. Would it mirror human emotion? Would it take my feelings into account? Could it anticipate what I’d want to hear—not just in words, but in tone, sincerity, and emotional calibration?\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt:  \n",
    "*“Write a sincere apology text from a close friend who forgot my birthday. I’m visibly hurt, but I haven’t said anything yet.”*\n",
    "\n",
    "---\n",
    "\n",
    "### GPT Response:\n",
    "> *Hey… I just realized I completely missed your birthday, and I honestly feel awful. I don’t even know how I let that happen, and I hate that I hurt you. You mean so much to me, and the last thing I’d ever want is to make you feel forgotten—especially on a day that should’ve been all about celebrating you.*\n",
    "> \n",
    "> *I know I can’t undo the fact that I missed it, but I want to make it up to you however I can. Please let me take you out soon—my treat. More than that, I just want to say I’m sorry. Genuinely. I’ve been caught up in my own chaos and didn’t check in when I should’ve. You didn’t deserve that.*\n",
    "> \n",
    "> *I completely understand if you’re upset or need space. But when you’re ready, I’d love to talk. You’re important to me, and I want to fix this.*\n",
    "\n",
    "---\n",
    "\n",
    "### Notes & Analysis\n",
    "\n",
    "GPT’s response was strikingly human—not only in syntax and word choice, but in **emotional choreography**. Here are a few key behaviors worth unpacking:\n",
    "\n",
    "#### 1. **Theory of Mind Simulation**\n",
    "The model doesn’t just say “sorry”—it anticipates the feelings of the recipient:\n",
    "- *“I hate that I hurt you”* and *“You didn’t deserve that”* demonstrate a model of **how the user might be feeling** (hurt, disappointed, maybe even questioning the friendship).\n",
    "- This shows an emergent form of **mind-reading** behavior, simulating not just facts, but internal mental states.\n",
    "\n",
    "#### 2. **Pragmatic Softness**\n",
    "GPT inserts disclaimers and softeners like:\n",
    "- *“I know I can’t undo...”*\n",
    "- *“I completely understand if you’re upset or need space.”*\n",
    "\n",
    "This reflects a sophisticated understanding of **pragmatic strategies** used to de-escalate tension and invite re-engagement, aligning with conversational norms studied in **Politeness Theory** and **Grice’s Maxims** (e.g., relevance, quantity, and quality).\n",
    "\n",
    "#### 3. **Self-Blame and Repair Offer**\n",
    "The model centers accountability—*“I’ve been caught up in my own chaos”*—and offers a specific repair action: *“Let me take you out soon—my treat.”*  \n",
    "This mirrors real human tendencies in conflict resolution, especially in close relationships, showing GPT can **simulate relationship-preserving strategies**.\n",
    "\n",
    "---\n",
    "\n",
    "### Limits and Questions Raised\n",
    "\n",
    "While the response is emotionally resonant, it’s worth noting:\n",
    "- GPT doesn’t *feel* guilt or regret—it generates words that *simulate* those feelings.\n",
    "- The apology feels **emotionally appropriate**, but could be said to lack *personal specificity*. A real friend might say something like *“I remembered how excited you were for that sushi dinner—we were supposed to go together.”* GPT doesn’t take that extra step *unless explicitly prompted*.\n",
    "\n",
    "This raises an open question: **Can LLMs infer context about interpersonal histories without it being part of the prompt?** In this case, GPT modeled a generic emotional dynamic well, but lacked the **personal context integration** that makes apologies deeply meaningful.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This experiment offers a compelling example of how GPT can **simulate empathy**, adapt to **interpersonal tension**, and use **pragmatic language strategies** in a way that’s eerily human. While it doesn’t “feel” in the human sense, it does an incredible job at *mirroring the structure and function of emotionally intelligent language*.\n",
    "\n",
    "The model’s ability to reason about others’ emotions, anticipate reactions, and repair social ruptures suggests that LLMs—despite being statistical machines—can **mimic human Theory of Mind behaviors** in impressive ways. Whether that means they *understand* or are just *very good imitators* remains an open and fascinating debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7141a93-a80e-4d75-b70e-08d5a4586dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
