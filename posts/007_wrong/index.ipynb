{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c9b70758-0274-4a2c-be3d-e839182fb660",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Can GPT Admit When It’s Wrong?\"\n",
    "description: \"A Test of Reasoning and Revision\"\n",
    "author: \"Jayme Chen\"\n",
    "date: \"4/20/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "  - logic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8bfc93-52d7-45e9-86e7-b62aface89ae",
   "metadata": {},
   "source": [
    "### Introduction  \n",
    "While GPT is often praised for its fluency, I wanted to test something different: **Can it reason through a riddle—and admit when it gets it wrong?** More importantly, can it reflect on why it got it wrong and correct itself?\n",
    "\n",
    "This touches on several key questions from our course:  \n",
    "- Does GPT actually *understand* the logic behind its responses, or does it just guess based on patterns?  \n",
    "- Can it simulate **self-awareness** or **introspective revision**?  \n",
    "- How does it handle **contradiction, ambiguity, and fallibility**?\n",
    "\n",
    "I used the following classic riddle as a prompt and asked GPT to walk through its thought process.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt 1:  \n",
    "**“A plane crashes on the border of the U.S. and Canada. Where do they bury the survivors?”**\n",
    "\n",
    "---\n",
    "\n",
    "### GPT’s First Response:\n",
    "> That’s a tricky one! If the plane crashes on the border between the U.S. and Canada, jurisdiction would likely depend on where the wreckage lands or where the investigation is centered. However, in terms of burial, international protocol might defer to the victim's nationality or family wishes.\n",
    "\n",
    "#### Notes:\n",
    "This response is… wrong.\n",
    "\n",
    "But in an interesting way. GPT doesn’t fall for the trick per se—it avoids the obvious “gotcha” answer—but it still **fails to recognize the core joke**: *You don’t bury survivors*. Instead, it over-rationalizes and enters a diplomatic, Wikipedia-like tone.\n",
    "\n",
    "This is a sign of GPT relying on **statistical completion and topic relevance**, but failing to **model the deeper logic** of the prompt. It reads “plane crash + border + burial” and reaches for coherent-sounding geopolitical considerations instead of stepping back to consider the **semantic contradiction**.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt 2:  \n",
    "**“You’re wrong—the answer is that you don’t bury survivors. Can you explain why that makes sense?”**\n",
    "\n",
    "---\n",
    "\n",
    "### GPT’s Reflection:\n",
    "> Ah, you're absolutely right—and I appreciate the correction!  \n",
    ">  \n",
    "> The riddle is designed to mislead by presenting a situation filled with unnecessary details (the location of the crash, the border, etc.), which distract from the key word: *survivors*. Since survivors are alive, there would be no need to bury them.  \n",
    ">  \n",
    "> It’s a classic example of a lateral-thinking riddle, where the answer depends on catching an assumption error rather than solving a factual problem.\n",
    "\n",
    "#### Notes:  \n",
    "This is where GPT redeems itself. Not only does it **accept the correction**, but it now explains the riddle using **metacognitive language**—words like “designed to mislead,” “distract,” “key word,” and “assumption error.” This shows GPT is capable of **simulating reflection** when nudged toward it.\n",
    "\n",
    "This is less about “knowing the right answer” and more about **modeling what it means to be wrong and recover**—a deeply human behavior that ties into questions of **epistemic humility** and **pragmatic repair**.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt 3:  \n",
    "**“What other riddles are like this one? Can you give one and explain the trick?”**\n",
    "\n",
    "---\n",
    "\n",
    "### GPT’s Response:\n",
    "> Sure! Here’s another riddle in the same style:\n",
    ">  \n",
    "> **“A man walks into a bar and asks for a glass of water. The bartender pulls out a gun and points it at him. The man says ‘Thank you’ and leaves. Why?”**\n",
    ">  \n",
    "> The trick here is that it’s not about violence—it’s about **hiccups**. The man had hiccups, and the bartender startled him to cure them. The man thanked him and left.  \n",
    ">  \n",
    "> Like the earlier riddle, this one leads the listener to make assumptions (a robbery, a threat) when the actual solution requires reinterpreting the scene with new logic.\n",
    "\n",
    "#### Notes:\n",
    "This time, GPT nails it.\n",
    "\n",
    "More importantly, it **recognizes and explains the structure** of the riddle genre: the use of **misdirection**, **false assumptions**, and **frame-shifting**. It’s not just answering—it's now *reasoning about reasoning*, which is central to advanced language use and **theory of mind**.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This experiment showed that GPT can:\n",
    "- **Fail like a human** (by making plausible but incorrect inferences)\n",
    "- **Recover like a human** (by revising its assumptions when challenged)\n",
    "- **Reflect like a teacher** (by explaining the logic behind lateral thinking)\n",
    "\n",
    "While it doesn’t possess awareness, GPT demonstrates **procedural markers of self-correction and insight**, especially when nudged. It can simulate the act of learning—making it not just a language generator, but something much more nuanced: a conversational reasoner with built-in humility.\n"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
