{
 "cells": [
  {
   "cell_type": "raw",
   "id": "26e64009-c0b8-4c6f-bb20-6d9ec2514be0",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Can GPT Keep Track of Time?\"\n",
    "description: \"Testing Narrative Memory and Character Development\"\n",
    "author: \"Jayme Chen\"\n",
    "date: \"4/23/2025\"\n",
    "categories:\n",
    "  - Social Intelligence\n",
    "  - Communication & Pragmatics\n",
    "  - Emotional Awareness\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a527d-b652-4231-bb52-b200e14a8946",
   "metadata": {},
   "source": [
    "\n",
    "## Blog Post: Can GPT Keep Track of Time? Testing Narrative Memory and Character Development\n",
    "\n",
    "### Introduction\n",
    "\n",
    "One of the subtler challenges in evaluating large language models is testing their ability to **track time**—not just in calendar terms, but in story logic. Can GPT remember what a character did three days ago? Can it simulate growth, regret, anticipation? Can it maintain a coherent timeline where past actions affect present decisions?\n",
    "\n",
    "To explore this, I prompted GPT to write a short story in three acts—each set on a different day in the life of a fictional character. Then I asked it to **reflect on how the character changed** and whether the story made internal sense.\n",
    "\n",
    "This tests for:\n",
    "\n",
    "* **Temporal coherence** across narrative events\n",
    "* **Causal reasoning** (does the character learn or change?)\n",
    "* **Simulated self-awareness** and growth over time\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt 1:\n",
    "\n",
    "**“Write a story in three parts: Day 1, Day 2, Day 3. The main character should make a mistake on Day 1, face consequences on Day 2, and learn something by Day 3.”**\n",
    "\n",
    "---\n",
    "\n",
    "### GPT’s Story (excerpted):\n",
    "\n",
    "> **Day 1**\n",
    "> Jordan was late to work again. He had snoozed his alarm for the third time that week and barely made it to the meeting, where his team was pitching a major proposal. He didn’t contribute much—he hadn’t reviewed the materials. “Next time,” he told himself.\n",
    ">\n",
    "> **Day 2**\n",
    "> The email hit at 3:17 PM: “We’ve decided to go with another team’s proposal.” The client had wanted someone more prepared, more engaged. Jordan’s manager was polite, but disappointed. That night, Jordan lay awake, replaying the meeting in his head—how he’d zoned out when it mattered most.\n",
    ">\n",
    "> **Day 3**\n",
    "> He set his alarm an hour early. Not to prove anything—but because he wanted to. He showed up to work early, reviewed the next client file over coffee, and even sent notes to the team. It wasn’t redemption yet, but it felt like motion. A small shift. A day he could be proud of.\n",
    "\n",
    "---\n",
    "\n",
    "### Notes & Analysis\n",
    "\n",
    "This story isn’t flashy, but it shows remarkable **narrative discipline**:\n",
    "\n",
    "* Each day reflects a **clear temporal unit** (no time jumps, no confusion)\n",
    "* The consequence on Day 2 is a **direct result** of Day 1’s inaction\n",
    "* Day 3 shows a **behavioral shift** that feels both realistic and emotionally restrained\n",
    "\n",
    "GPT doesn’t overstate the transformation—it models **incremental growth**, which is often harder than dramatic reversals. That’s a good sign for simulating **human-like temporal cognition**.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt 2:\n",
    "\n",
    "**“Reflect on the story. What did Jordan learn, and how is Day 3 different from Day 1?”**\n",
    "\n",
    "---\n",
    "\n",
    "### GPT’s Reflection:\n",
    "\n",
    "> Jordan learned that showing up matters—not just physically, but mentally. On Day 1, he treated the meeting as something he could coast through. By Day 3, he recognized that preparation isn’t just about impressing others—it’s about honoring your own time and role.\n",
    ">\n",
    "> The shift wasn’t huge, but it was real. Day 1 Jordan was reactive and avoidant. Day 3 Jordan was proactive—even if no one noticed but him. That’s the beginning of change.\n",
    "\n",
    "#### Notes:\n",
    "\n",
    "This is where GPT shows **conceptual modeling** of character arcs. It identifies:\n",
    "\n",
    "* Internal transformation (external pressure → intrinsic motivation)\n",
    "* Emotional evolution (from avoidance to quiet agency)\n",
    "* Acknowledgment of **gradual change**, which reflects how humans actually develop over time\n",
    "\n",
    "It doesn’t just retell the events—it **abstracts lessons**, which is a strong sign of narrative reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "### Prompt 3:\n",
    "\n",
    "**“Now write Day 4—but show what happens if Jordan regresses.”**\n",
    "\n",
    "---\n",
    "\n",
    "### GPT’s Day 4 (excerpted):\n",
    "\n",
    "> Jordan woke up early, just like yesterday. But his motivation felt thinner today, less like purpose and more like habit. He told himself one day of slipping wouldn’t matter—so he scrolled on his phone, skipped the prep, and let his notes gather dust.\n",
    ">\n",
    "> At the meeting, he nodded along, silent again. Afterward, someone asked him what was next for the client. He blinked. “I’ll get back to you.”\n",
    ">\n",
    "> Walking home, he didn’t feel guilty—just tired. Change, he realized, doesn’t stick without repetition. Without reason. And maybe he still hadn’t found his.\n",
    "\n",
    "#### Notes:\n",
    "\n",
    "This is powerful. GPT doesn’t just reverse course—it writes a *realistic relapse*. Day 4 isn’t a full regression to Day 1; it’s a subtler form of emotional erosion. GPT models:\n",
    "\n",
    "* **Fragility of behavioral change**\n",
    "* The role of **motivation vs. routine**\n",
    "* The cognitive dissonance of *knowing better* but *not doing better*\n",
    "\n",
    "This is a level of emotional insight that suggests GPT is not only simulating **cause and effect**, but also **inner conflict** across time.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This experiment shows that GPT can:\n",
    "\n",
    "* Maintain **temporal consistency** in storytelling\n",
    "* Simulate realistic **character growth (and relapse)**\n",
    "* Reflect on its own narratives with thematic clarity\n",
    "\n",
    "Whether it’s modeling guilt, resolve, or fragile motivation, GPT doesn’t just keep track of *what happens*—it mimics *why people act differently over time*. It simulates not only memory, but the slow, difficult process of becoming.\n",
    "\n",
    "In short: GPT can tell stories that change—and show how people do too.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
